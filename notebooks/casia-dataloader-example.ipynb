{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gait_analysis import CasiaDataset, settings\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the quickly the indexing to access all the angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configuration  default\n"
     ]
    }
   ],
   "source": [
    "from gait_analysis.Config import Config\n",
    "c = Config()\n",
    "c.config['indexing']['grouping'] = 'person_sequence_angle'\n",
    "c.config['pose']['load'] = True\n",
    "c.config['flow']['load'] = True\n",
    "c.config['heatmaps']['load'] = True\n",
    "# c.config['transformers']['Rescale']['target'] = [\"heatmaps\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plain and untransformed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_3 = CasiaDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['scenes', 'flows', 'heatmaps'])\n"
     ]
    }
   ],
   "source": [
    "item = dataset_3[1]\n",
    "annotations = item['annotations']\n",
    "scenes = item['scenes']\n",
    "poses = item['poses']\n",
    "flows = item['flows']\n",
    "\n",
    "print(item.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the composer to construct reusable transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchvision.transforms.Compose object at 0x121897748>\n"
     ]
    }
   ],
   "source": [
    "from gait_analysis import Composer\n",
    "\n",
    "composer = Composer()\n",
    "transformer = composer.compose()\n",
    "print(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heatmaps are a list of lists:\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "with total number of elements: \n",
      "52  lists per frames\n",
      "2  lists per frames, meaning heatmaps per frame\n",
      "these come from the configuration:\n",
      "['LAnkle', 'RAnkle']\n",
      "Plotting the first element.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x123d862e8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmaps = item['heatmaps']\n",
    "print('heatmaps are a list of lists:')\n",
    "print(type(heatmaps))\n",
    "print(type(heatmaps[0]))\n",
    "print('with total number of elements: ')\n",
    "print(len(heatmaps),' lists per frames')\n",
    "print(len(heatmaps[0]),' lists per frames, meaning heatmaps per frame')\n",
    "print('these come from the configuration:')\n",
    "print(c.config['heatmaps']['body_keypoints_include_list'])\n",
    "print('Plotting the first element.')\n",
    "plt.imshow(item['heatmaps'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person_sequence_angle\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-13b7ea6c65e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexing_grouping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtransformed_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'==> transformed item is: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gait_36/lib/python3.6/site-packages/torchvision/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gait_project/gait_processing/gait_analysis/Transformers/SpanImagesList.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m# each frame has two images stores in a list...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# TODO: MORE APPROPRIATED INDEXING IS BY FRAME???\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mlists_images_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0;31m# initialize empty list to fill by frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "print(c.get_indexing_grouping())\n",
    "test_item = dataset_3[0]\n",
    "transformed_item = transformer(test_item)\n",
    "print('==> transformed item is: ',test_item.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing some samples of the transformed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = CasiaDataset(transform=transformer)\n",
    "\n",
    "for i in range(len(transformed_dataset)):\n",
    "    print('i: ', i)\n",
    "    sample = transformed_dataset[i]\n",
    "\n",
    "    print(i, sample.keys())\n",
    "    print(sample['annotations'].size())\n",
    "\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['annotations']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader = DataLoader(transformed_dataset, batch_size=4,\n",
    "#                         shuffle=True, num_workers=4)\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    # observe 4th batch and stop.\n",
    "    if i_batch == 3:\n",
    "        print(type(sample_batched))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEV: The problem is that the dimensions of the label are different for some of the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
