{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import os.path as path\n",
    "import copy\n",
    "# from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "\n",
    "from gait_analysis import AnnotationsCasia as Annotations\n",
    "from gait_analysis import CasiaDataset\n",
    "from gait_analysis.Config import Config\n",
    "from gait_analysis import Composer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configuration  one_angle\n",
      "[OK]\n"
     ]
    }
   ],
   "source": [
    "#change configuration in settings.py\n",
    "\n",
    "crop_im_size = [186,250]\n",
    "c = Config()\n",
    "c.config['indexing']['grouping'] = 'person_sequence_angle'\n",
    "c.config['indexing']['people selection'] = [1]\n",
    "#c.config['indexing']['sequences_selection'] = ['nm-01']\n",
    "c.config['pose']['load'] = False\n",
    "c.config['flow']['load'] = False\n",
    "c.config['heatmaps']['load'] = False\n",
    "#c.config['scenes']['sequences'] = ['nm']\n",
    "#c.config['scenes']['angles'] = ['108']\n",
    "c.config['dataset_output'] = {\n",
    "#         'data': [\"scenes\",\"flows\",\"heatmaps_LAnkle\",\"heatmaps_RAnkle\"],\n",
    "        'data': [\"scenes\"],\n",
    "        'label': \"annotations\"}\n",
    "composer = Composer()\n",
    "transformer = composer.compose()\n",
    "dataset = CasiaDataset(transform=transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NETWORK AND DATASET PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters defined\n"
     ]
    }
   ],
   "source": [
    "#DESIGN PARAMETERS FOR NEURAL NETWORK\n",
    "NR_LSTM_UNITS = 2 \n",
    "IMAGE_INPUT_SIZE_W = 640\n",
    "IMAGE_INPUT_SIZE_H = 480\n",
    "\n",
    "IMAGE_AFTER_CONV_SIZE_W = 18\n",
    "IMAGE_AFTER_CONV_SIZE_H = 13\n",
    "#for 3x3 kernels, n=num_layers: len_in = 2^n*len_out + sum[i=1..n](2^i)\n",
    "#CONV_LAYER_LENGTH = 5\n",
    "\n",
    "LSTM_IO_SIZE = 18*13\n",
    "LSTM_HIDDEN_SIZE = 18*13\n",
    "\n",
    "RGB_CHANNELS = 3\n",
    "TIMESTEPS = 40 # size videos\n",
    "BATCH_SIZE = 1 #until now just batch_size = 1\n",
    "\n",
    "NR_EPOCHS = 50\n",
    "\n",
    "VALIDATION_SPLIT = 0.2\n",
    "RANDOMIZED_SEED = 10\n",
    "SHUFFLE_DATASET = False\n",
    "\n",
    "learning_rate = 0.01 # reduce factos of 10 .. some epoch later.\n",
    "momentum = 0.9\n",
    "print(\"Hyperparameters defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings \n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 250\n",
      "Indices size: 250\n",
      "Split: 50\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "print(\"Dataset size:\", len(dataset))\n",
    "print(\"Indices size:\", len(indices))\n",
    "split = int(np.floor(VALIDATION_SPLIT * dataset_size))\n",
    "print(\"Split:\", split)\n",
    "if SHUFFLE_DATASET:\n",
    "    np.random.seed(RANDOMIZED_SEED)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "train_sampler = torch.utils.data.SequentialSampler(train_indices)\n",
    "test_sampler = torch.utils.data.SequentialSampler(test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=test_sampler)\n",
    "\n",
    "# #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#USE RANDOM IMAGES TO SET UP WORKING EXAMPLE\n",
    "class TEST_CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TEST_CNN_LSTM, self).__init__()\n",
    "        self.avialable_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3,6,3) #input 640x480\n",
    "        self.pool1 = nn.MaxPool2d(2,2) #input 638x478 output 319x239\n",
    "        self.conv2 = nn.Conv2d(6,16,3) # input 319x239 output 317x237\n",
    "        self.pool2 = nn.MaxPool2d(2,2) # input 317x237 output 158x118\n",
    "        self.conv3 = nn.Conv2d(16,6,3) # input 158x118 output 156x116\n",
    "        self.pool3 = nn.MaxPool2d(2,2) # input 156x116 output 78x58\n",
    "        self.conv4 = nn.Conv2d(6,3,3)  # input 78x58 output 76x56\n",
    "        self.pool4 = nn.MaxPool2d(2,2) # input 76x56 output 39x29\n",
    "        self.conv5 = nn.Conv2d(3,1,3)  # input 39x29 output 37x27\n",
    "        self.pool5 = nn.MaxPool2d(2,2) #output 37x27 output 18x13\n",
    "        self.lstm1 = nn.LSTM(LSTM_IO_SIZE,\n",
    "                            LSTM_HIDDEN_SIZE,\n",
    "                            TIMESTEPS)# horizontal direction\n",
    "        self.lstm2 = nn.LSTM(LSTM_IO_SIZE,\n",
    "                            LSTM_HIDDEN_SIZE,\n",
    "                            TIMESTEPS)# horizontal direction\n",
    "        self.fc1 = nn.Linear(LSTM_IO_SIZE,120)\n",
    "        self.fc2 = nn.Linear(120,20)\n",
    "        self.fc3 = nn.Linear(20,3)\n",
    "        \n",
    "        #initialize hidden states of LSTM\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "        #print(\"Hidden:\", _hidden)\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(TIMESTEPS, BATCH_SIZE, LSTM_HIDDEN_SIZE).to(self.avialable_device), \n",
    "                torch.randn(TIMESTEPS, BATCH_SIZE, LSTM_HIDDEN_SIZE).to(self.avialable_device))\n",
    "    def forward(self,x):\n",
    "#         print(\"Input list len:\",len(x))\n",
    "#         print(\"Input elemens size:\", x[0].size())\n",
    "#         batch_size = x[0].size()[0]\n",
    "\n",
    "        x_arr = torch.zeros(TIMESTEPS,BATCH_SIZE,1,IMAGE_AFTER_CONV_SIZE_H,IMAGE_AFTER_CONV_SIZE_W).to(self.avialable_device)\n",
    "        ## print(\"X arr size\", x_arr.size())\n",
    "        for i in range(TIMESTEPS):#parallel convolutions which are later concatenated for LSTM\n",
    "            x_tmp_c1 = self.pool1(F.relu(self.conv1(x[i].float())))\n",
    "            x_tmp_c2 = self.pool2(F.relu(self.conv2(x_tmp_c1)))\n",
    "            x_tmp_c3 = self.pool3(F.relu(self.conv3(x_tmp_c2)))\n",
    "            x_tmp_c4 = self.pool4(F.relu(self.conv4(x_tmp_c3)))\n",
    "            x_tmp_c5 = self.pool5(F.relu(self.conv5(x_tmp_c4)))\n",
    "            x_arr[i] = x_tmp_c5 # torch.squeeze(x_tmp_c5)\n",
    "        \n",
    "        x, hidden = self.lstm1(x_arr.view(TIMESTEPS,BATCH_SIZE,-1), self.hidden)\n",
    "        x, hidden = self.lstm2(x, self.hidden)\n",
    "        # the reshaping was taken from the documentation... and makes scense\n",
    "        x = x.view(TIMESTEPS,BATCH_SIZE,LSTM_HIDDEN_SIZE) #output.view(seq_len, batch, num_dir*hidden_size)\n",
    "#         x = torch.squeeze(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x) \n",
    "        x = x.permute(1,2,0)\n",
    "        return x\n",
    "print(\"Class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOS:\n",
    "# Look for overfitting..\n",
    "# use GPU: 300 samples. many epochs. learning rate maybe is too high.\n",
    "# Tweak learning rate\n",
    "# Increase the RNN size\n",
    "# Maybe change the CNN\n",
    "# Use patches. or OF\n",
    "# Increase the dataset: 10 images 10peoplo+++ not too much too much variance. \n",
    "# FEEDBACK on friday..:) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#TRAINING\n",
    "test_net = TEST_CNN_LSTM()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "test_net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(test_net.parameters(), lr=learning_rate, momentum=momentum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define and execute testing function\n",
    "def test_all_preds(model):\n",
    "    n_batches_test = len(test_loader)\n",
    "\n",
    "    #Time for printing\n",
    "    testing_start_time = time.time()\n",
    "\n",
    "    print('Start testing...')\n",
    "    correct = 0 \n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            inputs, labels = batch\n",
    "            \n",
    "            scenes = [s.to(device) for s in inputs['scenes']]\n",
    "            labels = labels.to(device)\n",
    "            if not labels.size()[0] == BATCH_SIZE:\n",
    "                # skip uncompleted batch size NN is fixed to BATCHSIZE\n",
    "                continue\n",
    "            outputs = model(scenes)\n",
    "#             print(\"Out:\", len(outputs), outputs.size())\n",
    "#             print(\"Labels:\", len(labels), labels.size())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "#             print('predicted:',len(predicted),predicted.size())\n",
    "            n_errors = torch.nonzero(torch.abs(labels.long() - predicted)).size(0)\n",
    "            total += predicted.numel()\n",
    "            # print('predicted',predicted)\n",
    "            correct += predicted.numel() - n_errors\n",
    "            # print('labels',labels)\n",
    "    print('Accuracy {:.2f}%'.format(100*correct/total))\n",
    "    print('...testing finished')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training over all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training.. on decive:. cuda:0\n",
      "Epoch: 0\n",
      "Loss epoch 0: 218.10583448410034, took 167.60365867614746s\n",
      "Epoch: 1\n",
      "Loss epoch 1: 217.11326837539673, took 160.8835253715515s\n",
      "Epoch: 2\n",
      "Loss epoch 2: 216.61324775218964, took 149.71982884407043s\n",
      "Epoch: 3\n",
      "Loss epoch 3: 216.5788345336914, took 148.05774784088135s\n",
      "Epoch: 4\n",
      "Loss epoch 4: 216.63714975118637, took 146.68776416778564s\n",
      "Epoch: 5\n",
      "Loss epoch 5: 216.60501909255981, took 147.53718733787537s\n",
      "Epoch: 6\n",
      "Loss epoch 6: 216.5289353132248, took 146.8386001586914s\n",
      "Epoch: 7\n",
      "Loss epoch 7: 216.46223932504654, took 147.58880472183228s\n",
      "Epoch: 8\n",
      "Loss epoch 8: 216.40885639190674, took 146.86871337890625s\n",
      "Epoch: 9\n",
      "Loss epoch 9: 216.34495556354523, took 146.694739818573s\n",
      "Epoch: 10\n",
      "Loss epoch 10: 216.28376710414886, took 148.08120369911194s\n",
      "Epoch: 11\n",
      "Loss epoch 11: 216.19697803258896, took 146.97914004325867s\n",
      "Epoch: 12\n",
      "Loss epoch 12: 216.12741804122925, took 147.6415684223175s\n",
      "Epoch: 13\n",
      "Loss epoch 13: 215.9012188911438, took 148.23764944076538s\n",
      "Epoch: 14\n",
      "Loss epoch 14: 215.75581073760986, took 147.77817916870117s\n",
      "Epoch: 15\n",
      "Loss epoch 15: 215.49442917108536, took 147.09125065803528s\n",
      "Epoch: 16\n",
      "Loss epoch 16: 214.96487188339233, took 147.64135432243347s\n",
      "Epoch: 17\n",
      "Loss epoch 17: 214.3668019771576, took 147.11073422431946s\n",
      "Epoch: 18\n",
      "Loss epoch 18: 214.0272187590599, took 147.3810751438141s\n",
      "Epoch: 19\n",
      "Loss epoch 19: 213.94891130924225, took 147.15670108795166s\n",
      "Epoch: 20\n",
      "Loss epoch 20: 213.9816491007805, took 147.14775228500366s\n",
      "Epoch: 21\n",
      "Loss epoch 21: 213.91811102628708, took 147.31994652748108s\n",
      "Epoch: 22\n",
      "Loss epoch 22: 213.92976260185242, took 147.09631061553955s\n",
      "Epoch: 23\n",
      "Loss epoch 23: 213.76937991380692, took 148.71238231658936s\n",
      "Epoch: 24\n",
      "Loss epoch 24: 213.7541065812111, took 146.8959140777588s\n",
      "Epoch: 25\n",
      "Loss epoch 25: 213.6797857284546, took 149.43548798561096s\n",
      "Epoch: 26\n",
      "Loss epoch 26: 213.71838515996933, took 147.25283455848694s\n",
      "Epoch: 27\n",
      "Loss epoch 27: 213.5825663805008, took 148.57786178588867s\n",
      "Epoch: 28\n",
      "Loss epoch 28: 213.57534110546112, took 146.69458985328674s\n",
      "Epoch: 29\n",
      "Loss epoch 29: 213.49427729845047, took 147.50669169425964s\n",
      "Epoch: 30\n",
      "Loss epoch 30: 213.44585692882538, took 147.23570156097412s\n",
      "Epoch: 31\n",
      "Loss epoch 31: 213.3906243443489, took 147.43124651908875s\n",
      "Epoch: 32\n",
      "Loss epoch 32: 213.6317703127861, took 147.22436928749084s\n",
      "Epoch: 33\n",
      "Loss epoch 33: 213.420479118824, took 146.62408542633057s\n",
      "Epoch: 34\n",
      "Loss epoch 34: 213.45353776216507, took 147.76112723350525s\n",
      "Epoch: 35\n",
      "Loss epoch 35: 213.25453132390976, took 146.01764178276062s\n",
      "Epoch: 36\n",
      "Loss epoch 36: 213.57553625106812, took 147.62745428085327s\n",
      "Epoch: 37\n",
      "Loss epoch 37: 213.60674476623535, took 149.04646611213684s\n",
      "Epoch: 38\n",
      "Loss epoch 38: 215.36809128522873, took 147.87813591957092s\n",
      "Epoch: 39\n",
      "Loss epoch 39: 215.19134485721588, took 147.13893485069275s\n",
      "Learning rate changed 0.01\n",
      "Epoch: 40\n",
      "Loss epoch 40: 214.99959141016006, took 147.71431469917297s\n",
      "Epoch: 41\n",
      "Loss epoch 41: 214.8135592341423, took 147.08133578300476s\n",
      "Epoch: 42\n",
      "Loss epoch 42: 214.63770014047623, took 147.57197642326355s\n",
      "Epoch: 43\n",
      "Loss epoch 43: 214.65634936094284, took 146.9156322479248s\n",
      "Epoch: 44\n",
      "Loss epoch 44: 214.54439914226532, took 146.35586404800415s\n",
      "Epoch: 45\n",
      "Loss epoch 45: 214.65220695734024, took 147.43650722503662s\n",
      "Epoch: 46\n",
      "Loss epoch 46: 214.5519322156906, took 147.65638422966003s\n",
      "Epoch: 47\n",
      "Loss epoch 47: 214.31837409734726, took 147.7005169391632s\n",
      "Epoch: 48\n",
      "Loss epoch 48: 214.18353217840195, took 147.2850832939148s\n",
      "Epoch: 49\n",
      "Loss epoch 49: 214.39039134979248, took 147.58297061920166s\n",
      "Start testing...\n",
      "Accuracy 37.66%\n",
      "...testing finished\n",
      "...Training finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f75b0cca6a0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_batches = len(train_loader)\n",
    "\n",
    "#Time for printing\n",
    "training_start_time = time.time()\n",
    "\n",
    "loss_array = np.zeros(NR_EPOCHS)\n",
    "\n",
    "print('Start training.. on decive:.',device)\n",
    "for epoch in range(NR_EPOCHS): \n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    if (epoch == 40):\n",
    "        learning_rate = 0.01\n",
    "        optimizer = optim.SGD(test_net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        print (\"Learning rate changed\", learning_rate)\n",
    "#     if (epoch == 80):\n",
    "#         learning_rate = 0.001\n",
    "#         optimizer = optim.SGD(test_net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "#         print (\"Learning rate changed\", learning_rate)\n",
    "    \n",
    "    print(\"Epoch:\", epoch)\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(train_loader): #loads all angles\n",
    "        inputs, labels = batch\n",
    "        scenes = [s.to(device) for s in inputs['scenes']]\n",
    "        labels = labels.unsqueeze(-1).to(device)\n",
    "        if not labels.size()[0] == BATCH_SIZE:\n",
    "            # skip uncompleted batch size NN is fixed to BATCHSIZE\n",
    "            continue\n",
    "        optimizer.zero_grad() \n",
    "        outputs = test_net(scenes)\n",
    "        outputs = outputs.unsqueeze(-1)\n",
    "        #print(\"Size before permutation:\", outputs.size())\n",
    "        outputs = outputs.permute(0,2,1,3).squeeze(3).squeeze(0)\n",
    "        labels = labels.squeeze(2).squeeze(0)\n",
    "        #print(\"Out:\", len(outputs), outputs.size())\n",
    "        #print(\"Labels:\", len(labels), labels.size())\n",
    "        #print(\"Here\")\n",
    "        #print(scenes[0].squeeze(0).permute(2,1,0).size())\n",
    "        #for j in range(10):\n",
    "        #    scene_print = scenes[j].squeeze(0).permute(1,2,0)\n",
    "        #    plt.imshow(scene_print.numpy())\n",
    "        #    plt.show()\n",
    "        #print(labels)\n",
    "        loss = criterion(outputs,labels.long())\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "        #Print statistics\n",
    "        # print(loss.data.item())\n",
    "        running_loss += loss.data.item()\n",
    "        #total_train_loss += loss.data.item()\n",
    "        \n",
    "        #Print every 10th batch of an epoch\n",
    "#         if (i + 1) % (print_every + 1) == 0:\n",
    "#             print(\"Epoch {}, {:d}% \\t train_loss(mean): {:.2f} took: {:.2f}s\".format(\n",
    "#                     epoch+1, int(100 * (i+1) / n_batches), running_loss/print_every, time.time() - start_time))\n",
    "#             #Reset running loss and time\n",
    "#             running_loss = 0.0\n",
    "#             start_time = time.time()\n",
    "    # test after each epoch\n",
    "    print(\"Loss epoch {}: {}, took {}s\".format(epoch, running_loss,time.time()-start_time))\n",
    "    loss_array[epoch] = running_loss\n",
    "\n",
    "test_all_preds(test_net)\n",
    "#print('total training loss for epoch {}: {:.6f}'.format(epoch+1, total_train_loss))    \n",
    "print('...Training finished')\n",
    "plt.plot(loss_array)\n",
    "plt.plot(loss_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(labels.size())\n",
    "# print(outputs.size())\n",
    "# print(labels)\n",
    "# print(outputs)\n",
    "# import matplotlib.pyplot as plt\n",
    "# print(scenes[0].squeeze(0).size())\n",
    "# plt.imshow(scenes[9].squeeze(0).permute(1,2,0))\n",
    "# plt.figure(figsize=(30,40))\n",
    "# print('left foot trans from air to ground')\n",
    "# plt.subplot(131)\n",
    "# plt.imshow(scenes[4])\n",
    "# plt.title('frame 44')\n",
    "# plt.subplot(132)\n",
    "# plt.imshow(scenes[5])\n",
    "# plt.title('frame 45')\n",
    "# plt.subplot(133)\n",
    "# plt.imshow(scenes[6])\n",
    "# plt.title('frame 46')\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python gait_37",
   "language": "python",
   "name": "gait_37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
