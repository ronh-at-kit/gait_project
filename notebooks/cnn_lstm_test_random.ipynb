{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class defined\n",
      "Start training...\n",
      "('Epoch:', 0)\n",
      "('Loss:', 1.0909373760223389)\n",
      "('Epoch:', 1)\n",
      "('Loss:', 1.089163064956665)\n",
      "('Epoch:', 2)\n",
      "('Loss:', 1.0857974290847778)\n",
      "('Epoch:', 3)\n",
      "('Loss:', 1.0811439752578735)\n",
      "('Epoch:', 4)\n",
      "('Loss:', 1.0754539966583252)\n",
      "('Epoch:', 5)\n",
      "('Loss:', 1.0689092874526978)\n",
      "('Epoch:', 6)\n",
      "('Loss:', 1.061870813369751)\n",
      "('Epoch:', 7)\n",
      "('Loss:', 1.0541836023330688)\n",
      "('Epoch:', 8)\n",
      "('Loss:', 1.045945167541504)\n",
      "('Epoch:', 9)\n",
      "('Loss:', 1.0371663570404053)\n",
      "('Epoch:', 10)\n",
      "('Loss:', 1.0278629064559937)\n",
      "('Epoch:', 11)\n",
      "('Loss:', 1.01815927028656)\n",
      "('Epoch:', 12)\n",
      "('Loss:', 1.0078754425048828)\n",
      "('Epoch:', 13)\n",
      "('Loss:', 0.9970199465751648)\n",
      "('Epoch:', 14)\n",
      "('Loss:', 0.9857150316238403)\n",
      "('Epoch:', 15)\n",
      "('Loss:', 0.9738418459892273)\n",
      "('Epoch:', 16)\n",
      "('Loss:', 0.9615076780319214)\n",
      "('Epoch:', 17)\n",
      "('Loss:', 0.9487428665161133)\n",
      "('Epoch:', 18)\n",
      "('Loss:', 0.93562251329422)\n",
      "('Epoch:', 19)\n",
      "('Loss:', 0.9222139120101929)\n",
      "('Epoch:', 20)\n",
      "('Loss:', 0.9085963368415833)\n",
      "('Epoch:', 21)\n",
      "('Loss:', 0.8947837948799133)\n",
      "('Epoch:', 22)\n",
      "('Loss:', 0.8808712959289551)\n",
      "('Epoch:', 23)\n",
      "('Loss:', 0.8669524192810059)\n",
      "('Epoch:', 24)\n",
      "('Loss:', 0.8531176447868347)\n",
      "('Epoch:', 25)\n",
      "('Loss:', 0.8394516110420227)\n",
      "('Epoch:', 26)\n",
      "('Loss:', 0.8260670900344849)\n",
      "('Epoch:', 27)\n",
      "('Loss:', 0.8130707740783691)\n",
      "('Epoch:', 28)\n",
      "('Loss:', 0.8004257082939148)\n",
      "('Epoch:', 29)\n",
      "('Loss:', 0.7880157828330994)\n",
      "('Epoch:', 30)\n",
      "('Loss:', 0.7758970260620117)\n",
      "('Epoch:', 31)\n",
      "('Loss:', 0.7639657258987427)\n",
      "('Epoch:', 32)\n",
      "('Loss:', 0.7522057294845581)\n",
      "('Epoch:', 33)\n",
      "('Loss:', 0.7405751943588257)\n",
      "('Epoch:', 34)\n",
      "('Loss:', 0.7289919257164001)\n",
      "('Epoch:', 35)\n",
      "('Loss:', 0.7174643874168396)\n",
      "('Epoch:', 36)\n",
      "('Loss:', 0.7059756517410278)\n",
      "('Epoch:', 37)\n",
      "('Loss:', 0.6945880651473999)\n",
      "('Epoch:', 38)\n",
      "('Loss:', 0.6832320094108582)\n",
      "('Epoch:', 39)\n",
      "('Loss:', 0.6718599796295166)\n",
      "('Epoch:', 40)\n",
      "('Loss:', 0.6604989767074585)\n",
      "('Epoch:', 41)\n",
      "('Loss:', 0.6490321159362793)\n",
      "('Epoch:', 42)\n",
      "('Loss:', 0.6375991106033325)\n",
      "('Epoch:', 43)\n",
      "('Loss:', 0.6261349320411682)\n",
      "('Epoch:', 44)\n",
      "('Loss:', 0.6146406531333923)\n",
      "('Epoch:', 45)\n",
      "('Loss:', 0.6030887365341187)\n",
      "('Epoch:', 46)\n",
      "('Loss:', 0.591454029083252)\n",
      "('Epoch:', 47)\n",
      "('Loss:', 0.579822838306427)\n",
      "('Epoch:', 48)\n",
      "('Loss:', 0.5682463645935059)\n",
      "('Epoch:', 49)\n",
      "('Loss:', 0.5566868782043457)\n",
      "('Epoch:', 50)\n",
      "('Loss:', 0.545200765132904)\n",
      "('Epoch:', 51)\n",
      "('Loss:', 0.5336980223655701)\n",
      "('Epoch:', 52)\n",
      "('Loss:', 0.5221878886222839)\n",
      "('Epoch:', 53)\n",
      "('Loss:', 0.51067054271698)\n",
      "('Epoch:', 54)\n",
      "('Loss:', 0.49913889169692993)\n",
      "('Epoch:', 55)\n",
      "('Loss:', 0.48761826753616333)\n",
      "('Epoch:', 56)\n",
      "('Loss:', 0.47605305910110474)\n",
      "('Epoch:', 57)\n",
      "('Loss:', 0.4644182622432709)\n",
      "('Epoch:', 58)\n",
      "('Loss:', 0.45268258452415466)\n",
      "('Epoch:', 59)\n",
      "('Loss:', 0.44078630208969116)\n",
      "('Epoch:', 60)\n",
      "('Loss:', 0.42877164483070374)\n",
      "('Epoch:', 61)\n",
      "('Loss:', 0.4166589379310608)\n",
      "('Epoch:', 62)\n",
      "('Loss:', 0.40439748764038086)\n",
      "('Epoch:', 63)\n",
      "('Loss:', 0.39210692048072815)\n",
      "('Epoch:', 64)\n",
      "('Loss:', 0.3797207474708557)\n",
      "('Epoch:', 65)\n",
      "('Loss:', 0.3672606348991394)\n",
      "('Epoch:', 66)\n",
      "('Loss:', 0.3547341823577881)\n",
      "('Epoch:', 67)\n",
      "('Loss:', 0.3421920835971832)\n",
      "('Epoch:', 68)\n",
      "('Loss:', 0.3296579420566559)\n",
      "('Epoch:', 69)\n",
      "('Loss:', 0.31723731756210327)\n",
      "('Epoch:', 70)\n",
      "('Loss:', 0.30489522218704224)\n",
      "('Epoch:', 71)\n",
      "('Loss:', 0.29268139600753784)\n",
      "('Epoch:', 72)\n",
      "('Loss:', 0.2806786000728607)\n",
      "('Epoch:', 73)\n",
      "('Loss:', 0.26886773109436035)\n",
      "('Epoch:', 74)\n",
      "('Loss:', 0.25726306438446045)\n",
      "('Epoch:', 75)\n",
      "('Loss:', 0.24589809775352478)\n",
      "('Epoch:', 76)\n",
      "('Loss:', 0.23479247093200684)\n",
      "('Epoch:', 77)\n",
      "('Loss:', 0.2239517718553543)\n",
      "('Epoch:', 78)\n",
      "('Loss:', 0.21339242160320282)\n",
      "('Epoch:', 79)\n",
      "('Loss:', 0.20315484702587128)\n",
      "('Epoch:', 80)\n",
      "('Loss:', 0.19328297674655914)\n",
      "('Epoch:', 81)\n",
      "('Loss:', 0.18379414081573486)\n",
      "('Epoch:', 82)\n",
      "('Loss:', 0.17466667294502258)\n",
      "('Epoch:', 83)\n",
      "('Loss:', 0.1659112274646759)\n",
      "('Epoch:', 84)\n",
      "('Loss:', 0.15759581327438354)\n",
      "('Epoch:', 85)\n",
      "('Loss:', 0.14972847700119019)\n",
      "('Epoch:', 86)\n",
      "('Loss:', 0.14232787489891052)\n",
      "('Epoch:', 87)\n",
      "('Loss:', 0.1353446990251541)\n",
      "('Epoch:', 88)\n",
      "('Loss:', 0.12878486514091492)\n",
      "('Epoch:', 89)\n",
      "('Loss:', 0.12263895571231842)\n",
      "('Epoch:', 90)\n",
      "('Loss:', 0.11684006452560425)\n",
      "('Epoch:', 91)\n",
      "('Loss:', 0.1114082783460617)\n",
      "('Epoch:', 92)\n",
      "('Loss:', 0.10630221664905548)\n",
      "('Epoch:', 93)\n",
      "('Loss:', 0.1014624685049057)\n",
      "('Epoch:', 94)\n",
      "('Loss:', 0.09690473228693008)\n",
      "('Epoch:', 95)\n",
      "('Loss:', 0.09264318645000458)\n",
      "('Epoch:', 96)\n",
      "('Loss:', 0.08861160278320312)\n",
      "('Epoch:', 97)\n",
      "('Loss:', 0.08481912314891815)\n",
      "('Epoch:', 98)\n",
      "('Loss:', 0.08125090599060059)\n",
      "('Epoch:', 99)\n",
      "('Loss:', 0.07786986976861954)\n",
      "...Training finished\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "#DESIGN PARAMETERS FOR NEURAL NETWORK\n",
    "NR_LSTM_UNITS = 2\n",
    "IMAGE_INPUT_SIZE = 50\n",
    "IMAGE_AFTER_CONV_SIZE = 24\n",
    "\n",
    "LSTM_INPUT_SIZE = IMAGE_AFTER_CONV_SIZE*IMAGE_AFTER_CONV_SIZE\n",
    "\n",
    "RGB_CHANNELS = 3\n",
    "TIMESTEPS = 10\n",
    "BATCH_SIZE = 1 #until now just batch_size = 1\n",
    "\n",
    "#USE RANDOM IMAGES TO SET UP WORKING EXAMPLE\n",
    "class TEST_CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TEST_CNN_LSTM, self).__init__()\n",
    "        self.conv = nn.Conv2d(3,1,3) #input 50x50x3\n",
    "        self.pool = nn.MaxPool2d(2,2) #input 48x48 output 24x24\n",
    "        self.lstm = nn.LSTM(LSTM_INPUT_SIZE,\n",
    "                            LSTM_INPUT_SIZE,\n",
    "                            NR_LSTM_UNITS)\n",
    "        self.fc1 = nn.Linear(LSTM_INPUT_SIZE,\n",
    "                             120)\n",
    "        self.fc2 = nn.Linear(120,3)\n",
    "        \n",
    "        #initialize hidden states of LSTM\n",
    "        self._hidden = (torch.randn(NR_LSTM_UNITS, BATCH_SIZE, LSTM_INPUT_SIZE), \n",
    "                        torch.randn(NR_LSTM_UNITS, BATCH_SIZE, LSTM_INPUT_SIZE))\n",
    "        #print(\"Hidden:\", _hidden)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #print(\"Input:\", x.size())\n",
    "        x = x.float() #necessary for some reason\n",
    "        x_arr = torch.zeros(TIMESTEPS,IMAGE_AFTER_CONV_SIZE,IMAGE_AFTER_CONV_SIZE)\n",
    "        #print(\"X arr size\", x_arr.size())\n",
    "        for i in range(TIMESTEPS):#parallel convolutions which are later concatenated for LSTM\n",
    "            x_tmp2 = self.pool(F.relu(self.conv(x[i].unsqueeze(0))))\n",
    "            x_arr[i] = torch.squeeze(x_tmp2)\n",
    "        \n",
    "        x, _hidden = self.lstm(x_arr.view(TIMESTEPS,BATCH_SIZE,-1), self._hidden)\n",
    "        x = x.view(-1,LSTM_INPUT_SIZE)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "print(\"Class defined\")\n",
    "\n",
    "rand_arr = np.random.rand(TIMESTEPS,RGB_CHANNELS,IMAGE_INPUT_SIZE,IMAGE_INPUT_SIZE)\n",
    "test_images = torch.from_numpy(rand_arr)\n",
    "#test_labels = torch.tensor([0,1,2,0,1,2,0,1,2,0]) #DIFFICULT\n",
    "test_labels = torch.tensor([0,0,0,1,1,1,2,2,2,2])#EASY\n",
    "\n",
    "#TRAINING\n",
    "test_net = TEST_CNN_LSTM()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(test_net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "print('Start training...')\n",
    "for epoch in range(100): \n",
    "    print(\"Epoch:\", epoch)\n",
    "    running_loss = 0.0\n",
    "    #for i in range(TIMESTEP):\n",
    "    inputs = test_images\n",
    "    labels = test_labels\n",
    "\n",
    "    optimizer.zero_grad() \n",
    "    outputs = test_net(inputs)\n",
    "    #print(\"Out:\", len(outputs), outputs)\n",
    "    #print(\"Labels:\", len(labels), labels)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward() \n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "    print(\"Loss:\", running_loss)\n",
    "print('...Training finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR TESTING PURPOSES\n",
    "test = torch.zeros(10,24,24)\n",
    "test[1] = torch.randn(24,24)\n",
    "test = test.view(10,-1)\n",
    "#concat = torch.cat([x for x in test],0)\n",
    "print(test.size())\n",
    "#print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#print(test_images[0])\n",
    "#concatenation = torch.cat((test_images, test_images))\n",
    "\n",
    "#for x in range(test_images.size(0)):\n",
    "#    concatenation = torch.cat((test_images[x]))\n",
    "#print(concatenation.size())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python gait_36",
   "language": "python",
   "name": "gait_36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
