{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class defined\n",
      "('Shape', (10, 3, 228, 228))\n",
      "Start training...\n",
      "('Epoch:', 0)\n",
      "('Loss:', 1.1016583442687988)\n",
      "('Epoch:', 1)\n",
      "('Loss:', 1.1004270315170288)\n",
      "('Epoch:', 2)\n",
      "('Loss:', 1.09827721118927)\n",
      "('Epoch:', 3)\n",
      "('Loss:', 1.0956131219863892)\n",
      "('Epoch:', 4)\n",
      "('Loss:', 1.092881441116333)\n",
      "('Epoch:', 5)\n",
      "('Loss:', 1.0903798341751099)\n",
      "('Epoch:', 6)\n",
      "('Loss:', 1.0885006189346313)\n",
      "('Epoch:', 7)\n",
      "('Loss:', 1.0872610807418823)\n",
      "('Epoch:', 8)\n",
      "('Loss:', 1.0866347551345825)\n",
      "('Epoch:', 9)\n",
      "('Loss:', 1.086483120918274)\n",
      "('Epoch:', 10)\n",
      "('Loss:', 1.0866007804870605)\n",
      "('Epoch:', 11)\n",
      "('Loss:', 1.0867527723312378)\n",
      "('Epoch:', 12)\n",
      "('Loss:', 1.0867154598236084)\n",
      "('Epoch:', 13)\n",
      "('Loss:', 1.0864487886428833)\n",
      "('Epoch:', 14)\n",
      "('Loss:', 1.0859477519989014)\n",
      "('Epoch:', 15)\n",
      "('Loss:', 1.085232138633728)\n",
      "('Epoch:', 16)\n",
      "('Loss:', 1.0842483043670654)\n",
      "('Epoch:', 17)\n",
      "('Loss:', 1.083093285560608)\n",
      "('Epoch:', 18)\n",
      "('Loss:', 1.081889271736145)\n",
      "('Epoch:', 19)\n",
      "('Loss:', 1.0807422399520874)\n",
      "('Epoch:', 20)\n",
      "('Loss:', 1.0796411037445068)\n",
      "('Epoch:', 21)\n",
      "('Loss:', 1.0786335468292236)\n",
      "('Epoch:', 22)\n",
      "('Loss:', 1.0776960849761963)\n",
      "('Epoch:', 23)\n",
      "('Loss:', 1.0767970085144043)\n",
      "('Epoch:', 24)\n",
      "('Loss:', 1.0758541822433472)\n",
      "('Epoch:', 25)\n",
      "('Loss:', 1.0748342275619507)\n",
      "('Epoch:', 26)\n",
      "('Loss:', 1.0736377239227295)\n",
      "('Epoch:', 27)\n",
      "('Loss:', 1.0722447633743286)\n",
      "('Epoch:', 28)\n",
      "('Loss:', 1.0706592798233032)\n",
      "('Epoch:', 29)\n",
      "('Loss:', 1.0688953399658203)\n",
      "('Epoch:', 30)\n",
      "('Loss:', 1.066941261291504)\n",
      "('Epoch:', 31)\n",
      "('Loss:', 1.0648351907730103)\n",
      "('Epoch:', 32)\n",
      "('Loss:', 1.0625983476638794)\n",
      "('Epoch:', 33)\n",
      "('Loss:', 1.0602582693099976)\n",
      "('Epoch:', 34)\n",
      "('Loss:', 1.057864785194397)\n",
      "('Epoch:', 35)\n",
      "('Loss:', 1.0553998947143555)\n",
      "('Epoch:', 36)\n",
      "('Loss:', 1.0528385639190674)\n",
      "('Epoch:', 37)\n",
      "('Loss:', 1.0501925945281982)\n",
      "('Epoch:', 38)\n",
      "('Loss:', 1.047474980354309)\n",
      "('Epoch:', 39)\n",
      "('Loss:', 1.0446884632110596)\n",
      "('Epoch:', 40)\n",
      "('Loss:', 1.0419291257858276)\n",
      "('Epoch:', 41)\n",
      "('Loss:', 1.0392290353775024)\n",
      "('Epoch:', 42)\n",
      "('Loss:', 1.0365190505981445)\n",
      "('Epoch:', 43)\n",
      "('Loss:', 1.0340903997421265)\n",
      "('Epoch:', 44)\n",
      "('Loss:', 1.0316179990768433)\n",
      "('Epoch:', 45)\n",
      "('Loss:', 1.028570532798767)\n",
      "('Epoch:', 46)\n",
      "('Loss:', 1.0253431797027588)\n",
      "('Epoch:', 47)\n",
      "('Loss:', 1.0222218036651611)\n",
      "('Epoch:', 48)\n",
      "('Loss:', 1.0188779830932617)\n",
      "('Epoch:', 49)\n",
      "('Loss:', 1.014813780784607)\n",
      "('Epoch:', 50)\n",
      "('Loss:', 1.0099523067474365)\n",
      "('Epoch:', 51)\n",
      "('Loss:', 1.0053658485412598)\n",
      "('Epoch:', 52)\n",
      "('Loss:', 1.002892017364502)\n",
      "('Epoch:', 53)\n",
      "('Loss:', 1.000815987586975)\n",
      "('Epoch:', 54)\n",
      "('Loss:', 0.9986704587936401)\n",
      "('Epoch:', 55)\n",
      "('Loss:', 0.9964930415153503)\n",
      "('Epoch:', 56)\n",
      "('Loss:', 0.9943230748176575)\n",
      "('Epoch:', 57)\n",
      "('Loss:', 0.992315948009491)\n",
      "('Epoch:', 58)\n",
      "('Loss:', 0.9904586672782898)\n",
      "('Epoch:', 59)\n",
      "('Loss:', 0.9887958765029907)\n",
      "('Epoch:', 60)\n",
      "('Loss:', 0.9871775507926941)\n",
      "('Epoch:', 61)\n",
      "('Loss:', 0.9857737421989441)\n",
      "('Epoch:', 62)\n",
      "('Loss:', 0.9844231605529785)\n",
      "('Epoch:', 63)\n",
      "('Loss:', 0.9830859899520874)\n",
      "('Epoch:', 64)\n",
      "('Loss:', 0.9818180799484253)\n",
      "('Epoch:', 65)\n",
      "('Loss:', 0.9805598258972168)\n",
      "('Epoch:', 66)\n",
      "('Loss:', 0.979287326335907)\n",
      "('Epoch:', 67)\n",
      "('Loss:', 0.9779537320137024)\n",
      "('Epoch:', 68)\n",
      "('Loss:', 0.976617157459259)\n",
      "('Epoch:', 69)\n",
      "('Loss:', 0.9750053286552429)\n",
      "('Epoch:', 70)\n",
      "('Loss:', 0.9735543131828308)\n",
      "('Epoch:', 71)\n",
      "('Loss:', 0.9720864295959473)\n",
      "('Epoch:', 72)\n",
      "('Loss:', 0.9701906442642212)\n",
      "('Epoch:', 73)\n",
      "('Loss:', 0.9682693481445312)\n",
      "('Epoch:', 74)\n",
      "('Loss:', 0.9664672613143921)\n",
      "('Epoch:', 75)\n",
      "('Loss:', 0.9647053480148315)\n",
      "('Epoch:', 76)\n",
      "('Loss:', 0.9618998765945435)\n",
      "('Epoch:', 77)\n",
      "('Loss:', 0.9596236944198608)\n",
      "('Epoch:', 78)\n",
      "('Loss:', 0.9572208523750305)\n",
      "('Epoch:', 79)\n",
      "('Loss:', 0.9544843435287476)\n",
      "('Epoch:', 80)\n",
      "('Loss:', 0.9515596628189087)\n",
      "('Epoch:', 81)\n",
      "('Loss:', 0.9485920071601868)\n",
      "('Epoch:', 82)\n",
      "('Loss:', 0.945549488067627)\n",
      "('Epoch:', 83)\n",
      "('Loss:', 0.942130446434021)\n",
      "('Epoch:', 84)\n",
      "('Loss:', 0.9387584924697876)\n",
      "('Epoch:', 85)\n",
      "('Loss:', 0.9356842041015625)\n",
      "('Epoch:', 86)\n",
      "('Loss:', 0.9317375421524048)\n",
      "('Epoch:', 87)\n",
      "('Loss:', 0.9277951121330261)\n",
      "('Epoch:', 88)\n",
      "('Loss:', 0.9241549372673035)\n",
      "('Epoch:', 89)\n",
      "('Loss:', 0.9204839468002319)\n",
      "('Epoch:', 90)\n",
      "('Loss:', 0.9169005155563354)\n",
      "('Epoch:', 91)\n",
      "('Loss:', 0.9135528802871704)\n",
      "('Epoch:', 92)\n",
      "('Loss:', 0.9102209210395813)\n",
      "('Epoch:', 93)\n",
      "('Loss:', 0.9073125123977661)\n",
      "('Epoch:', 94)\n",
      "('Loss:', 0.9043357968330383)\n",
      "('Epoch:', 95)\n",
      "('Loss:', 0.9017522931098938)\n",
      "('Epoch:', 96)\n",
      "('Loss:', 0.8996240496635437)\n",
      "('Epoch:', 97)\n",
      "('Loss:', 0.897294819355011)\n",
      "('Epoch:', 98)\n",
      "('Loss:', 0.895054817199707)\n",
      "('Epoch:', 99)\n",
      "('Loss:', 0.8929116129875183)\n",
      "...Training finished\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "#DESIGN PARAMETERS FOR NEURAL NETWORK\n",
    "NR_LSTM_UNITS = 2\n",
    "IMAGE_INPUT_SIZE = 228\n",
    "IMAGE_AFTER_CONV_SIZE = 5\n",
    "#for 3x3 kernels, n=num_layers: len_in = 2^n*len_out + sum[i=1..n](2^i)\n",
    "#CONV_LAYER_LENGTH = 5\n",
    "\n",
    "LSTM_IO_SIZE = IMAGE_AFTER_CONV_SIZE*IMAGE_AFTER_CONV_SIZE\n",
    "\n",
    "RGB_CHANNELS = 3\n",
    "TIMESTEPS = 10\n",
    "BATCH_SIZE = 1 #until now just batch_size = 1\n",
    "\n",
    "#USE RANDOM IMAGES TO SET UP WORKING EXAMPLE\n",
    "class TEST_CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TEST_CNN_LSTM, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,3) #input 388x388\n",
    "        self.pool1 = nn.MaxPool2d(2,2) #input 48x48 output 24x24\n",
    "        self.conv2 = nn.Conv2d(6,16,3)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        self.conv3 = nn.Conv2d(16,6,3)\n",
    "        self.pool3 = nn.MaxPool2d(2,2)\n",
    "        self.conv4 = nn.Conv2d(6,3,3)\n",
    "        self.pool4 = nn.MaxPool2d(2,2)\n",
    "        self.conv5 = nn.Conv2d(3,1,3)\n",
    "        self.pool5 = nn.MaxPool2d(2,2) #output 5x5\n",
    "        self.lstm = nn.LSTM(LSTM_IO_SIZE,\n",
    "                            LSTM_IO_SIZE,\n",
    "                            NR_LSTM_UNITS)\n",
    "        self.fc1 = nn.Linear(LSTM_IO_SIZE,120)\n",
    "        self.fc2 = nn.Linear(120,20)\n",
    "        self.fc3 = nn.Linear(20,3)\n",
    "        \n",
    "        #initialize hidden states of LSTM\n",
    "        self._hidden = (torch.randn(NR_LSTM_UNITS, BATCH_SIZE, LSTM_IO_SIZE), \n",
    "                        torch.randn(NR_LSTM_UNITS, BATCH_SIZE, LSTM_IO_SIZE))\n",
    "        #print(\"Hidden:\", _hidden)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #print(\"Input:\", x.size())\n",
    "        x = x.float() #necessary for some reason\n",
    "        x_arr = torch.zeros(TIMESTEPS,IMAGE_AFTER_CONV_SIZE,IMAGE_AFTER_CONV_SIZE)\n",
    "        #print(\"X arr size\", x_arr.size())\n",
    "        for i in range(TIMESTEPS):#parallel convolutions which are later concatenated for LSTM\n",
    "            x_tmp_c1 = self.pool1(F.relu(self.conv1(x[i].unsqueeze(0))))\n",
    "            x_tmp_c2 = self.pool2(F.relu(self.conv2(x_tmp_c1)))\n",
    "            x_tmp_c3 = self.pool3(F.relu(self.conv3(x_tmp_c2)))\n",
    "            x_tmp_c4 = self.pool4(F.relu(self.conv4(x_tmp_c3)))\n",
    "            x_tmp_c5 = self.pool5(F.relu(self.conv5(x_tmp_c4)))\n",
    "            x_arr[i] = torch.squeeze(x_tmp_c5)\n",
    "        #\n",
    "        x, _hidden = self.lstm(x_arr.view(TIMESTEPS,BATCH_SIZE,-1), self._hidden)\n",
    "        x = x.view(-1,LSTM_IO_SIZE)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "print(\"Class defined\")\n",
    "\n",
    "#rand_arr = np.random.rand(TIMESTEPS,RGB_CHANNELS,IMAGE_INPUT_SIZE,IMAGE_INPUT_SIZE)\n",
    "arr_1 = np.full((1,RGB_CHANNELS,IMAGE_INPUT_SIZE,IMAGE_INPUT_SIZE),0)\n",
    "arr_2 = np.full((1,RGB_CHANNELS,IMAGE_INPUT_SIZE,IMAGE_INPUT_SIZE),1)\n",
    "arr_3 = np.full((1,RGB_CHANNELS,IMAGE_INPUT_SIZE,IMAGE_INPUT_SIZE),2)\n",
    "arr_full = np.concatenate((arr_1, arr_2, arr_3, arr_1, arr_2, arr_3, arr_1, arr_2, arr_3, arr_1))\n",
    "print(\"Shape\", np.shape(arr_full))\n",
    "test_images = torch.from_numpy(arr_full)\n",
    "test_labels = torch.tensor([0,1,2,0,1,2,0,1,2,0]) #DIFFICULT\n",
    "#test_labels = torch.tensor([0,0,0,1,1,1,2,2,2,2])#EASY\n",
    "\n",
    "#TRAINING\n",
    "test_net = TEST_CNN_LSTM()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(test_net.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "\n",
    "print('Start training...')\n",
    "for epoch in range(100): \n",
    "    print(\"Epoch:\", epoch)\n",
    "    running_loss = 0.0\n",
    "    #for i in range(TIMESTEP):\n",
    "    inputs = test_images\n",
    "    labels = test_labels\n",
    "\n",
    "    optimizer.zero_grad() \n",
    "    outputs = test_net(inputs)\n",
    "    #print(\"Out:\", len(outputs), outputs)\n",
    "    #print(\"Labels:\", len(labels), labels)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward() \n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "    print(\"Loss:\", running_loss)\n",
    "print('...Training finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR TESTING PURPOSES\n",
    "test = torch.zeros(10,24,24)\n",
    "test[1] = torch.randn(24,24)\n",
    "test = test.view(10,-1)\n",
    "#concat = torch.cat([x for x in test],0)\n",
    "print(test.size())\n",
    "#print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#print(test_images[0])\n",
    "#concatenation = torch.cat((test_images, test_images))\n",
    "\n",
    "#for x in range(test_images.size(0)):\n",
    "#    concatenation = torch.cat((test_images[x]))\n",
    "#print(concatenation.size())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python gait_36",
   "language": "python",
   "name": "gait_36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
