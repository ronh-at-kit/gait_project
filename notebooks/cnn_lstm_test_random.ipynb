{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configuration needed\n",
      "Class defined\n",
      "Shape (10, 3, 228, 228)\n",
      "Start training...\n",
      "Epoch: 0\n",
      "Loss: 1.1323322057724\n",
      "Epoch: 1\n",
      "Loss: 1.1278235912322998\n",
      "Epoch: 2\n",
      "Loss: 1.120080828666687\n",
      "Epoch: 3\n",
      "Loss: 1.1121705770492554\n",
      "Epoch: 4\n",
      "Loss: 1.103941559791565\n",
      "Epoch: 5\n",
      "Loss: 1.0956740379333496\n",
      "Epoch: 6\n",
      "Loss: 1.0881673097610474\n",
      "Epoch: 7\n",
      "Loss: 1.0819135904312134\n",
      "Epoch: 8\n",
      "Loss: 1.0769630670547485\n",
      "Epoch: 9\n",
      "Loss: 1.0728566646575928\n",
      "Epoch: 10\n",
      "Loss: 1.068825602531433\n",
      "Epoch: 11\n",
      "Loss: 1.0653632879257202\n",
      "Epoch: 12\n",
      "Loss: 1.0616862773895264\n",
      "Epoch: 13\n",
      "Loss: 1.0573618412017822\n",
      "Epoch: 14\n",
      "Loss: 1.0512897968292236\n",
      "Epoch: 15\n",
      "Loss: 1.043039083480835\n",
      "Epoch: 16\n",
      "Loss: 1.0323933362960815\n",
      "Epoch: 17\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-51c5d9e6940e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;31m#     print(\"Labels:\", len(labels),labels.size() , labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gait_37/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gait_37/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"No configuration needed\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "#DESIGN PARAMETERS FOR NEURAL NETWORK\n",
    "NR_LSTM_UNITS = 2\n",
    "IMAGE_INPUT_SIZE = 228\n",
    "IMAGE_AFTER_CONV_SIZE = 5\n",
    "#for 3x3 kernels, n=num_layers: len_in = 2^n*len_out + sum[i=1..n](2^i)\n",
    "#CONV_LAYER_LENGTH = 5\n",
    "\n",
    "LSTM_IO_SIZE = IMAGE_AFTER_CONV_SIZE*IMAGE_AFTER_CONV_SIZE\n",
    "\n",
    "RGB_CHANNELS = 3\n",
    "TIMESTEPS = 10\n",
    "BATCH_SIZE = 1 #until now just batch_size = 1\n",
    "\n",
    "#USE RANDOM IMAGES TO SET UP WORKING EXAMPLE\n",
    "class TEST_CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TEST_CNN_LSTM, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,3) #input 388x388\n",
    "        self.pool1 = nn.MaxPool2d(2,2) #input 48x48 output 24x24\n",
    "        self.conv2 = nn.Conv2d(6,16,3)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        self.conv3 = nn.Conv2d(16,6,3)\n",
    "        self.pool3 = nn.MaxPool2d(2,2)\n",
    "        self.conv4 = nn.Conv2d(6,3,3)\n",
    "        self.pool4 = nn.MaxPool2d(2,2)\n",
    "        self.conv5 = nn.Conv2d(3,1,3)\n",
    "        self.pool5 = nn.MaxPool2d(2,2) #output 5x5\n",
    "        self.lstm = nn.LSTM(LSTM_IO_SIZE,\n",
    "                            LSTM_IO_SIZE,\n",
    "                            NR_LSTM_UNITS)\n",
    "        self.fc1 = nn.Linear(LSTM_IO_SIZE,120)\n",
    "        self.fc2 = nn.Linear(120,20)\n",
    "        self.fc3 = nn.Linear(20,3)\n",
    "        \n",
    "        #initialize hidden states of LSTM\n",
    "        self._hidden = (torch.randn(NR_LSTM_UNITS, BATCH_SIZE, LSTM_IO_SIZE), \n",
    "                        torch.randn(NR_LSTM_UNITS, BATCH_SIZE, LSTM_IO_SIZE))\n",
    "        #print(\"Hidden:\", _hidden)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #print(\"Input:\", x.size())\n",
    "        x = x.float() #necessary for some reason\n",
    "        x_arr = torch.zeros(TIMESTEPS,IMAGE_AFTER_CONV_SIZE,IMAGE_AFTER_CONV_SIZE)\n",
    "        #print(\"X arr size\", x_arr.size())\n",
    "        for i in range(TIMESTEPS):#parallel convolutions which are later concatenated for LSTM\n",
    "            x_tmp_c1 = self.pool1(F.relu(self.conv1(x[i].unsqueeze(0))))\n",
    "            x_tmp_c2 = self.pool2(F.relu(self.conv2(x_tmp_c1)))\n",
    "            x_tmp_c3 = self.pool3(F.relu(self.conv3(x_tmp_c2)))\n",
    "            x_tmp_c4 = self.pool4(F.relu(self.conv4(x_tmp_c3)))\n",
    "            x_tmp_c5 = self.pool5(F.relu(self.conv5(x_tmp_c4)))\n",
    "            x_arr[i] = torch.squeeze(x_tmp_c5)\n",
    "        #\n",
    "        x, _hidden = self.lstm(x_arr.view(TIMESTEPS,BATCH_SIZE,-1), self._hidden)\n",
    "        x = x.view(-1,LSTM_IO_SIZE)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "print(\"Class defined\")\n",
    "\n",
    "#rand_arr = np.random.rand(TIMESTEPS,RGB_CHANNELS,IMAGE_INPUT_SIZE,IMAGE_INPUT_SIZE)\n",
    "arr_1 = np.full((1,RGB_CHANNELS,IMAGE_INPUT_SIZE,IMAGE_INPUT_SIZE),0)\n",
    "arr_2 = np.full((1,RGB_CHANNELS,IMAGE_INPUT_SIZE,IMAGE_INPUT_SIZE),1)\n",
    "arr_3 = np.full((1,RGB_CHANNELS,IMAGE_INPUT_SIZE,IMAGE_INPUT_SIZE),2)\n",
    "arr_full = np.concatenate((arr_1, arr_2, arr_3, arr_1, arr_2, arr_3, arr_1, arr_2, arr_3, arr_1))\n",
    "print(\"Shape\", np.shape(arr_full))\n",
    "test_images = torch.from_numpy(arr_full)\n",
    "# test_labels = torch.tensor([0,1,2,0,1,2,0,1,2,0]) #DIFFICULT\n",
    "test_labels = torch.tensor([0,0,0,1,1,1,2,2,2,2])#EASY\n",
    "\n",
    "#TRAINING\n",
    "test_net = TEST_CNN_LSTM()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(test_net.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "\n",
    "print('Start training...')\n",
    "for epoch in range(50): \n",
    "    print(\"Epoch:\", epoch)\n",
    "    running_loss = 0.0\n",
    "    #for i in range(TIMESTEP):\n",
    "    inputs = test_images\n",
    "    labels = test_labels\n",
    "\n",
    "    optimizer.zero_grad() \n",
    "    outputs = test_net(inputs)\n",
    "#     print(\"Out:\", len(outputs),outputs.size(),  outputs)\n",
    "#     print(\"Labels:\", len(labels),labels.size() , labels)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward() \n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "    print(\"Loss:\", running_loss)\n",
    "print('...Training finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR TESTING PURPOSES\n",
    "test = torch.zeros(10,24,24)\n",
    "test[1] = torch.randn(24,24)\n",
    "test = test.view(10,-1)\n",
    "#concat = torch.cat([x for x in test],0)\n",
    "print(test.size())\n",
    "#print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_images)\n",
    "#\n",
    "#print(test_images[0])\n",
    "#concatenation = torch.cat((test_images, test_images))\n",
    "\n",
    "#for x in range(test_images.size(0)):\n",
    "#    concatenation = torch.cat((test_images[x]))\n",
    "#print(concatenation.size())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python gait_36",
   "language": "python",
   "name": "gait_36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
