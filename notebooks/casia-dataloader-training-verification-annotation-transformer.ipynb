{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gait_analysis import CasiaDataset, settings\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import utils\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure a dataset aggregation of input/labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the datasets and the indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configuration  default\n",
      "[OK]\n"
     ]
    }
   ],
   "source": [
    "from gait_analysis.Config import Config\n",
    "c = Config()\n",
    "c.config['indexing']['grouping'] = 'person_sequence'\n",
    "c.config['pose']['load'] = True\n",
    "c.config['flow']['load'] = True\n",
    "c.config['heatmaps']['load'] = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the dataset_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.config['dataset_output'] = {\n",
    "        'data': [\"scenes\",\"flows\",\"heatmaps\"],\n",
    "        'label': \"annotations\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.config['transformers'] = {\n",
    "        # 'Crop':{'include list':['LAnkle','RAnkle'],'output_size':256,'target':'flows'}\n",
    "        'SpanImagesList': {'remove':True, 'names': [\"heatmaps_LAnkle\",\"heatmaps_RAnkle\"],'target': [\"heatmaps\"]},\n",
    "        'Rescale': {'output_size' : (640,480), 'target': [\"heatmaps_LAnkle\",\"heatmaps_RAnkle\"]},\n",
    "        'AnnotationToLabel': {'target': [\"annotations\"]},\n",
    "        'Transpose': {'swapping': (2, 0, 1), 'target': [\"scenes\", \"flows\"]},\n",
    "#         'Transpose' : {'swapping': (2, 0, 1) , 'target': [\"scenes\"]},\n",
    "        'DimensionResize' : {'dimension': 40, 'target': [\"heatmaps_LAnkle\",\"heatmaps_RAnkle\",\"scenes\",\"flows\",\"annotations\"]},\n",
    "#         'DimensionResize' : {'dimension': 10, 'target': [\"scenes\",\"annotations\"]},\n",
    "        'ToTensor': {'target':[\"scenes\",\"annotations\"]}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plain and untransformed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_plain = CasiaDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['scenes', 'flows', 'heatmaps'])\n"
     ]
    }
   ],
   "source": [
    "item, labels = dataset_plain[1]\n",
    "scenes = item['scenes']\n",
    "flows = item['flows']\n",
    "print(item.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the composer to construct reusable transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    <gait_analysis.Transformers.SpanImagesList.SpanImagesList object at 0x7f895ca7a160>\n",
      "    <gait_analysis.Transformers.Rescale.Rescale object at 0x7f895ca7a278>\n",
      "    <gait_analysis.Transformers.AnnotationToLabel.AnnotationToLabel object at 0x7f895ca7a2b0>\n",
      "    <gait_analysis.Transformers.Transpose.Transpose object at 0x7f895ca7a2e8>\n",
      "    <gait_analysis.Transformers.DimensionResize.DimensionResize object at 0x7f895ca7a320>\n",
      "    <gait_analysis.Transformers.ToTensor.ToTensor object at 0x7f895ca7a390>\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from gait_analysis import Composer\n",
    "\n",
    "composer = Composer()\n",
    "transformer = composer.compose()\n",
    "print(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person_sequence\n"
     ]
    }
   ],
   "source": [
    "print(c.get_indexing_grouping())\n",
    "test_item, labels_df = dataset_plain[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just to test we include add a field annotations \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> transformed item is:  dict_keys(['scenes', 'flows', 'annotations', 'heatmaps_LAnkle', 'heatmaps_RAnkle'])\n"
     ]
    }
   ],
   "source": [
    "test_item['annotations'] = labels_df\n",
    "transformed_item = transformer(test_item)\n",
    "print('==> transformed item is: ',test_item.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['scenes', 'flows', 'heatmaps'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transformed_item['scenes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_id</th>\n",
       "      <th>left_foot</th>\n",
       "      <th>right_foot</th>\n",
       "      <th>combined</th>\n",
       "      <th>codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>IN_THE_AIR</td>\n",
       "      <td>ON_GROUND</td>\n",
       "      <td>IN_THE_AIRON_GROUND</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>IN_THE_AIR</td>\n",
       "      <td>ON_GROUND</td>\n",
       "      <td>IN_THE_AIRON_GROUND</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>IN_THE_AIR</td>\n",
       "      <td>ON_GROUND</td>\n",
       "      <td>IN_THE_AIRON_GROUND</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>IN_THE_AIR</td>\n",
       "      <td>ON_GROUND</td>\n",
       "      <td>IN_THE_AIRON_GROUND</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>IN_THE_AIR</td>\n",
       "      <td>ON_GROUND</td>\n",
       "      <td>IN_THE_AIRON_GROUND</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>IN_THE_AIR</td>\n",
       "      <td>ON_GROUND</td>\n",
       "      <td>IN_THE_AIRON_GROUND</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>ON_GROUND</td>\n",
       "      <td>ON_GROUND</td>\n",
       "      <td>ON_GROUNDON_GROUND</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>ON_GROUND</td>\n",
       "      <td>ON_GROUND</td>\n",
       "      <td>ON_GROUNDON_GROUND</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>ON_GROUND</td>\n",
       "      <td>ON_GROUND</td>\n",
       "      <td>ON_GROUNDON_GROUND</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>ON_GROUND</td>\n",
       "      <td>IN_THE_AIR</td>\n",
       "      <td>ON_GROUNDIN_THE_AIR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    frame_id   left_foot  right_foot             combined  codes\n",
       "30        30  IN_THE_AIR   ON_GROUND  IN_THE_AIRON_GROUND      0\n",
       "31        31  IN_THE_AIR   ON_GROUND  IN_THE_AIRON_GROUND      0\n",
       "32        32  IN_THE_AIR   ON_GROUND  IN_THE_AIRON_GROUND      0\n",
       "33        33  IN_THE_AIR   ON_GROUND  IN_THE_AIRON_GROUND      0\n",
       "34        34  IN_THE_AIR   ON_GROUND  IN_THE_AIRON_GROUND      0\n",
       "35        35  IN_THE_AIR   ON_GROUND  IN_THE_AIRON_GROUND      0\n",
       "36        36   ON_GROUND   ON_GROUND   ON_GROUNDON_GROUND      2\n",
       "37        37   ON_GROUND   ON_GROUND   ON_GROUNDON_GROUND      2\n",
       "38        38   ON_GROUND   ON_GROUND   ON_GROUNDON_GROUND      2\n",
       "39        39   ON_GROUND  IN_THE_AIR  ON_GROUNDIN_THE_AIR      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the transformer and the dataset_output specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing some samples of the transformed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:  0\n",
      "0 dict_keys(['scenes', 'flows', 'heatmaps_LAnkle', 'heatmaps_RAnkle'])\n",
      "torch.Size([40])\n",
      "i:  1\n",
      "1 dict_keys(['scenes', 'flows', 'heatmaps_LAnkle', 'heatmaps_RAnkle'])\n",
      "torch.Size([40])\n",
      "i:  2\n",
      "2 dict_keys(['scenes', 'flows', 'heatmaps_LAnkle', 'heatmaps_RAnkle'])\n",
      "torch.Size([40])\n",
      "i:  3\n",
      "3 dict_keys(['scenes', 'flows', 'heatmaps_LAnkle', 'heatmaps_RAnkle'])\n",
      "torch.Size([40])\n",
      "i:  4\n",
      "4 dict_keys(['scenes', 'flows', 'heatmaps_LAnkle', 'heatmaps_RAnkle'])\n",
      "torch.Size([40])\n",
      "i:  5\n",
      "5 dict_keys(['scenes', 'flows', 'heatmaps_LAnkle', 'heatmaps_RAnkle'])\n",
      "torch.Size([40])\n"
     ]
    }
   ],
   "source": [
    "c.config['dataset_output'] = {\n",
    "        'data': [\"scenes\",\"flows\",\"heatmaps_LAnkle\",\"heatmaps_RAnkle\"],\n",
    "        'label': \"annotations\"}\n",
    "transformed_dataset = CasiaDataset(transform=transformer)\n",
    "\n",
    "for i in range(len(transformed_dataset)):\n",
    "    print('i: ', i)\n",
    "    sample, labels = transformed_dataset[i]\n",
    "\n",
    "    print(i, sample.keys())\n",
    "    print(labels.size())\n",
    "\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader: using the transformed dataset with the transformer to create a training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader = DataLoader(transformed_dataset, batch_size=4,\n",
    "#                         shuffle=True, num_workers=4)\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DEV: The problem is that the dimensions of the label are different for some of the videos. In this case the aggregation works for all the angles in the video but no arbitrary batch_size will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_flows(inputs):\n",
    "    flows = inputs['flows']\n",
    "    print('plotting sample flow chunck')\n",
    "    flow = flows[4]\n",
    "    batch_size = flow.size(0)\n",
    "    im_size = flow.size()\n",
    "    print('im_size = ', im_size)\n",
    "    print('batch_size = ', batch_size )\n",
    "    grid = utils.make_grid(flow)\n",
    "    plt.figure(figsize=(10,50))\n",
    "    plt.imshow(grid.numpy()[2,:,:])\n",
    "    plt.show()\n",
    "    \n",
    "def plot_scenes(inputs):\n",
    "    scenes = inputs['scenes']\n",
    "    print('plotting sample scene chunck')\n",
    "    scene = scenes[4]\n",
    "    grid = utils.make_grid(scene)\n",
    "    plt.figure(figsize=(10,50))\n",
    "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_heatmap(inputs):\n",
    "    hmaps = inputs['heatmaps_LAnkle']\n",
    "    print('plotting sample heatmasp chunck')\n",
    "    hmap = hmaps[4].numpy()\n",
    "    print('hmap.shape = ',hmap.shape)\n",
    "    plt.figure(figsize=(10,50))\n",
    "    plt.subplot(151)\n",
    "    plt.imshow(hmap[1,:,:])\n",
    "    plt.subplot(152)\n",
    "    plt.imshow(hmap[2,:,:])\n",
    "    plt.subplot(153)\n",
    "    plt.imshow(hmap[3,:,:])\n",
    "    plt.subplot(154)\n",
    "    plt.imshow(hmap[4,:,:])\n",
    "    plt.subplot(155)\n",
    "    plt.imshow(hmap[5,:,:])\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    # observe 4th batch and stop.\n",
    "    if i_batch == 9:\n",
    "        inputs, labels = sample_batched\n",
    "        plot_flows(inputs)\n",
    "        plot_scenes(inputs)\n",
    "        plot_heatmap(inputs)\n",
    "        print(type(sample_batched))\n",
    "        print('labels,',labels.size(),labels)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 400, 400)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.eye(400)\n",
    "\n",
    "a.resize((1,400,400))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f68e25005952>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformed_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/Datasets/Gait/Repositories/gait_project/gait_analysis/DataSets/CasiaDataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# annotations are always in the output:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mannotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_frame_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annotations'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# adding all other optional features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/Datasets/Gait/Repositories/gait_project/gait_analysis/DataSets/AnnotationsCasia.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mannotation\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mDataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         '''\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mdataset_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mgrouping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexing_grouping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "i,l = transformed_dataset[42]\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python gait_37",
   "language": "python",
   "name": "gait_37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
