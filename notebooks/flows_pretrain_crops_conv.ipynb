{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Settings.py should be e.g. cnn_flows_prtrain\")\n",
    "#DESIGN PARAMETERS FOR NEURAL NETWORK\n",
    "\n",
    "VALIDATION_SPLIT = 0.2 #indicated ratio of training to validation data: 0.2 -> 20% VALIDATION data\n",
    "RANDOMIZED_SEED = 20\n",
    "SHUFFLE_DATASET = False\n",
    "\n",
    "TRAINING_PREPARATION = False\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "TIME_STEPS = 40\n",
    "\n",
    "NR_EPOCHS = 50\n",
    "\n",
    "LR = 0.001\n",
    "# MOMENTUM = 0.9\n",
    "print(\"Hyperparameters defined\")\n",
    "print(\"Bug with learning rate when sequence length is not the same for each element of the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import os.path as path\n",
    "import copy\n",
    "\n",
    "from gait_analysis import AnnotationsCasia as Annotations\n",
    "from gait_analysis import CasiaDataset\n",
    "from gait_analysis.Config import Config\n",
    "from gait_analysis import Composer\n",
    "from gait_analysis import WeightWatcher\n",
    "from gait_analysis import AccuracyTracker\n",
    "from gait_analysis import AccuracyTrackerTrainTest\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gait_analysis.Models import PretrainConvFlow\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change configuration in settings.py\n",
    "c = Config()\n",
    "c.config['indexing']['grouping'] = 'person_sequence_angle'\n",
    "composer = Composer()\n",
    "transformer = composer.compose()\n",
    "dataset = CasiaDataset(transform=transformer)\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "print(\"Dataset size:\", len(dataset))\n",
    "print(\"Indices size:\", len(indices))\n",
    "split = int(np.floor(VALIDATION_SPLIT * dataset_size))\n",
    "print(\"Split:\", split)\n",
    "if SHUFFLE_DATASET:\n",
    "    np.random.seed(RANDOMIZED_SEED)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "train_sampler = torch.utils.data.SequentialSampler(train_indices)\n",
    "test_sampler = torch.utils.data.SequentialSampler(test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=1, sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PretrainConvFlow.PretrainConvFlow()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=LR)\n",
    "\n",
    "learning_rate_array = []\n",
    "loss_array = []\n",
    "# monitor = WeightWatcher(net,['conv5','fc1'])\n",
    "tt_acc_tracker = AccuracyTrackerTrainTest([0,1,2])\n",
    "# test_acc_tracker = AccuracyTracker([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if TRAINING_PREPARATION:\n",
    "#     print('Start training...')\n",
    "#     print(\"Expected loss with {} different classes and {} data elements: {}\".format(3, len(dataset)-split, (len(dataset)-split)*np.log(3)))\n",
    "#     running_loss = 0.0\n",
    "#     print(\"Batch size:\", BATCH_SIZE)\n",
    "#     print(\"Evaluating first element...\")\n",
    "#     start_time = time.time()\n",
    "#     i, batch = next(iter(enumerate(train_loader)))\n",
    "#     inputs, labels = batch\n",
    "#     #TODO make list disappear\n",
    "\n",
    "#     data_in_list = [s.to(device) for s in inputs['flows']]\n",
    "#     labels = labels.to(device)\n",
    "\n",
    "#     print(\"--------------------------\\nOriginal input:\")\n",
    "#     print(\"Data in: List length\", len(data_in_list), \"List element:\", data_in_list[0].size())\n",
    "#     print(\"Labels:\", labels.size())\n",
    "#     print(\"--------------------------\\nSingle element:\")\n",
    "#     data_element = data_in_list[0]\n",
    "#     label_element = labels[:,0].long()\n",
    "#     print(\"Data element:\", data_element.size())\n",
    "#     print(\"Label element:\", label_element.size())\n",
    "\n",
    "#     optimizer.zero_grad() \n",
    "#     output_element = net(data_element)\n",
    "\n",
    "#     loss = criterion(output_element,label_element)\n",
    "#     loss.backward() \n",
    "#     optimizer.step()\n",
    "\n",
    "#     running_loss += loss.data.item()\n",
    "#     elapsed_time = time.time() - start_time;\n",
    "#     print(\"Loss:{}, expected loss:{}\".format(running_loss, np.log(3)))\n",
    "#     print(\"Time needed:{}s\".format(elapsed_time))\n",
    "#     print(\"Expected loss for total training data: \", (len(dataset)-split)*np.log(3))\n",
    "#     print(\"Expected training time per epoch:{} min\".format(elapsed_time* len(train_loader)*TIME_STEPS/BATCH_SIZE/60))\n",
    "#     print(\"Estimated total training time:{} hours\".format(elapsed_time* len(train_loader)*TIME_STEPS/BATCH_SIZE*NR_EPOCHS/3600))\n",
    "# print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start training...\")\n",
    "for epoch in range(NR_EPOCHS): \n",
    "    start_time = time.time()\n",
    "#     print(\"Epoch:\", epoch)\n",
    "    running_loss = 0.0\n",
    "    running_test_loss = 0.0\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        inputs, labels = batch\n",
    "        data_in_list = [s.to(device) for s in inputs['flows']]\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "#         print(\"--------------------------\\nOriginal input:\")\n",
    "#         print(\"Data in: List length\", len(data_in_list), \"List element:\", data_in_list[0].size())\n",
    "#         print(\"Labels:\", labels.size())\n",
    "\n",
    "        for j, data_element in enumerate(data_in_list):\n",
    "            if (labels.size(1) != len(data_in_list)):\n",
    "                print(\"WARNING, labels and data_element length do not match in Set\",i, \"element\", j)\n",
    "#                 print(\"Label element after\")\n",
    "#                 print(labels[0:len(data_in_list),j].size())\n",
    "#                 print(labels.size(),len(data_in_list))\n",
    "            label_element = labels[0:len(data_in_list),j].long()\n",
    "#             print(\"--------------------------\\nSingle element:\")\n",
    "#             print(\"Data element size:\", data_element.size())\n",
    "#             print(\"Label element size:\", label_element.size())\n",
    "#             print(\"Data element\", data_element)\n",
    "#             print(\"Label element\", label_element)\n",
    "#             print(\"Label element after\",label_element)\n",
    "\n",
    "#             print(\"Data element\", data_element[0][0])\n",
    "    \n",
    "            optimizer.zero_grad() \n",
    "            output_element = net(data_element)\n",
    "#             print(\"Output element\",output_element)\n",
    "#             print(\"Label element after\",label_element)\n",
    "            loss = criterion(output_element,label_element)\n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.data.item()/(len(dataset)*(1-VALIDATION_SPLIT))/TIME_STEPS*BATCH_SIZE\n",
    "#             print(\"losses:\",loss.data.item(),len(dataset),TIMESTEPS)\n",
    "#             print(\"Prediction:\", torch.max(output_element,1)[1])\n",
    "#             print(\"Labels:\", label_element.long())\n",
    "            prediction = torch.max(output_element,1)[1]\n",
    "            tt_acc_tracker.update_acc(prediction,label_element,\"TRAIN\")\n",
    "        \n",
    "    #TEST SET\n",
    "    for i,batch in enumerate(test_loader):\n",
    "        inputs, labels = batch\n",
    "        data_in_list = [s.to(device) for s in inputs['flows']]\n",
    "        labels = labels.to(device)\n",
    "        for j, data_element in enumerate(data_in_list):\n",
    "            if (labels.size(1) != len(data_in_list)):\n",
    "                print(\"WARNING, labels and data_element length do not match in TEST Set\",i, \"element\", j)\n",
    "#                 print(labels[0:len(data_in_list),j].size())\n",
    "            label_element = labels[0:len(data_in_list),j].long()\n",
    "\n",
    "            output_element = net(data_element)\n",
    "            test_loss = criterion(output_element,label_element)\n",
    "            running_test_loss += loss.data.item()/(len(dataset)*VALIDATION_SPLIT)/TIME_STEPS\n",
    "\n",
    "            prediction = torch.max(output_element,1)[1]\n",
    "            tt_acc_tracker.update_acc(prediction,label_element,\"TEST\")\n",
    "        \n",
    "            \n",
    "    print(\"-----------------------------\")\n",
    "    print(\"Training set:\")\n",
    "    print(\"Epoch {}: Loss [{},{}], Acc [{},{}] took {}s\".format(epoch, running_loss,running_test_loss,tt_acc_tracker.get_acc_tot(\"TRAIN\"),tt_acc_tracker.get_acc_tot(\"TEST\"), np.around(time.time()-start_time,decimals=2)))\n",
    "    print(\"Accuracy by class [{},{}] Total elements: [{},{}]\".format(tt_acc_tracker.get_acc(\"TRAIN\"),tt_acc_tracker.get_acc(\"TEST\"), tt_acc_tracker.get_labels_distribution(\"TRAIN\"),tt_acc_tracker.get_labels_distribution(\"TEST\")))\n",
    "\n",
    "    tt_acc_tracker.update_graph()\n",
    "    tt_acc_tracker.reset_acc_both()\n",
    "    tt_acc_tracker.update_loss(running_loss)\n",
    "    tt_acc_tracker.update_lr(LR)\n",
    "    \n",
    "\n",
    "    \n",
    "#     monitor.update_weights(net,['conv5','fc1'])\n",
    "\n",
    "#test_all_preds(test_net) \n",
    "print('...Training finished')\n",
    "# plt.plot(loss_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_EPOCHS = 10\n",
    "LR = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(39,40):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net.state_dict(), '/mnt/DATA/HIWI/IBT/saved_models/PretrainConvFlow/001_all_seq_ts40_test.pt')\n",
    "# acc_tracker.write_to_csv('/mnt/DATA/HIWI/IBT/saved_models/PretrainConvFlow/001_all_seq_ts40_test/')\n",
    "# Later:\n",
    "# loaded_model = PretrainConvFlow.PretrainConvFlow()\n",
    "# loaded_model.load_state_dict(torch.load('/mnt/DATA/HIWI/IBT/saved_models/PretrainConvFlow/first_draft'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# path = '/mnt/DATA/HIWI/IBT/saved_models/PretrainConvFlow/001_all_seq_ts40/'\n",
    "# with open(path + \"acc_tot.csv\", 'w') as file:\n",
    "#     wr = csv.writer(file)\n",
    "#     wr.writerow(acc_tracker.get_acc_tot_graph())\n",
    "# with open(path + \"loss.csv\", 'w') as file:\n",
    "#     wr = csv.writer(file)\n",
    "#     wr.writerow(acc_tracker.get_loss_graph())\n",
    "# with open(path + \"lr.csv\", 'w') as file:\n",
    "#     wr = csv.writer(file)\n",
    "#     wr.writerow(acc_tracker.get_lr_graph())\n",
    "# acc = acc_tracker.get_acc_graph()\n",
    "# for i in range(len(acc)):\n",
    "#     with open(path + \"acc\" + str(i) + \".csv\", 'w') as file:\n",
    "#         wr = csv.writer(file)\n",
    "#         wr.writerow(acc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_flows_pretrain = {\n",
    "#     'indexing':{\n",
    "#         #'grouping': 'person_sequence_angle',\n",
    "#         'selection': 'manual_people_sequence',     #  => 'auto'= by final annotation or\n",
    "#                                  #  => 'manual_people' = uses 'people' list\n",
    "#                                  #  => 'manual_people_sequence' uses combination of two lists 'people' and 'sequences'\n",
    "#         'people_selection': [1],\n",
    "#         # 'sequences_selection': ['nm-01']\n",
    "#         'sequences_selection': ['bg-01','bg-02','cl-01','cl-02','nm-01','nm-02','nm-03','nm-04','nm-05','nm-06']\n",
    "#         },\n",
    "#     'pose': {\n",
    "#         'load': False,\n",
    "#         'preprocess': False,\n",
    "#         'D': 2 ,\n",
    "#         # the complete list is:\n",
    "#         #'body_keypoints_include_list': ['LAnkle' , 'RAnkle' , 'LKnee' , 'RKnee' , 'RHip' , 'LHip' , 'RBigToe' ,\n",
    "#         #                                'LBigToe' , 'RSmallToe' , 'LSmallToe' , 'RHeel' , 'LHeel']\n",
    "#         'body_keypoints_include_list': ['LAnkle','RAnkle','LKnee','RKnee','RHip','LHip']\n",
    "#         },\n",
    "#     'flow': {\n",
    "#         'load':True,\n",
    "#         'preprocess' : True,\n",
    "#         'crops': True,\n",
    "#         'method' : 'dense',\n",
    "#         'load_patches' : True,\n",
    "#         'patch_size' : 5\n",
    "#         },\n",
    "#     'scenes':{\n",
    "#         'load':False,\n",
    "#         'preprocess': False,\n",
    "#         'crops' : False,\n",
    "#         'gray_scale' : False,\n",
    "#         'load_tracked' : False,\n",
    "#         'sequences': ['nm'],\n",
    "#         'angles': [90]\n",
    "#     },\n",
    "#     'heatmaps':{\n",
    "#         'load':False,\n",
    "#         'preprocess': False,\n",
    "#         'body_keypoints_include_list' : ['LAnkle','RAnkle']\n",
    "#     },\n",
    "#     'dataset_output' : {\n",
    "#         'data': [\"flows\"],\n",
    "#         'label': \"annotations\"\n",
    "#     },\n",
    "#     'transformers':{\n",
    "#         # 'Crop':{'include list':['LAnkle','RAnkle'],'output_size':256,'target':'flows'}\n",
    "#         # 'SpanImagesList': {'remove':True, 'names': [\"heatmaps_LAnkle\",\"heatmaps_RAnkle\"],'target': [\"heatmaps\"]},\n",
    "#         # 'Rescale': {'output_size' : (640,480), 'target': [\"flows\"]},\n",
    "#         'AnnotationToLabel': {'target': [\"annotations\"]},\n",
    "#         'Transpose' : {'swapping': (2, 0, 1) , 'target': [\"flows\"]},\n",
    "#         'Normalize': {'target': [\"flows\"]},\n",
    "#         'DimensionResize' : {'start': 5, 'dimension': 40, 'target': [\"flows\",\"annotations\"],'annotations_offset': 1},\n",
    "#         'ToTensor': {'target':[\"flows\",\"annotations\"]}\n",
    "#     }\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python gait_36",
   "language": "python",
   "name": "gait_36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
