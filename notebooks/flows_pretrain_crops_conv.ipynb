{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings.py should be e.g. cnn_flows_prtrain\n",
      "Hyperparameters defined\n",
      "Bug with learning rate when sequence length is not the same for each element of the dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings.py should be e.g. cnn_flows_prtrain\")\n",
    "#DESIGN PARAMETERS FOR NEURAL NETWORK\n",
    "\n",
    "VALIDATION_SPLIT = 0.2 #indicated ratio of training to validation data: 0.2 -> 20% VALIDATION data\n",
    "RANDOMIZED_SEED = 20\n",
    "SHUFFLE_DATASET = False\n",
    "\n",
    "TRAINING_PREPARATION = False\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "TIME_STEPS = 40\n",
    "\n",
    "NR_EPOCHS = 20\n",
    "\n",
    "LR = 0.001\n",
    "# MOMENTUM = 0.9\n",
    "print(\"Hyperparameters defined\")\n",
    "print(\"Bug with learning rate when sequence length is not the same for each element of the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import os.path as path\n",
    "import copy\n",
    "\n",
    "from gait_analysis import AnnotationsCasia as Annotations\n",
    "from gait_analysis import CasiaDataset\n",
    "from gait_analysis.Config import Config\n",
    "from gait_analysis import Composer\n",
    "from gait_analysis import WeightWatcher\n",
    "from gait_analysis import AccuracyTracker\n",
    "from gait_analysis import AccuracyTrackerTrainTest\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gait_analysis.Models import PretrainConvFlow\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configuration  cnn_flows_pretrain\n",
      "[OK]\n",
      "Dataset size: 595\n",
      "Indices size: 595\n",
      "Split: 119\n"
     ]
    }
   ],
   "source": [
    "#change configuration in settings.py\n",
    "c = Config()\n",
    "c.config['indexing']['grouping'] = 'person_sequence_angle'\n",
    "composer = Composer()\n",
    "transformer = composer.compose()\n",
    "dataset = CasiaDataset(transform=transformer)\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "print(\"Dataset size:\", len(dataset))\n",
    "print(\"Indices size:\", len(indices))\n",
    "split = int(np.floor(VALIDATION_SPLIT * dataset_size))\n",
    "print(\"Split:\", split)\n",
    "if SHUFFLE_DATASET:\n",
    "    np.random.seed(RANDOMIZED_SEED)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "train_sampler = torch.utils.data.SequentialSampler(train_indices)\n",
    "test_sampler = torch.utils.data.SequentialSampler(test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=1, sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "net = PretrainConvFlow.PretrainConvFlow()\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=LR)\n",
    "\n",
    "# monitor = WeightWatcher(net,['conv5','fc1'])\n",
    "tt_acc_tracker = AccuracyTrackerTrainTest([0,1,2])\n",
    "# test_acc_tracker = AccuracyTracker([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if TRAINING_PREPARATION:\n",
    "#     print('Start training...')\n",
    "#     print(\"Expected loss with {} different classes and {} data elements: {}\".format(3, len(dataset)-split, (len(dataset)-split)*np.log(3)))\n",
    "#     running_loss = 0.0\n",
    "#     print(\"Batch size:\", BATCH_SIZE)\n",
    "#     print(\"Evaluating first element...\")\n",
    "#     start_time = time.time()\n",
    "#     i, batch = next(iter(enumerate(train_loader)))\n",
    "#     inputs, labels = batch\n",
    "#     #TODO make list disappear\n",
    "\n",
    "#     data_in_list = [s.to(device) for s in inputs['flows']]\n",
    "#     labels = labels.to(device)\n",
    "\n",
    "#     print(\"--------------------------\\nOriginal input:\")\n",
    "#     print(\"Data in: List length\", len(data_in_list), \"List element:\", data_in_list[0].size())\n",
    "#     print(\"Labels:\", labels.size())\n",
    "#     print(\"--------------------------\\nSingle element:\")\n",
    "#     data_element = data_in_list[0]\n",
    "#     label_element = labels[:,0].long()\n",
    "#     print(\"Data element:\", data_element.size())\n",
    "#     print(\"Label element:\", label_element.size())\n",
    "\n",
    "#     optimizer.zero_grad() \n",
    "#     output_element = net(data_element)\n",
    "\n",
    "#     loss = criterion(output_element,label_element)\n",
    "#     loss.backward() \n",
    "#     optimizer.step()\n",
    "\n",
    "#     running_loss += loss.data.item()\n",
    "#     elapsed_time = time.time() - start_time;\n",
    "#     print(\"Loss:{}, expected loss:{}\".format(running_loss, np.log(3)))\n",
    "#     print(\"Time needed:{}s\".format(elapsed_time))\n",
    "#     print(\"Expected loss for total training data: \", (len(dataset)-split)*np.log(3))\n",
    "#     print(\"Expected training time per epoch:{} min\".format(elapsed_time* len(train_loader)*TIME_STEPS/BATCH_SIZE/60))\n",
    "#     print(\"Estimated total training time:{} hours\".format(elapsed_time* len(train_loader)*TIME_STEPS/BATCH_SIZE*NR_EPOCHS/3600))\n",
    "# print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 0: Loss [0.08984521269903938,0.03708196431398347], Acc [0.963,0.946] took 83.47s\n",
      "Accuracy by class [[0.979, 0.953, 0.958],[0.943, 0.955, 0.94]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 1: Loss [0.08604935000918633,0.17853589355946903], Acc [0.964,0.943] took 83.44s\n",
      "Accuracy by class [[0.977, 0.956, 0.961],[0.972, 0.931, 0.929]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 2: Loss [0.08478246377974243,0.002352510113268982], Acc [0.964,0.953] took 83.46s\n",
      "Accuracy by class [[0.976, 0.952, 0.963],[0.968, 0.953, 0.94]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 3: Loss [0.08869284372952835,0.04651524871588167], Acc [0.964,0.947] took 83.36s\n",
      "Accuracy by class [[0.978, 0.953, 0.962],[0.972, 0.938, 0.933]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 4: Loss [0.08523551411799565,0.018601480871441124], Acc [0.964,0.939] took 83.45s\n",
      "Accuracy by class [[0.975, 0.954, 0.965],[0.96, 0.945, 0.917]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 5: Loss [0.08136848727663774,0.04283406957984012], Acc [0.966,0.929] took 83.65s\n",
      "Accuracy by class [[0.978, 0.955, 0.965],[0.966, 0.876, 0.949]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 6: Loss [0.0831852326964951,0.06548152863978485], Acc [0.966,0.936] took 83.74s\n",
      "Accuracy by class [[0.977, 0.953, 0.967],[0.923, 0.951, 0.932]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 7: Loss [0.08135846069955979,0.011727665551006041], Acc [0.967,0.951] took 83.3s\n",
      "Accuracy by class [[0.977, 0.957, 0.968],[0.965, 0.96, 0.93]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 8: Loss [0.10451192072985938,0.10456234961747936], Acc [0.962,0.949] took 83.77s\n",
      "Accuracy by class [[0.971, 0.952, 0.963],[0.953, 0.95, 0.943]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 9: Loss [0.07598323192045835,0.008676742203533414], Acc [0.968,0.95] took 83.42s\n",
      "Accuracy by class [[0.977, 0.959, 0.969],[0.968, 0.947, 0.938]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 10: Loss [0.08043131955856861,0.02074479125439992], Acc [0.968,0.953] took 83.41s\n",
      "Accuracy by class [[0.978, 0.959, 0.967],[0.948, 0.957, 0.954]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 11: Loss [0.07799077412140942,0.0820001289248438], Acc [0.968,0.955] took 83.63s\n",
      "Accuracy by class [[0.976, 0.96, 0.968],[0.975, 0.957, 0.935]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 12: Loss [0.08162285854312112,0.022105915471910983], Acc [0.965,0.96] took 83.3s\n",
      "Accuracy by class [[0.976, 0.955, 0.966],[0.976, 0.953, 0.952]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 13: Loss [0.08675053078150997,0.05158997327089556], Acc [0.966,0.936] took 82.51s\n",
      "Accuracy by class [[0.974, 0.955, 0.968],[0.96, 0.965, 0.889]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 14: Loss [0.07523321371628,0.07420884072780976], Acc [0.97,0.958] took 82.3s\n",
      "Accuracy by class [[0.976, 0.962, 0.972],[0.977, 0.96, 0.94]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 15: Loss [0.08547609571999464,0.39275768399239774], Acc [0.966,0.941] took 82.1s\n",
      "Accuracy by class [[0.974, 0.958, 0.967],[0.96, 0.938, 0.929]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 16: Loss [0.07599420515593416,0.00738895777612868], Acc [0.97,0.95] took 82.17s\n",
      "Accuracy by class [[0.978, 0.961, 0.97],[0.944, 0.953, 0.953]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 17: Loss [0.07533269777085469,0.04922797158360078], Acc [0.969,0.954] took 82.13s\n",
      "Accuracy by class [[0.976, 0.96, 0.97],[0.955, 0.958, 0.949]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 18: Loss [0.07763701249551713,0.010378395207226054], Acc [0.968,0.955] took 82.73s\n",
      "Accuracy by class [[0.976, 0.959, 0.969],[0.956, 0.946, 0.963]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 19: Loss [0.0870845713755389,0.1744265109300691], Acc [0.965,0.949] took 85.39s\n",
      "Accuracy by class [[0.974, 0.957, 0.966],[0.957, 0.95, 0.941]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 20: Loss [0.07245919684969483,0.009206356480717303], Acc [0.972,0.953] took 109.92s\n",
      "Accuracy by class [[0.978, 0.964, 0.974],[0.938, 0.964, 0.957]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 21: Loss [0.06532874503622936,0.0006125569343566283], Acc [0.973,0.956] took 109.74s\n",
      "Accuracy by class [[0.98, 0.964, 0.975],[0.958, 0.956, 0.955]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 22: Loss [0.06533587319226619,0.006516984663904177], Acc [0.973,0.953] took 109.99s\n",
      "Accuracy by class [[0.98, 0.965, 0.976],[0.952, 0.951, 0.956]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 23: Loss [0.07272550002187525,0.002373295137658905], Acc [0.97,0.946] took 109.86s\n",
      "Accuracy by class [[0.976, 0.961, 0.973],[0.93, 0.972, 0.937]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 24: Loss [0.07883237677415,0.021094337105750673], Acc [0.969,0.952] took 109.73s\n",
      "Accuracy by class [[0.974, 0.961, 0.972],[0.974, 0.955, 0.93]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 25: Loss [0.07706710360655683,0.019842360168694652], Acc [0.969,0.95] took 109.65s\n",
      "Accuracy by class [[0.976, 0.961, 0.97],[0.94, 0.952, 0.957]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 26: Loss [0.06719920648491776,0.039306130260226405], Acc [0.974,0.95] took 109.83s\n",
      "Accuracy by class [[0.979, 0.965, 0.978],[0.947, 0.952, 0.951]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 27: Loss [0.0755924773022939,0.000732949818484495], Acc [0.97,0.964] took 110.01s\n",
      "Accuracy by class [[0.974, 0.962, 0.973],[0.968, 0.97, 0.956]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 28: Loss [0.07159645232296663,0.011729649268091169], Acc [0.972,0.967] took 110.02s\n",
      "Accuracy by class [[0.976, 0.966, 0.975],[0.966, 0.964, 0.97]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 29: Loss [0.07005204156243158,0.06897710263729372], Acc [0.973,0.963] took 109.72s\n",
      "Accuracy by class [[0.98, 0.965, 0.974],[0.975, 0.962, 0.954]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 30: Loss [0.07352590268671497,0.01217067241668609], Acc [0.971,0.965] took 109.89s\n",
      "Accuracy by class [[0.977, 0.961, 0.974],[0.974, 0.965, 0.957]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 31: Loss [0.060493602749217536,0.008097426965831945], Acc [0.976,0.971] took 110.08s\n",
      "Accuracy by class [[0.978, 0.97, 0.979],[0.979, 0.96, 0.974]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 32: Loss [0.06363421950842449,0.004035387653857656], Acc [0.973,0.97] took 109.75s\n",
      "Accuracy by class [[0.977, 0.967, 0.975],[0.985, 0.969, 0.958]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 33: Loss [0.06314575416397919,0.0013742191949859762], Acc [0.976,0.957] took 110.23s\n",
      "Accuracy by class [[0.981, 0.971, 0.977],[0.954, 0.969, 0.949]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 34: Loss [0.0690384985549873,0.027349872514607635], Acc [0.973,0.942] took 110.37s\n",
      "Accuracy by class [[0.979, 0.964, 0.976],[0.902, 0.962, 0.959]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 35: Loss [0.0726370060290092,0.046003691852095685], Acc [0.971,0.945] took 110.25s\n",
      "Accuracy by class [[0.978, 0.965, 0.971],[0.943, 0.956, 0.937]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 36: Loss [0.07274618274449107,0.21086494624613508], Acc [0.972,0.954] took 110.38s\n",
      "Accuracy by class [[0.977, 0.965, 0.973],[0.955, 0.945, 0.96]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 37: Loss [0.07045108264306278,0.0002354213211219868], Acc [0.973,0.955] took 109.66s\n",
      "Accuracy by class [[0.978, 0.965, 0.977],[0.966, 0.966, 0.936]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 38: Loss [0.05525068095679781,0.007333878893404559], Acc [0.979,0.966] took 110.12s\n",
      "Accuracy by class [[0.983, 0.971, 0.982],[0.964, 0.969, 0.965]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 39: Loss [0.0644004787963095,0.15188430249691912], Acc [0.976,0.95] took 110.42s\n",
      "Accuracy by class [[0.98, 0.969, 0.979],[0.934, 0.965, 0.949]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 40: Loss [0.06822996767670184,0.10496487468480017], Acc [0.973,0.943] took 110.12s\n",
      "Accuracy by class [[0.978, 0.965, 0.976],[0.925, 0.955, 0.947]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 41: Loss [0.06459006739304868,0.0002718567848205389], Acc [0.974,0.96] took 109.66s\n",
      "Accuracy by class [[0.979, 0.968, 0.976],[0.973, 0.972, 0.939]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 42: Loss [0.05859871230942123,7.915496826172039e-05], Acc [0.977,0.972] took 109.71s\n",
      "Accuracy by class [[0.983, 0.97, 0.977],[0.979, 0.967, 0.971]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 43: Loss [0.06209794311430069,0.049992017447948456], Acc [0.978,0.926] took 109.87s\n",
      "Accuracy by class [[0.982, 0.971, 0.981],[0.917, 0.95, 0.91]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 44: Loss [0.08645074894385693,0.0013371706008909912], Acc [0.968,0.965] took 110.19s\n",
      "Accuracy by class [[0.973, 0.962, 0.97],[0.981, 0.948, 0.968]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 45: Loss [0.0580772332150094,0.00013503005902747823], Acc [0.977,0.963] took 109.75s\n",
      "Accuracy by class [[0.982, 0.968, 0.98],[0.97, 0.96, 0.96]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 46: Loss [0.0569409571041762,0.0002673396083991777], Acc [0.978,0.967] took 110.05s\n",
      "Accuracy by class [[0.982, 0.971, 0.981],[0.966, 0.96, 0.974]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 47: Loss [0.05276390219952202,0.0004061545769218703], Acc [0.98,0.974] took 110.13s\n",
      "Accuracy by class [[0.985, 0.971, 0.983],[0.98, 0.966, 0.977]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 48: Loss [0.07861149411985041,0.22642210125925066], Acc [0.971,0.964] took 110.21s\n",
      "Accuracy by class [[0.975, 0.964, 0.973],[0.966, 0.955, 0.97]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "-----------------------------\n",
      "Training set:\n",
      "Epoch 49: Loss [0.06516861846450885,0.10856582969426329], Acc [0.975,0.96] took 109.65s\n",
      "Accuracy by class [[0.979, 0.967, 0.978],[0.952, 0.97, 0.958]] Total elements: [[6066, 6090, 6884],[1460, 1591, 1709]]\n",
      "...Training finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training...\")\n",
    "for epoch in range(NR_EPOCHS): \n",
    "    start_time = time.time()\n",
    "#     print(\"Epoch:\", epoch)\n",
    "    running_loss = 0.0\n",
    "    running_test_loss = 0.0\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        inputs, labels = batch\n",
    "        data_in_list = [s.to(device) for s in inputs['flows']]\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "#         print(\"--------------------------\\nOriginal input:\")\n",
    "#         print(\"Data in: List length\", len(data_in_list), \"List element:\", data_in_list[0].size())\n",
    "#         print(\"Labels:\", labels.size())\n",
    "#         if (labels.size(1) != len(data_in_list)):\n",
    "#                 print(\"WARNING:\",labels.size(),len(data_in_list))\n",
    "        for j, data_element in enumerate(data_in_list):\n",
    "            label_element = labels[0:len(data_in_list),j].long()\n",
    "#             print(\"--------------------------\\nSingle element:\")\n",
    "#             print(\"Data element size:\", data_element.size())\n",
    "#             print(\"Label element size:\", label_element.size())\n",
    "#             print(\"Data element\", data_element)\n",
    "#             print(\"Label element\", label_element)\n",
    "#             print(\"Label element after\",label_element)\n",
    "\n",
    "#             print(\"Data element\", data_element[0][0])\n",
    "    \n",
    "            optimizer.zero_grad() \n",
    "            output_element = net(data_element)\n",
    "#             print(\"Output element\",output_element)\n",
    "#             print(\"Label element after\",label_element)\n",
    "            loss = criterion(output_element,label_element)\n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.data.item()/(len(dataset)*(1-VALIDATION_SPLIT))/TIME_STEPS*BATCH_SIZE\n",
    "#             print(\"losses:\",loss.data.item(),len(dataset),TIMESTEPS)\n",
    "#             print(\"Prediction:\", torch.max(output_element,1)[1])\n",
    "#             print(\"Labels:\", label_element.long())\n",
    "            prediction = torch.max(output_element,1)[1]\n",
    "            tt_acc_tracker.update_acc(prediction,label_element,\"TRAIN\")\n",
    "        \n",
    "    #TEST SET\n",
    "    for i,batch in enumerate(test_loader):\n",
    "        inputs, labels = batch\n",
    "        data_in_list = [s.to(device) for s in inputs['flows']]\n",
    "        labels = labels.to(device)\n",
    "        for j, data_element in enumerate(data_in_list):\n",
    "#             if (labels.size(1) != len(data_in_list)):\n",
    "#                 print(\"WARNING, labels and data_element length do not match in TEST Set\",i, \"element\", j)\n",
    "#                 print(labels[0:len(data_in_list),j].size())\n",
    "            label_element = labels[0:len(data_in_list),j].long()\n",
    "\n",
    "            output_element = net(data_element)\n",
    "            test_loss = criterion(output_element,label_element)\n",
    "            running_test_loss += loss.data.item()/(len(dataset)*VALIDATION_SPLIT)/TIME_STEPS\n",
    "\n",
    "            prediction = torch.max(output_element,1)[1]\n",
    "            tt_acc_tracker.update_acc(prediction,label_element,\"TEST\")\n",
    "\n",
    "    print(\"-----------------------------\")\n",
    "    print(\"Training set:\")\n",
    "    print(\"Epoch {}: Loss [{},{}], Acc [{},{}] took {}s\".format(epoch, running_loss,running_test_loss,tt_acc_tracker.get_acc_tot(\"TRAIN\"),tt_acc_tracker.get_acc_tot(\"TEST\"), np.around(time.time()-start_time,decimals=2)))\n",
    "    print(\"Accuracy by class [{},{}] Total elements: [{},{}]\".format(tt_acc_tracker.get_acc(\"TRAIN\"),tt_acc_tracker.get_acc(\"TEST\"), tt_acc_tracker.get_labels_distribution(\"TRAIN\"),tt_acc_tracker.get_labels_distribution(\"TEST\")))\n",
    "\n",
    "    tt_acc_tracker.update_graph()\n",
    "    tt_acc_tracker.reset_acc_both()\n",
    "    tt_acc_tracker.update_loss(running_loss)\n",
    "    tt_acc_tracker.update_lr(LR)\n",
    "\n",
    "#     monitor.update_weights(net,['conv5','fc1'])\n",
    "\n",
    "#test_all_preds(test_net) \n",
    "print('...Training finished')\n",
    "# plt.plot(loss_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_EPOCHS = 50\n",
    "LR = 0.00001\n",
    "tt_acc_tracker.reset_acc_both()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net.state_dict(), '/mnt/DATA/HIWI/IBT/saved_models/PretrainConvFlow/001_all_seq_ts40_test.pt')\n",
    "# acc_tracker.write_to_csv('/mnt/DATA/HIWI/IBT/saved_models/PretrainConvFlow/001_all_seq_ts40_test/')\n",
    "# Later:\n",
    "# loaded_model = PretrainConvFlow.PretrainConvFlow()\n",
    "# loaded_model.load_state_dict(torch.load('/mnt/DATA/HIWI/IBT/saved_models/PretrainConvFlow/first_draft'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# path = '/mnt/DATA/HIWI/IBT/saved_models/PretrainConvFlow/001_all_seq_ts40/'\n",
    "# with open(path + \"acc_tot.csv\", 'w') as file:\n",
    "#     wr = csv.writer(file)\n",
    "#     wr.writerow(acc_tracker.get_acc_tot_graph())\n",
    "# with open(path + \"loss.csv\", 'w') as file:\n",
    "#     wr = csv.writer(file)\n",
    "#     wr.writerow(acc_tracker.get_loss_graph())\n",
    "# with open(path + \"lr.csv\", 'w') as file:\n",
    "#     wr = csv.writer(file)\n",
    "#     wr.writerow(acc_tracker.get_lr_graph())\n",
    "# acc = acc_tracker.get_acc_graph()\n",
    "# for i in range(len(acc)):\n",
    "#     with open(path + \"acc\" + str(i) + \".csv\", 'w') as file:\n",
    "#         wr = csv.writer(file)\n",
    "#         wr.writerow(acc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_flows_pretrain = {\n",
    "#     'indexing':{\n",
    "#         #'grouping': 'person_sequence_angle',\n",
    "#         'selection': 'manual_people_sequence',     #  => 'auto'= by final annotation or\n",
    "#                                  #  => 'manual_people' = uses 'people' list\n",
    "#                                  #  => 'manual_people_sequence' uses combination of two lists 'people' and 'sequences'\n",
    "#         'people_selection': [1],\n",
    "#         # 'sequences_selection': ['nm-01']\n",
    "#         'sequences_selection': ['bg-01','bg-02','cl-01','cl-02','nm-01','nm-02','nm-03','nm-04','nm-05','nm-06']\n",
    "#         },\n",
    "#     'pose': {\n",
    "#         'load': False,\n",
    "#         'preprocess': False,\n",
    "#         'D': 2 ,\n",
    "#         # the complete list is:\n",
    "#         #'body_keypoints_include_list': ['LAnkle' , 'RAnkle' , 'LKnee' , 'RKnee' , 'RHip' , 'LHip' , 'RBigToe' ,\n",
    "#         #                                'LBigToe' , 'RSmallToe' , 'LSmallToe' , 'RHeel' , 'LHeel']\n",
    "#         'body_keypoints_include_list': ['LAnkle','RAnkle','LKnee','RKnee','RHip','LHip']\n",
    "#         },\n",
    "#     'flow': {\n",
    "#         'load':True,\n",
    "#         'preprocess' : True,\n",
    "#         'crops': True,\n",
    "#         'method' : 'dense',\n",
    "#         'load_patches' : True,\n",
    "#         'patch_size' : 5\n",
    "#         },\n",
    "#     'scenes':{\n",
    "#         'load':False,\n",
    "#         'preprocess': False,\n",
    "#         'crops' : False,\n",
    "#         'gray_scale' : False,\n",
    "#         'load_tracked' : False,\n",
    "#         'sequences': ['nm'],\n",
    "#         'angles': [90]\n",
    "#     },\n",
    "#     'heatmaps':{\n",
    "#         'load':False,\n",
    "#         'preprocess': False,\n",
    "#         'body_keypoints_include_list' : ['LAnkle','RAnkle']\n",
    "#     },\n",
    "#     'dataset_output' : {\n",
    "#         'data': [\"flows\"],\n",
    "#         'label': \"annotations\"\n",
    "#     },\n",
    "#     'transformers':{\n",
    "#         # 'Crop':{'include list':['LAnkle','RAnkle'],'output_size':256,'target':'flows'}\n",
    "#         # 'SpanImagesList': {'remove':True, 'names': [\"heatmaps_LAnkle\",\"heatmaps_RAnkle\"],'target': [\"heatmaps\"]},\n",
    "#         # 'Rescale': {'output_size' : (640,480), 'target': [\"flows\"]},\n",
    "#         'AnnotationToLabel': {'target': [\"annotations\"]},\n",
    "#         'Transpose' : {'swapping': (2, 0, 1) , 'target': [\"flows\"]},\n",
    "#         'Normalize': {'target': [\"flows\"]},\n",
    "#         'DimensionResize' : {'start': 5, 'dimension': 40, 'target': [\"flows\",\"annotations\"],'annotations_offset': 1},\n",
    "#         'ToTensor': {'target':[\"flows\",\"annotations\"]}\n",
    "#     }\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
