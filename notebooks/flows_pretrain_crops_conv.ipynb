{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings.py should be e.g. cnn_flows_prtrain\n",
      "Hyperparameters defined\n",
      "Bug with learning rate when sequence length is not the same for each element of the dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings.py should be e.g. cnn_flows_prtrain\")\n",
    "#DESIGN PARAMETERS FOR NEURAL NETWORK\n",
    "\n",
    "VALIDATION_SPLIT = 0.0 #indicated ratio of training to validation data: 0.2 -> 20% VALIDATION data\n",
    "RANDOMIZED_SEED = 20\n",
    "SHUFFLE_DATASET = False\n",
    "\n",
    "TRAINING_PREPARATION = False\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "TIME_STEPS = 10\n",
    "\n",
    "NR_EPOCHS = 100\n",
    "\n",
    "LR = 0.0001\n",
    "MOMENTUM = 0.9\n",
    "print(\"Hyperparameters defined\")\n",
    "print(\"Bug with learning rate when sequence length is not the same for each element of the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import os.path as path\n",
    "import copy\n",
    "\n",
    "from gait_analysis import AnnotationsCasia as Annotations\n",
    "from gait_analysis import CasiaDataset\n",
    "from gait_analysis.Config import Config\n",
    "from gait_analysis import Composer\n",
    "from gait_analysis import WeightWatcher\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gait_analysis.Models import PretrainConvFlow\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configuration  cnn_flows_pretrain\n",
      "[OK]\n",
      "Dataset size: 30\n",
      "Indices size: 30\n",
      "Split: 0\n"
     ]
    }
   ],
   "source": [
    "#change configuration in settings.py\n",
    "c = Config()\n",
    "c.config['indexing']['grouping'] = 'person_sequence_angle'\n",
    "composer = Composer()\n",
    "transformer = composer.compose()\n",
    "dataset = CasiaDataset(transform=transformer)\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "print(\"Dataset size:\", len(dataset))\n",
    "print(\"Indices size:\", len(indices))\n",
    "split = int(np.floor(VALIDATION_SPLIT * dataset_size))\n",
    "print(\"Split:\", split)\n",
    "if SHUFFLE_DATASET:\n",
    "    np.random.seed(RANDOMIZED_SEED)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "train_sampler = torch.utils.data.SequentialSampler(train_indices)\n",
    "test_sampler = torch.utils.data.SequentialSampler(test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "if TRAINING_PREPARATION:\n",
    "    print('Start training...')\n",
    "    print(\"Expected loss with {} different classes and {} data elements: {}\".format(3, len(dataset)-split, (len(dataset)-split)*np.log(3)))\n",
    "    running_loss = 0.0\n",
    "    print(\"Batch size:\", BATCH_SIZE)\n",
    "    print(\"Evaluating first element...\")\n",
    "    start_time = time.time()\n",
    "    i, batch = next(iter(enumerate(train_loader)))\n",
    "    inputs, labels = batch\n",
    "    #TODO make list disappear\n",
    "\n",
    "    data_in_list = [s.to(device) for s in inputs['flows']]\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    print(\"--------------------------\\nOriginal input:\")\n",
    "    print(\"Data in: List length\", len(data_in_list), \"List element:\", data_in_list[0].size())\n",
    "    print(\"Labels:\", labels.size())\n",
    "    print(\"--------------------------\\nSingle element:\")\n",
    "    data_element = data_in_list[0]\n",
    "    label_element = labels[:,0].long()\n",
    "    print(\"Data element:\", data_element.size())\n",
    "    print(\"Label element:\", label_element.size())\n",
    "\n",
    "    optimizer.zero_grad() \n",
    "    output_element = net(data_element)\n",
    "\n",
    "    loss = criterion(output_element,label_element)\n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.data.item()\n",
    "    elapsed_time = time.time() - start_time;\n",
    "    print(\"Loss:{}, expected loss:{}\".format(running_loss, np.log(3)))\n",
    "    print(\"Time needed:{}s\".format(elapsed_time))\n",
    "    print(\"Expected loss for total training data: \", (len(dataset)-split)*np.log(3))\n",
    "    print(\"Expected training time per epoch:{} min\".format(elapsed_time* len(train_loader)*TIMESTEPS/BATCH_SIZE/60))\n",
    "    print(\"Estimated total training time:{} hours\".format(elapsed_time* len(train_loader)*TIMESTEPS/BATCH_SIZE*NR_EPOCHS/3600))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "net = PretrainConvFlow.PretrainConvFlow()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=MOMENTUM)\n",
    "\n",
    "learning_rate_array = []\n",
    "loss_array = []\n",
    "monitor = WeightWatcher(net,['conv5','fc1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "-----------------------------\n",
      "Epoch 0: Loss 0.34933065593087337, Acc 0.8466666666666667, took 17.372836112976074s\n",
      "Accuracy by class [0.9328358208955224, 0.8275862068965517, 0.75] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 1: Loss 0.3297964401519873, Acc 0.8566666666666667, took 19.39310336112976s\n",
      "Accuracy by class [0.9402985074626866, 0.8448275862068966, 0.7592592592592593] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 2: Loss 0.3071645486700163, Acc 0.8533333333333333, took 20.128742694854736s\n",
      "Accuracy by class [0.9402985074626866, 0.8448275862068966, 0.75] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 3: Loss 0.29553152236350483, Acc 0.8533333333333333, took 20.58406972885132s\n",
      "Accuracy by class [0.9402985074626866, 0.8448275862068966, 0.75] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 4: Loss 0.323293677854042, Acc 0.8433333333333333, took 19.886809587478638s\n",
      "Accuracy by class [0.9328358208955224, 0.8448275862068966, 0.7314814814814815] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 5: Loss 0.30277309100454197, Acc 0.8566666666666667, took 18.19900131225586s\n",
      "Accuracy by class [0.9477611940298507, 0.8620689655172413, 0.7407407407407407] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 6: Loss 0.31591243788211987, Acc 0.8566666666666667, took 18.315953731536865s\n",
      "Accuracy by class [0.9402985074626866, 0.8793103448275862, 0.7407407407407407] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 7: Loss 0.32362323103162305, Acc 0.86, took 18.361860036849976s\n",
      "Accuracy by class [0.9402985074626866, 0.8793103448275862, 0.75] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 8: Loss 0.3112354866205729, Acc 0.87, took 19.074289321899414s\n",
      "Accuracy by class [0.9402985074626866, 0.8793103448275862, 0.7777777777777778] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 9: Loss 0.2821226960948366, Acc 0.88, took 19.2974112033844s\n",
      "Accuracy by class [0.9402985074626866, 0.896551724137931, 0.7962962962962963] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 10: Loss 0.3208001513158283, Acc 0.8733333333333333, took 18.556758403778076s\n",
      "Accuracy by class [0.9402985074626866, 0.9137931034482759, 0.7685185185185185] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 11: Loss 0.26178585252724623, Acc 0.8933333333333333, took 18.087661504745483s\n",
      "Accuracy by class [0.9552238805970149, 0.8793103448275862, 0.8240740740740741] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 12: Loss 0.28760970710311085, Acc 0.8833333333333333, took 18.46576476097107s\n",
      "Accuracy by class [0.9552238805970149, 0.896551724137931, 0.7870370370370371] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 13: Loss 0.22882322681679737, Acc 0.9066666666666666, took 17.857552766799927s\n",
      "Accuracy by class [0.9626865671641791, 0.896551724137931, 0.8425925925925926] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 14: Loss 0.23573324007913474, Acc 0.9033333333333333, took 19.411216259002686s\n",
      "Accuracy by class [0.9701492537313433, 0.9137931034482759, 0.8148148148148148] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 15: Loss 0.20718157656063946, Acc 0.9066666666666666, took 20.30717897415161s\n",
      "Accuracy by class [0.9701492537313433, 0.896551724137931, 0.8333333333333334] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 16: Loss 0.19774488084930156, Acc 0.9233333333333333, took 19.16668725013733s\n",
      "Accuracy by class [0.9776119402985075, 0.9137931034482759, 0.8611111111111112] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 17: Loss 0.18681235846670466, Acc 0.92, took 19.63146138191223s\n",
      "Accuracy by class [0.9701492537313433, 0.9137931034482759, 0.8611111111111112] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 18: Loss 0.18004706047092137, Acc 0.9366666666666666, took 20.293288230895996s\n",
      "Accuracy by class [0.9776119402985075, 0.9310344827586207, 0.8888888888888888] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 19: Loss 0.17391098387694606, Acc 0.9333333333333333, took 17.54149866104126s\n",
      "Accuracy by class [0.9776119402985075, 0.9137931034482759, 0.8888888888888888] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 20: Loss 0.16703129068943476, Acc 0.9333333333333333, took 19.0064697265625s\n",
      "Accuracy by class [0.9701492537313433, 0.9310344827586207, 0.8888888888888888] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 21: Loss 0.16058931857345063, Acc 0.9333333333333333, took 18.594778537750244s\n",
      "Accuracy by class [0.9776119402985075, 0.9310344827586207, 0.8796296296296297] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 22: Loss 0.15227221650244852, Acc 0.9333333333333333, took 19.45536470413208s\n",
      "Accuracy by class [0.9701492537313433, 0.9310344827586207, 0.8888888888888888] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 23: Loss 0.15007001205094628, Acc 0.9333333333333333, took 18.683341026306152s\n",
      "Accuracy by class [0.9701492537313433, 0.9310344827586207, 0.8888888888888888] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 24: Loss 0.1478634051691491, Acc 0.94, took 19.286442756652832s\n",
      "Accuracy by class [0.9850746268656716, 0.9310344827586207, 0.8888888888888888] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 25: Loss 0.2559922497002996, Acc 0.9166666666666666, took 17.634011268615723s\n",
      "Accuracy by class [0.9552238805970149, 0.9137931034482759, 0.8703703703703703] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 26: Loss 0.24704077187100967, Acc 0.9233333333333333, took 17.918123245239258s\n",
      "Accuracy by class [0.9701492537313433, 0.9137931034482759, 0.8703703703703703] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 27: Loss 0.1655297324430042, Acc 0.9299999999999999, took 17.883273363113403s\n",
      "Accuracy by class [0.9701492537313433, 0.9482758620689655, 0.8703703703703703] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 28: Loss 0.1872721115928528, Acc 0.9233333333333333, took 20.478617668151855s\n",
      "Accuracy by class [0.9626865671641791, 0.9137931034482759, 0.8796296296296297] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 29: Loss 0.12463198365464145, Acc 0.96, took 18.488312244415283s\n",
      "Accuracy by class [0.9850746268656716, 0.9655172413793104, 0.9259259259259259] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 30: Loss 0.11878807133737912, Acc 0.96, took 19.91687822341919s\n",
      "Accuracy by class [0.9850746268656716, 0.9655172413793104, 0.9259259259259259] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 31: Loss 0.11633011062882964, Acc 0.9566666666666667, took 17.82085943222046s\n",
      "Accuracy by class [0.9925373134328358, 0.9482758620689655, 0.9166666666666666] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 32: Loss 0.11563981335842377, Acc 0.9566666666666667, took 17.897353649139404s\n",
      "Accuracy by class [0.9925373134328358, 0.9655172413793104, 0.9074074074074074] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 33: Loss 0.10955150523447325, Acc 0.9566666666666667, took 20.5898175239563s\n",
      "Accuracy by class [0.9850746268656716, 0.9482758620689655, 0.9259259259259259] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 34: Loss 0.12454603879639779, Acc 0.9566666666666667, took 19.179586172103882s\n",
      "Accuracy by class [0.9850746268656716, 0.9655172413793104, 0.9166666666666666] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 35: Loss 0.10017631864155495, Acc 0.97, took 18.24911332130432s\n",
      "Accuracy by class [0.9925373134328358, 0.9827586206896551, 0.9351851851851852] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 36: Loss 0.8065166894583308, Acc 0.81, took 17.765963554382324s\n",
      "Accuracy by class [0.835820895522388, 0.8275862068965517, 0.7685185185185185] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 37: Loss 0.31454357472833483, Acc 0.8866666666666667, took 18.717293977737427s\n",
      "Accuracy by class [0.9477611940298507, 0.9310344827586207, 0.7870370370370371] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 38: Loss 0.2629454523521418, Acc 0.9233333333333333, took 19.824095964431763s\n",
      "Accuracy by class [0.9701492537313433, 0.9310344827586207, 0.8611111111111112] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 39: Loss 0.22681327397748346, Acc 0.9233333333333333, took 18.0817973613739s\n",
      "Accuracy by class [0.9850746268656716, 0.9655172413793104, 0.8240740740740741] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 40: Loss 0.1891693140071342, Acc 0.9433333333333334, took 19.242664337158203s\n",
      "Accuracy by class [0.9925373134328358, 0.9482758620689655, 0.8796296296296297] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 41: Loss 0.1720422071138456, Acc 0.9433333333333334, took 19.020155429840088s\n",
      "Accuracy by class [0.9850746268656716, 0.9655172413793104, 0.8796296296296297] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 42: Loss 0.17438170787791016, Acc 0.94, took 18.99479031562805s\n",
      "Accuracy by class [0.9776119402985075, 0.9482758620689655, 0.8888888888888888] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 43: Loss 0.1477599945043039, Acc 0.96, took 18.284898042678833s\n",
      "Accuracy by class [0.9850746268656716, 0.9655172413793104, 0.9259259259259259] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 44: Loss 0.1380073793915774, Acc 0.9566666666666667, took 18.7819766998291s\n",
      "Accuracy by class [0.9850746268656716, 0.9655172413793104, 0.9166666666666666] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 45: Loss 0.1569310619272528, Acc 0.94, took 17.24992084503174s\n",
      "Accuracy by class [0.9626865671641791, 0.9482758620689655, 0.9074074074074074] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 46: Loss 0.12789832808475693, Acc 0.9633333333333334, took 17.833770990371704s\n",
      "Accuracy by class [0.9776119402985075, 0.9655172413793104, 0.9444444444444444] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 47: Loss 0.11822445044511677, Acc 0.9666666666666667, took 19.931082725524902s\n",
      "Accuracy by class [0.9850746268656716, 0.9655172413793104, 0.9444444444444444] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 48: Loss 0.11527991672217767, Acc 0.9633333333333334, took 18.174275636672974s\n",
      "Accuracy by class [0.9850746268656716, 0.9655172413793104, 0.9351851851851852] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 49: Loss 0.12687827627187287, Acc 0.9533333333333334, took 18.468146324157715s\n",
      "Accuracy by class [0.9850746268656716, 0.9482758620689655, 0.9166666666666666] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 50: Loss 0.22045257411859756, Acc 0.92, took 18.768022775650024s\n",
      "Accuracy by class [0.9477611940298507, 0.9137931034482759, 0.8888888888888888] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 51: Loss 0.1687208123176296, Acc 0.94, took 18.10223698616028s\n",
      "Accuracy by class [0.9701492537313433, 0.9655172413793104, 0.8888888888888888] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 52: Loss 0.17239548756754927, Acc 0.94, took 20.564868450164795s\n",
      "Accuracy by class [0.9552238805970149, 0.9655172413793104, 0.9074074074074074] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 53: Loss 0.13683186961082655, Acc 0.9566666666666667, took 19.273436307907104s\n",
      "Accuracy by class [0.9850746268656716, 0.9482758620689655, 0.9259259259259259] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 54: Loss 0.11783367655229998, Acc 0.96, took 19.361727952957153s\n",
      "Accuracy by class [0.9925373134328358, 0.9655172413793104, 0.9166666666666666] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 55: Loss 0.11344234564730868, Acc 0.9666666666666667, took 18.25314950942993s\n",
      "Accuracy by class [0.9850746268656716, 0.9655172413793104, 0.9444444444444444] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 56: Loss 0.10077257653132007, Acc 0.97, took 18.174715757369995s\n",
      "Accuracy by class [0.9925373134328358, 0.9655172413793104, 0.9444444444444444] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 57: Loss 0.09050741572439926, Acc 0.9766666666666667, took 17.108713626861572s\n",
      "Accuracy by class [0.9850746268656716, 0.9655172413793104, 0.9722222222222222] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 58: Loss 0.07802893670345461, Acc 0.9833333333333333, took 18.589073419570923s\n",
      "Accuracy by class [1.0, 0.9827586206896551, 0.9629629629629629] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 59: Loss 0.11356291143369884, Acc 0.96, took 17.924434900283813s\n",
      "Accuracy by class [0.9776119402985075, 0.9482758620689655, 0.9444444444444444] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 60: Loss 0.07891037153138805, Acc 0.98, took 17.413970947265625s\n",
      "Accuracy by class [0.9925373134328358, 0.9827586206896551, 0.9629629629629629] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 61: Loss 0.0976806901455698, Acc 0.97, took 17.877804040908813s\n",
      "Accuracy by class [0.9850746268656716, 0.9827586206896551, 0.9444444444444444] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 62: Loss 0.07486165186374098, Acc 0.9833333333333333, took 19.202754974365234s\n",
      "Accuracy by class [0.9925373134328358, 0.9827586206896551, 0.9722222222222222] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 63: Loss 0.07886511318584441, Acc 0.98, took 18.534606218338013s\n",
      "Accuracy by class [0.9925373134328358, 0.9827586206896551, 0.9629629629629629] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 64: Loss 0.07051391339868095, Acc 0.9833333333333333, took 17.552867650985718s\n",
      "Accuracy by class [0.9925373134328358, 0.9827586206896551, 0.9722222222222222] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 65: Loss 0.06628586702919961, Acc 0.9833333333333333, took 16.98027992248535s\n",
      "Accuracy by class [0.9925373134328358, 0.9827586206896551, 0.9722222222222222] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 66: Loss 0.06516749776556122, Acc 0.9833333333333333, took 17.99647068977356s\n",
      "Accuracy by class [0.9925373134328358, 0.9827586206896551, 0.9722222222222222] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 67: Loss 0.05954245497745396, Acc 0.99, took 18.85145592689514s\n",
      "Accuracy by class [0.9925373134328358, 0.9827586206896551, 0.9907407407407407] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 68: Loss 0.0597772827851505, Acc 0.9833333333333333, took 19.447291374206543s\n",
      "Accuracy by class [0.9925373134328358, 0.9827586206896551, 0.9722222222222222] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 69: Loss 0.07972315149747448, Acc 0.9766666666666667, took 18.669716358184814s\n",
      "Accuracy by class [0.9850746268656716, 0.9827586206896551, 0.9629629629629629] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 70: Loss 0.12372978034846746, Acc 0.9766666666666667, took 17.78014302253723s\n",
      "Accuracy by class [0.9850746268656716, 0.9827586206896551, 0.9629629629629629] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 71: Loss 0.06110486220336214, Acc 0.98, took 19.240642070770264s\n",
      "Accuracy by class [1.0, 0.9482758620689655, 0.9722222222222222] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 72: Loss 0.06125007725133856, Acc 0.9766666666666667, took 18.648653745651245s\n",
      "Accuracy by class [0.9776119402985075, 0.9827586206896551, 0.9722222222222222] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 73: Loss 0.046063338195368425, Acc 0.99, took 17.60537338256836s\n",
      "Accuracy by class [1.0, 0.9827586206896551, 0.9814814814814815] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 74: Loss 0.058424298640070545, Acc 0.9766666666666667, took 17.7183997631073s\n",
      "Accuracy by class [0.9850746268656716, 0.9827586206896551, 0.9629629629629629] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 75: Loss 0.05410060806171561, Acc 0.9833333333333333, took 17.496273279190063s\n",
      "Accuracy by class [0.9850746268656716, 0.9827586206896551, 0.9814814814814815] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 76: Loss 0.0745278102322634, Acc 0.9733333333333334, took 17.53157353401184s\n",
      "Accuracy by class [0.9776119402985075, 0.9827586206896551, 0.9629629629629629] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 77: Loss 0.09743261962448291, Acc 0.9666666666666667, took 17.870644092559814s\n",
      "Accuracy by class [0.9701492537313433, 0.9827586206896551, 0.9537037037037037] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 78: Loss 0.5709750456011349, Acc 0.89, took 17.063594818115234s\n",
      "Accuracy by class [0.9029850746268657, 0.9137931034482759, 0.8611111111111112] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 79: Loss 0.252685479812908, Acc 0.9233333333333333, took 16.868899822235107s\n",
      "Accuracy by class [0.9552238805970149, 0.9310344827586207, 0.8796296296296297] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 80: Loss 0.0926906764678582, Acc 0.9766666666666667, took 17.669311046600342s\n",
      "Accuracy by class [0.9925373134328358, 0.9827586206896551, 0.9537037037037037] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 81: Loss 0.07682166806874495, Acc 0.9733333333333334, took 17.647912979125977s\n",
      "Accuracy by class [0.9776119402985075, 0.9827586206896551, 0.9629629629629629] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 82: Loss 0.06575351231698742, Acc 0.98, took 17.435417652130127s\n",
      "Accuracy by class [0.9850746268656716, 0.9827586206896551, 0.9722222222222222] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 83: Loss 0.05384251331756504, Acc 0.99, took 17.157423496246338s\n",
      "Accuracy by class [0.9925373134328358, 0.9827586206896551, 0.9907407407407407] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 84: Loss 0.0579434227353886, Acc 0.99, took 16.82120990753174s\n",
      "Accuracy by class [0.9925373134328358, 0.9827586206896551, 0.9907407407407407] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 85: Loss 0.0473024462406831, Acc 0.9866666666666667, took 17.67029333114624s\n",
      "Accuracy by class [0.9925373134328358, 0.9827586206896551, 0.9814814814814815] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 86: Loss 0.04367619267665171, Acc 0.9866666666666667, took 17.661211729049683s\n",
      "Accuracy by class [0.9925373134328358, 0.9827586206896551, 0.9814814814814815] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 87: Loss 0.038280505459092735, Acc 0.9866666666666667, took 16.56797432899475s\n",
      "Accuracy by class [0.9925373134328358, 0.9827586206896551, 0.9814814814814815] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 88: Loss 0.03247040990640926, Acc 0.99, took 17.386012077331543s\n",
      "Accuracy by class [0.9925373134328358, 0.9827586206896551, 0.9907407407407407] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 89: Loss 0.028637344684856694, Acc 0.99, took 17.918333768844604s\n",
      "Accuracy by class [0.9925373134328358, 0.9827586206896551, 0.9907407407407407] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 90: Loss 0.023885413673004525, Acc 0.9933333333333333, took 16.959422826766968s\n",
      "Accuracy by class [1.0, 0.9827586206896551, 0.9907407407407407] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 91: Loss 0.020481040156814363, Acc 0.9933333333333333, took 17.383306980133057s\n",
      "Accuracy by class [1.0, 0.9827586206896551, 0.9907407407407407] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 92: Loss 0.018725365221313933, Acc 0.9933333333333333, took 17.36967444419861s\n",
      "Accuracy by class [1.0, 0.9827586206896551, 0.9907407407407407] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 93: Loss 0.015489265568350655, Acc 1.0, took 17.234731912612915s\n",
      "Accuracy by class [1.0, 1.0, 1.0] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 94: Loss 0.013545392089475665, Acc 1.0, took 17.18328595161438s\n",
      "Accuracy by class [1.0, 1.0, 1.0] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 95: Loss 0.012076695418240984, Acc 1.0, took 17.482272386550903s\n",
      "Accuracy by class [1.0, 1.0, 1.0] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 96: Loss 0.010913301024640986, Acc 1.0, took 17.75800061225891s\n",
      "Accuracy by class [1.0, 1.0, 1.0] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 97: Loss 0.009913598327833976, Acc 1.0, took 17.365493059158325s\n",
      "Accuracy by class [1.0, 1.0, 1.0] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 98: Loss 0.009137139668712279, Acc 1.0, took 17.2070472240448s\n",
      "Accuracy by class [1.0, 1.0, 1.0] Total elements: [134, 58, 108]\n",
      "-----------------------------\n",
      "Epoch 99: Loss 0.008364883301233781, Acc 1.0, took 17.454498052597046s\n",
      "Accuracy by class [1.0, 1.0, 1.0] Total elements: [134, 58, 108]\n",
      "...Training finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training...\")\n",
    "for epoch in range(NR_EPOCHS): \n",
    "    start_time = time.time()\n",
    "#     print(\"Epoch:\", epoch)\n",
    "    running_loss = 0.0\n",
    "    incorrectly_predicted = 0 \n",
    "    total_elements = 0\n",
    "    correctly = [0, 0, 0]\n",
    "    total_class = [0, 0, 0]\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        inputs, labels = batch\n",
    "        data_in_list = [s.to(device) for s in inputs['flows']]\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "#         print(\"--------------------------\\nOriginal input:\")\n",
    "#         print(\"Data in: List length\", len(data_in_list), \"List element:\", data_in_list[0].size())\n",
    "#         print(\"Labels:\", labels.size())\n",
    "\n",
    "        for j, data_element in enumerate(data_in_list):\n",
    "            if (labels.size(1) != len(data_in_list)):\n",
    "                print(\"WARNING, labels and data_element length do not match in Set\",i, \"element\", j)\n",
    "#                 print(\"Label element after\")\n",
    "                print(labels[0:len(data_in_list),j].size())\n",
    "            label_element = labels[0:len(data_in_list),j].long()\n",
    "#             print(\"--------------------------\\nSingle element:\")\n",
    "#             print(\"Data element size:\", data_element.size())\n",
    "#             print(\"Label element size:\", label_element.size())\n",
    "#             print(\"Data element\", data_element)\n",
    "#             print(\"Label element\", label_element)\n",
    "#             print(\"Label element after\",label_element)\n",
    "\n",
    "#             print(\"Data element\", data_element[0][0])\n",
    "    \n",
    "            optimizer.zero_grad() \n",
    "            output_element = net(data_element)\n",
    "#             print(\"Output element\",output_element)\n",
    "#             print(\"Label element after\",label_element)\n",
    "            loss = criterion(output_element,label_element)\n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.data.item()/len(dataset)/TIME_STEPS*BATCH_SIZE\n",
    "#             print(\"losses:\",loss.data.item(),len(dataset),TIMESTEPS)\n",
    "#             print(\"Prediction:\", torch.max(output_element,1)[1])\n",
    "#             print(\"Labels:\", label_element.long())\n",
    "            prediction = torch.max(output_element,1)[1]\n",
    "            incorrectly_predicted += torch.nonzero(torch.max(output_element,1)[1] - label_element.long()).numel()\n",
    "            total_elements += (torch.max(output_element,1)[1] - label_element.long()).numel()\n",
    "            \n",
    "            for pred,label in zip(prediction,label_element):\n",
    "                if label == 0:\n",
    "                    total_class[0] += 1\n",
    "                    if pred == 0:\n",
    "                        correctly[0] += 1\n",
    "                elif label == 1:\n",
    "                    total_class[1] += 1\n",
    "                    if pred == 1:\n",
    "                        correctly[1] += 1\n",
    "                else:\n",
    "                    total_class[2] += 1\n",
    "                    if pred == 2:\n",
    "                        correctly[2] += 1\n",
    "    \n",
    "    print(\"-----------------------------\")\n",
    "    print(\"Epoch {}: Loss {}, Acc {}, took {}s\".format(epoch, running_loss,1 - incorrectly_predicted/total_elements, time.time()-start_time))\n",
    "    print(\"Accuracy by class\", [c/(t) for c,t in zip(correctly,total_class)], \"Total elements:\", total_class)\n",
    "    monitor.update_weights(net,['conv5','fc1'])\n",
    "    w_conv5, w_fc1 = monitor.get_weight_changes(['conv5','fc1'])\n",
    "#     print(\"FC1:\",w_fc1[-1],\"CONV5:\",w_conv5[-1])\n",
    "    monitor.update_loss(running_loss)\n",
    "    learning_rate_array.append(LR)\n",
    "\n",
    "#test_all_preds(test_net) \n",
    "print('...Training finished')\n",
    "# plt.plot(loss_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "total = sum([0, 1, 10])\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net.state_dict(), '/mnt/DATA/HIWI/IBT/saved_models/PretrainConvFlow/first_draft')\n",
    "# Later:\n",
    "# loaded_model = PretrainConvFlow.PretrainConvFlow()\n",
    "# loaded_model.load_state_dict(torch.load('/mnt/DATA/HIWI/IBT/saved_models/PretrainConvFlow/first_draft'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later:\n",
    "# loaded_model = PretrainConvFlow.PretrainConvFlow()\n",
    "# loaded_model.load_state_dict(torch.load('/mnt/DATA/HIWI/IBT/saved_models/PretrainConvFlow/first_draft'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of PretrainConvFlow(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv5): Conv2d(16, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=90, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=3, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# print(loaded_model.parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2156862e-09, 7.847238e-09, 2.0700796e-08, 3.871344e-08, 6.1552804e-08, 8.969565e-08, 1.2218719e-07, 1.5831262e-07, 1.9804826e-07, 2.3933092e-07, 2.8222172e-07, 3.2581772e-07, 3.706511e-07, 4.1725164e-07, 4.6413348e-07, 5.1167103e-07, 5.639011e-07, 6.177802e-07, 6.7190126e-07, 7.2838617e-07, 7.8659906e-07, 8.477239e-07, 9.113527e-07, 9.772217e-07, 1.0441237e-06, 1.1163859e-06, 1.1909921e-06, 1.2679316e-06, 1.3480918e-06, 1.4330559e-06, 1.5212614e-06, 1.6134283e-06, 1.7127483e-06, 1.8157624e-06, 1.9242343e-06, 2.0388193e-06, 2.167997e-06, 2.3079715e-06, 2.4548306e-06, 2.6118473e-06, 2.7824285e-06, 2.9723828e-06, 3.1879845e-06, 3.4336956e-06, 3.7198172e-06, 4.049786e-06, 4.447429e-06, 4.924816e-06, 5.4968773e-06, 6.20003e-06, 7.0652673e-06, 8.143118e-06, 9.50244e-06, 1.1229457e-05, 1.3462059e-05, 1.6277316e-05, 1.9779329e-05, 2.3899389e-05, 2.8418886e-05, 3.338968e-05, 3.9200368e-05, 4.5841312e-05, 5.25605e-05, 5.8519985e-05, 6.375299e-05, 6.876483e-05, 7.3768744e-05, 7.8768426e-05, 8.365686e-05, 8.8504705e-05, 9.318132e-05, 9.776864e-05, 0.00010257895, 0.00010719513, 0.00011155991, 0.00011606695, 0.0001205279, 0.00012484656, 0.00012891075, 0.00013292178, 0.00013671872, 0.00014031233, 0.00014390994, 0.00014729773, 0.00015079437, 0.0001539666, 0.00015677881, 0.00015973941, 0.00016232014, 0.00016530631, 0.00016818136, 0.00017095947, 0.00017407186, 0.00017726896, 0.00018062594, 0.00018401469, 0.00018799571, 0.00019114565, 0.00019477456, 0.0001987709]\n",
      "[1.0960290541251496, 1.0932694643735883, 1.0905971854925158, 1.0880925476551055, 1.0857483794291816, 1.0835307677586872, 1.0814295212427771, 1.079439201951027, 1.0775501757860182, 1.0757617125908532, 1.0740696728229528, 1.0724661618471143, 1.070942965149879, 1.0694922188917793, 1.0681081742048262, 1.066788562138875, 1.0655249079068503, 1.0643107732137045, 1.0631471276283264, 1.0620295902093249, 1.0609568228324258, 1.0599276751279827, 1.0589373538891476, 1.057983393470446, 1.0570632338523864, 1.0561776489019394, 1.0553276995817824, 1.054507847627004, 1.0537138044834136, 1.0529393384853993, 1.052185846368472, 1.051445359985034, 1.050713316599528, 1.049985958139102, 1.0492610186338427, 1.0485341906547545, 1.0477945864200593, 1.0470370610555013, 1.046258180340131, 1.0454588244358702, 1.0446409881114962, 1.0437710672616958, 1.0428361922502518, 1.0418211966753008, 1.0406999905904133, 1.0394401262203852, 1.0379885037740069, 1.0362556606531141, 1.034171230594317, 1.031602911154429, 1.0283704032500582, 1.0241916954517363, 1.0186633199453354, 1.0111888219912843, 1.0009272664785385, 0.9870043367147446, 0.9685941269000369, 0.9456717759370802, 0.9188139746586482, 0.8878714169065157, 0.8497842888037361, 0.8048691608011724, 0.7587998090932766, 0.7179282841583092, 0.6839578373978534, 0.655152368110915, 0.6309470196254551, 0.6099780531910557, 0.5913016300648452, 0.5746216545114294, 0.559402536577545, 0.5446723370114342, 0.5309161844973763, 0.5169261819993456, 0.5037214633019175, 0.491539651323304, 0.4791486223475658, 0.4683647039283338, 0.45866183980979264, 0.4494955048617461, 0.44168699072664225, 0.43399427173656785, 0.4270248903210208, 0.41985256561238204, 0.41454971898347137, 0.4073082198924263, 0.4017337499349499, 0.3959162533624597, 0.38990300492459934, 0.3850551796122696, 0.3782880307566908, 0.37443758287038986, 0.3651367970451246, 0.364490548354024, 0.350418400701589, 0.34914618494804006, 0.3459943760706361, 0.33671687041331394, 0.32131968365400393, 0.3137910594309991]\n"
     ]
    }
   ],
   "source": [
    "plt.plot(monitor.get_weight_changes(['conv5']))\n",
    "print(monitor.get_weight_changes(['conv5']))\n",
    "plt.plot(monitor.get_loss())\n",
    "print(monitor.get_loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_conv_accuracy(model):\n",
    "\n",
    "#     #Time for printing\n",
    "#     testing_start_time = time.time()\n",
    "\n",
    "#     print('Start testing...')\n",
    "#     correct = 0 \n",
    "#     total = 0\n",
    "#     with torch.no_grad():\n",
    "#         for i, batch in enumerate(train_loader):\n",
    "#             inputs, labels = batch\n",
    "            \n",
    "#             data_in = [s.to(device) for s in inputs['flows']]\n",
    "#             labels = labels.to(device)\n",
    "#             outputs = model(data_in)\n",
    "# #             print(\"Out:\", len(outputs), outputs.size())\n",
    "# #             print(\"Labels:\", len(labels), labels.size())\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "# #             print('predicted:',len(predicted),predicted.size())\n",
    "#             n_errors = torch.nonzero(torch.abs(labels.long() - predicted)).size(0)\n",
    "#             total += predicted.numel()\n",
    "#             # print('predicted',predicted)\n",
    "#             correct += predicted.numel() - n_errors\n",
    "#             # print('labels',labels)\n",
    "#     print('Accuracy {:.3f}%'.format(correct/total))\n",
    "#     print('...testing finished')\n",
    "# print(\"Definition done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python gait_36",
   "language": "python",
   "name": "gait_36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
