{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters defined\n"
     ]
    }
   ],
   "source": [
    "#DESIGN PARAMETERS FOR NEURAL NETWORK\n",
    "NR_LSTM_UNITS = 2 \n",
    "IMAGE_INPUT_SIZE_W = 640\n",
    "IMAGE_INPUT_SIZE_H = 480\n",
    "\n",
    "IMAGE_AFTER_CONV_SIZE_W = 18\n",
    "IMAGE_AFTER_CONV_SIZE_H = 13\n",
    "#for 3x3 kernels, n=num_layers: len_in = 2^n*len_out + sum[i=1..n](2^i)\n",
    "#CONV_LAYER_LENGTH = 5\n",
    "\n",
    "LSTM_IO_SIZE = 18*13\n",
    "LSTM_HIDDEN_SIZE = 18*13\n",
    "\n",
    "RGB_CHANNELS = 3\n",
    "TIMESTEPS = 10 # size videos\n",
    "BATCH_SIZE = 4 #until now just batch_size = 1\n",
    "\n",
    "NR_EPOCHS = 50\n",
    "\n",
    "VALIDATION_SPLIT = 0.2 #indicated ratio of training to validation data: 0.2 -> 20% VALIDATION data\n",
    "RANDOMIZED_SEED = 20\n",
    "SHUFFLE_DATASET = False\n",
    "\n",
    "learning_rate = 0.01 # reduce factos of 10 .. some epoch later.\n",
    "momentum = 0.9\n",
    "print(\"Hyperparameters defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import os.path as path\n",
    "import copy\n",
    "# from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "\n",
    "from gait_analysis import AnnotationsCasia as Annotations\n",
    "from gait_analysis import CasiaDataset\n",
    "from gait_analysis.Config import Config\n",
    "from gait_analysis import Composer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configuration  flows\n",
      "[OK]\n"
     ]
    }
   ],
   "source": [
    "#change configuration in settings.py\n",
    "crop_im_size = [186,250]\n",
    "c = Config()\n",
    "c.config['indexing']['grouping'] = 'person_sequence_angle'\n",
    "c.config['transformers']['DimensionResize']['dimension'] = TIMESTEPS\n",
    "#c.config['indexing']['people selection'] = [1]\n",
    "#c.config['indexing']['sequences_selection'] = ['nm-01']\n",
    "c.config['pose']['load'] = False\n",
    "c.config['flow']['load'] = True\n",
    "c.config['heatmaps']['load'] = False\n",
    "#c.config['scenes']['sequences'] = ['nm']\n",
    "#c.config['scenes']['angles'] = ['108']\n",
    "c.config['dataset_output'] = {\n",
    "#         'data': [\"scenes\",\"flows\",\"heatmaps_LAnkle\",\"heatmaps_RAnkle\"],\n",
    "        'data': ['flows'],\n",
    "        'label': \"annotations\"}\n",
    "composer = Composer()\n",
    "transformer = composer.compose()\n",
    "dataset = CasiaDataset(transform=transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings \n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 5\n",
      "Indices size: 5\n",
      "Split: 1\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "print(\"Dataset size:\", len(dataset))\n",
    "print(\"Indices size:\", len(indices))\n",
    "split = int(np.floor(VALIDATION_SPLIT * dataset_size))\n",
    "print(\"Split:\", split)\n",
    "if SHUFFLE_DATASET:\n",
    "    np.random.seed(RANDOMIZED_SEED)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "train_sampler = torch.utils.data.SequentialSampler(train_indices)\n",
    "test_sampler = torch.utils.data.SequentialSampler(test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=test_sampler)\n",
    "\n",
    "# #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class defined\n"
     ]
    }
   ],
   "source": [
    "class TEST_CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TEST_CNN_LSTM, self).__init__()\n",
    "        self.avialable_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3,6,3) #input 640x480\n",
    "        self.pool1 = nn.MaxPool2d(2,2) #input 638x478 output 319x239\n",
    "        self.conv2 = nn.Conv2d(6,16,3) # input 319x239 output 317x237\n",
    "        self.pool2 = nn.MaxPool2d(2,2) # input 317x237 output 158x118\n",
    "        self.conv3 = nn.Conv2d(16,6,3) # input 158x118 output 156x116\n",
    "        self.pool3 = nn.MaxPool2d(2,2) # input 156x116 output 78x58\n",
    "        self.conv4 = nn.Conv2d(6,3,3)  # input 78x58 output 76x56\n",
    "        self.pool4 = nn.MaxPool2d(2,2) # input 76x56 output 39x29\n",
    "        self.conv5 = nn.Conv2d(3,1,3)  # input 39x29 output 37x27\n",
    "        self.pool5 = nn.MaxPool2d(2,2) #output 37x27 output 18x13\n",
    "        self.lstm1 = nn.LSTM(LSTM_IO_SIZE,\n",
    "                            LSTM_HIDDEN_SIZE,\n",
    "                            TIMESTEPS)# horizontal direction\n",
    "        self.lstm2 = nn.LSTM(LSTM_IO_SIZE,\n",
    "                            LSTM_HIDDEN_SIZE,\n",
    "                            TIMESTEPS)# horizontal direction\n",
    "        self.fc1 = nn.Linear(LSTM_IO_SIZE,120)\n",
    "        self.fc2 = nn.Linear(120,20)\n",
    "        self.fc3 = nn.Linear(20,3)\n",
    "        \n",
    "        #initialize hidden states of LSTM\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "        #print(\"Hidden:\", _hidden)\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(TIMESTEPS, BATCH_SIZE, LSTM_HIDDEN_SIZE).to(self.avialable_device), \n",
    "                torch.randn(TIMESTEPS, BATCH_SIZE, LSTM_HIDDEN_SIZE).to(self.avialable_device))\n",
    "    def forward(self,x):\n",
    "#         print(\"Input list len:\",len(x))\n",
    "#         print(\"Input elemens size:\", x[0].size())\n",
    "#         batch_size = x[0].size()[0]\n",
    "\n",
    "        x_arr = torch.zeros(TIMESTEPS,BATCH_SIZE,1,IMAGE_AFTER_CONV_SIZE_H,IMAGE_AFTER_CONV_SIZE_W).to(self.avialable_device)\n",
    "        #print(\"X arr size\", x_arr.size())\n",
    "        #print(\"X size\", len(x))\n",
    "        for i in range(TIMESTEPS):#parallel convolutions which are later concatenated for LSTM\n",
    "            x_tmp_c1 = self.pool1(F.relu(self.conv1(x[i].float())))\n",
    "            x_tmp_c2 = self.pool2(F.relu(self.conv2(x_tmp_c1)))\n",
    "            x_tmp_c3 = self.pool3(F.relu(self.conv3(x_tmp_c2)))\n",
    "            x_tmp_c4 = self.pool4(F.relu(self.conv4(x_tmp_c3)))\n",
    "            x_tmp_c5 = self.pool5(F.relu(self.conv5(x_tmp_c4)))\n",
    "            x_arr[i] = x_tmp_c5 # torch.squeeze(x_tmp_c5)\n",
    "        \n",
    "        x, hidden = self.lstm1(x_arr.view(TIMESTEPS,BATCH_SIZE,-1), self.hidden)\n",
    "        x, hidden = self.lstm2(x, self.hidden)\n",
    "        # the reshaping was taken from the documentation... and makes scense\n",
    "        x = x.view(TIMESTEPS,BATCH_SIZE,LSTM_HIDDEN_SIZE) #output.view(seq_len, batch, num_dir*hidden_size)\n",
    "#         x = torch.squeeze(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x) \n",
    "        #x = x.squeeze(1)\n",
    "        x = x.permute(1,2,0)\n",
    "        #print (\"Size network output\", x.shape)\n",
    "        return x\n",
    "print(\"Class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#TRAINING\n",
    "test_net = TEST_CNN_LSTM()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "test_net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(test_net.parameters(), lr=learning_rate, momentum=momentum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set and evaluate computing time etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Expected loss with 3 different classes and 4 data points: 4.394449154672439\n",
      "Batch size: 4\n",
      "Evaluating first element...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/.conda/envs/gait_37/lib/python3.7/site-packages/pandas/core/computation/expressions.py:183: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
      "  .format(op=op_str, alt_op=unsupported[op_str]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time steps:10, input sequence length:10\n",
      "Out: 4 torch.Size([4, 3, 10])\n",
      "Labels: 4 torch.Size([4, 10])\n",
      "Loss:1.0444207191467285, expected loss:1.0986122886681098\n",
      "Time needed:36.91179609298706s\n",
      "Expected loss for total training data:  4.394449154672439\n",
      "Expected training time per epoch:0.6151966015497844 min\n",
      "Estimated total training time:0.5126638346248202 hours\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "print('Start training...')\n",
    "print(\"Expected loss with {} different classes and {} data points: {}\".format(3, len(dataset)-split, (len(dataset)-split)*np.log(3)))\n",
    "running_loss = 0.0\n",
    "#print(\"Data set length:\", len((train_loader)), \"Validation length:\", len(test_loader))\n",
    "print(\"Batch size:\", BATCH_SIZE)\n",
    "print(\"Evaluating first element...\")\n",
    "start_time = time.time()\n",
    "i, batch = next(iter(enumerate(train_loader)))\n",
    "inputs, labels = batch\n",
    "data_in = [s.to(device) for s in inputs['flows']]\n",
    "labels = labels.to(device)\n",
    "print(\"Time steps:{}, input sequence length:{}\".format(TIMESTEPS,len(data_in)))\n",
    "#print(\"NN input: \",len(flows),len(flows[0]),len(flows[0][0]),len(flows[0][0][0]),len(flows[0][0][0][0]))\n",
    "optimizer.zero_grad() \n",
    "outputs = test_net(data_in)\n",
    "print(\"Out:\", len(outputs), outputs.size())\n",
    "#print(\"Out content:\", outputs)\n",
    "print(\"Labels:\", len(labels), labels.size())\n",
    "#print(\"Labels content:\", labels)\n",
    "loss = criterion(outputs.float(),labels.long())\n",
    "loss.backward() \n",
    "optimizer.step()\n",
    "\n",
    "#Print statistics\n",
    "# print(loss.data.item())\n",
    "running_loss += loss.data.item()\n",
    "elapsed_time = time.time() - start_time;\n",
    "print(\"Loss:{}, expected loss:{}\".format(running_loss, np.log(3)))\n",
    "print(\"Time needed:{}s\".format(elapsed_time))\n",
    "print(\"Expected loss for total training data: \", (len(dataset)-split)*np.log(3))\n",
    "print(\"Expected training time per epoch:{} min\".format(elapsed_time* len(train_loader)/60))\n",
    "print(\"Estimated total training time:{} hours\".format(elapsed_time* len(train_loader)*NR_EPOCHS/3600))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define and execute testing function\n",
    "def test_all_preds(model):\n",
    "    n_batches_test = len(test_loader)\n",
    "\n",
    "    #Time for printing\n",
    "    testing_start_time = time.time()\n",
    "\n",
    "    print('Start testing...')\n",
    "    correct = 0 \n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            inputs, labels = batch\n",
    "            \n",
    "            data_in = [s.to(device) for s in inputs['flows']]\n",
    "            labels = labels.to(device)\n",
    "            if not labels.size()[0] == BATCH_SIZE:\n",
    "                # skip uncompleted batch size NN is fixed to BATCHSIZE\n",
    "                continue\n",
    "            outputs = model(data_in)\n",
    "#             print(\"Out:\", len(outputs), outputs.size())\n",
    "#             print(\"Labels:\", len(labels), labels.size())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "#             print('predicted:',len(predicted),predicted.size())\n",
    "            n_errors = torch.nonzero(torch.abs(labels.long() - predicted)).size(0)\n",
    "            total += predicted.numel()\n",
    "            # print('predicted',predicted)\n",
    "            correct += predicted.numel() - n_errors\n",
    "            # print('labels',labels)\n",
    "    print('Accuracy {:.2f}%'.format(100*correct/total))\n",
    "    print('...testing finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Loss epoch 0: 1.0431829690933228, took 22.540446758270264s\n",
      "Epoch: 1\n",
      "Loss epoch 1: 1.0408521890640259, took 23.329219341278076s\n",
      "Epoch: 2\n",
      "Loss epoch 2: 1.0375611782073975, took 23.842116832733154s\n",
      "Epoch: 3\n",
      "Loss epoch 3: 1.0334713459014893, took 20.0211238861084s\n",
      "Epoch: 4\n",
      "Loss epoch 4: 1.028731107711792, took 23.441691637039185s\n",
      "Epoch: 5\n",
      "Loss epoch 5: 1.0234687328338623, took 23.28370451927185s\n",
      "Epoch: 6\n",
      "Loss epoch 6: 1.017789363861084, took 20.75862979888916s\n",
      "Epoch: 7\n",
      "Loss epoch 7: 1.0117731094360352, took 22.817089080810547s\n",
      "Epoch: 8\n",
      "Loss epoch 8: 1.0055263042449951, took 21.27199625968933s\n",
      "Epoch: 9\n",
      "Loss epoch 9: 0.9991376996040344, took 22.171945571899414s\n",
      "Epoch: 10\n",
      "Loss epoch 10: 0.9926614761352539, took 21.818361282348633s\n",
      "Epoch: 11\n",
      "Loss epoch 11: 0.9861479997634888, took 21.00788974761963s\n",
      "Epoch: 12\n",
      "Loss epoch 12: 0.9796829223632812, took 20.778083086013794s\n",
      "Epoch: 13\n",
      "Loss epoch 13: 0.9733101725578308, took 21.34096336364746s\n",
      "Epoch: 14\n",
      "Loss epoch 14: 0.9670717120170593, took 20.681850910186768s\n",
      "Epoch: 15\n",
      "Loss epoch 15: 0.9609997868537903, took 24.474120140075684s\n",
      "Epoch: 16\n",
      "Loss epoch 16: 0.9551271200180054, took 21.007043600082397s\n",
      "Epoch: 17\n",
      "Loss epoch 17: 0.9494749903678894, took 22.343740463256836s\n",
      "Epoch: 18\n",
      "Loss epoch 18: 0.9440606832504272, took 23.418421506881714s\n",
      "Epoch: 19\n",
      "Loss epoch 19: 0.9388812780380249, took 28.218419790267944s\n",
      "Epoch: 20\n",
      "Loss epoch 20: 0.9339445233345032, took 21.470898866653442s\n",
      "Epoch: 21\n",
      "Loss epoch 21: 0.929252028465271, took 22.393746376037598s\n",
      "Epoch: 22\n",
      "Loss epoch 22: 0.9248028993606567, took 22.65548825263977s\n",
      "Epoch: 23\n",
      "Loss epoch 23: 0.9205945730209351, took 22.95650839805603s\n",
      "Epoch: 24\n",
      "Loss epoch 24: 0.9166189432144165, took 21.245002269744873s\n",
      "Epoch: 25\n",
      "Loss epoch 25: 0.9128662347793579, took 21.613699913024902s\n",
      "Epoch: 26\n",
      "Loss epoch 26: 0.9093281030654907, took 19.72436499595642s\n",
      "Epoch: 27\n",
      "Loss epoch 27: 0.9059942364692688, took 20.501990795135498s\n",
      "Epoch: 28\n",
      "Loss epoch 28: 0.9028533697128296, took 24.112958669662476s\n",
      "Epoch: 29\n",
      "Loss epoch 29: 0.8999031782150269, took 25.746617078781128s\n",
      "Epoch: 30\n",
      "Loss epoch 30: 0.8971293568611145, took 21.682250022888184s\n",
      "Epoch: 31\n",
      "Loss epoch 31: 0.8945016860961914, took 23.151928424835205s\n",
      "Epoch: 32\n",
      "Loss epoch 32: 0.8920149803161621, took 20.56375217437744s\n",
      "Epoch: 33\n",
      "Loss epoch 33: 0.88965904712677, took 22.986740827560425s\n",
      "Epoch: 34\n",
      "Loss epoch 34: 0.8874180912971497, took 23.054481506347656s\n",
      "Epoch: 35\n",
      "Loss epoch 35: 0.8852773904800415, took 23.03597116470337s\n",
      "Epoch: 36\n",
      "Loss epoch 36: 0.8832260966300964, took 20.942453861236572s\n",
      "Epoch: 37\n",
      "Loss epoch 37: 0.8812530636787415, took 25.094093084335327s\n",
      "Epoch: 38\n",
      "Loss epoch 38: 0.8793481588363647, took 20.932791709899902s\n",
      "Epoch: 39\n",
      "Loss epoch 39: 0.8775010108947754, took 26.627954721450806s\n",
      "Epoch: 40\n",
      "Loss epoch 40: 0.8757025599479675, took 21.315723419189453s\n",
      "Epoch: 41\n",
      "Loss epoch 41: 0.8739444017410278, took 21.666637182235718s\n",
      "Epoch: 42\n",
      "Loss epoch 42: 0.8722192645072937, took 21.960304260253906s\n",
      "Epoch: 43\n",
      "Loss epoch 43: 0.870520293712616, took 20.81197500228882s\n",
      "Epoch: 44\n",
      "Loss epoch 44: 0.8688419461250305, took 21.959182500839233s\n",
      "Epoch: 45\n",
      "Loss epoch 45: 0.8671784400939941, took 20.54771089553833s\n",
      "Epoch: 46\n",
      "Loss epoch 46: 0.8655274510383606, took 22.984012603759766s\n",
      "Epoch: 47\n",
      "Loss epoch 47: 0.8638767004013062, took 21.599103212356567s\n",
      "Epoch: 48\n",
      "Loss epoch 48: 0.8622249364852905, took 22.66081213951111s\n",
      "Epoch: 49\n",
      "Loss epoch 49: 0.8605669736862183, took 19.850695610046387s\n",
      "...Training finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1a46b0d828>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_array = []\n",
    "for epoch in range(NR_EPOCHS): \n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    print(\"Epoch:\", epoch)\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        inputs, labels = batch\n",
    "        data_in = [s.to(device) for s in inputs['flows']]\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        outputs = test_net(data_in)\n",
    "        loss = criterion(outputs.float(),labels.long())\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.data.item()\n",
    "\n",
    "    print(\"Loss epoch {}: {}, took {}s\".format(epoch, running_loss,time.time()-start_time))\n",
    "    loss_array.append(running_loss)\n",
    "\n",
    "#test_all_preds(test_net) \n",
    "print('...Training finished')\n",
    "plt.plot(loss_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected loss for untrained set with Cross Entropy:\n",
    "k = number of classes\n",
    "N = number of labeled data in dataset\n",
    "loss_per_prediction = -log(1/k) = log(k)\n",
    "total_loss = sum(log(k)) = N*log(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python gait_36",
   "language": "python",
   "name": "gait_36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
