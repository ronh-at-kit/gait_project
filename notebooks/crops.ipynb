{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config should be e.g. crops\n",
      "loading configuration  crops\n",
      "[OK]\n"
     ]
    }
   ],
   "source": [
    "#CONFIG\n",
    "print(\"Settings.py should be e.g. crops\")\n",
    "print(\"Still in development, may have bugs\")\n",
    "from gait_analysis import CasiaDataset\n",
    "from gait_analysis.Config import Config\n",
    "import numpy as np\n",
    "\n",
    "from gait_analysis import CasiaDataset\n",
    "from gait_analysis.Config import Config\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "\n",
    "c = Config()\n",
    "c.config['indexing']['grouping'] = 'person_sequence_angle'\n",
    "#c.config['people_selection'] = range(1,2)\n",
    "#c.config['body_keypoints_include_list'] = ['LAnkle','RAnkle','LKnee','RKnee','LHip','RHip', \n",
    "#                                           'LHeel', 'RHeel,', 'LBigToe', 'RBigToe', 'LSmallToe', 'RBigToe']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 12 poses\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-801bee47e23c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minvalid_pose_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Using\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'poses'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"poses\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#for i in range(5):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#for listitem in dataset: print(listitem)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gait_project/gait_analysis/DataSets/CasiaDataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'scenes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscenes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'valid_indices'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0min_frame_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scenes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscenes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'flows'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'valid_indices'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0min_frame_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gait_project/gait_analysis/DataSets/ScenesCasia.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Loading scene images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_scene\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gait_project/gait_analysis/DataSets/ScenesCasia.py\u001b[0m in \u001b[0;36m_load_scene\u001b[0;34m(self, dataset_item)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mscene_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscene_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscene_images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gait_project/gait_analysis/DataSets/ScenesCasia.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mscene_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscene_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscene_images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gait_project/gait_analysis/DataSets/ScenesCasia.py\u001b[0m in \u001b[0;36mread_image\u001b[0;34m(im_file)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} don\\'t exist.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = CasiaDataset()\n",
    "#for i in range(len(dataset)):\n",
    "x_max_list = []\n",
    "y_max_list = []\n",
    "invalid_pose_counter = 0\n",
    "print(\"Using\",dataset[0]['poses'].shape[0],\"poses\")\n",
    "for item in dataset: \n",
    "#for i in range(5):\n",
    "    #for listitem in dataset: print(listitem)\n",
    "    annotations = item['annotations']\n",
    "    scenes = item['scenes']\n",
    "    poses = item['poses']\n",
    "#     print(\"Nr scenes, poses:\", len(scenes),poses.shape)\n",
    "    #print(\"Currently in\", dataset.dataset_items[i])\n",
    "    #print(\"Shapes:\")\n",
    "    #print(poses.shape)\n",
    "    x_tmp = []\n",
    "    y_tmp = []\n",
    "    for scene,nr in zip(scenes,range(poses.shape[2])):\n",
    "        pose = poses[:,:,nr]\n",
    "        p_x = pose[:,0]\n",
    "        p_y = pose[:,1]\n",
    "#         print(p_x)\n",
    "#         print(p_y)\n",
    "        if (all(p_x == 0) or all(p_y == 0)):\n",
    "            print(\"Problematic pose\")\n",
    "        else:\n",
    "            x_max = np.max([p for p in p_x if p != 0])\n",
    "            x_min = np.min([p for p in p_x if p != 0])\n",
    "            abs_delta_x = x_max-x_min\n",
    "            x_max_list.append(abs_delta_x)\n",
    "            y_max = np.max([p for p in p_y if p != 0])\n",
    "            y_min = np.min([p for p in p_y if p != 0])\n",
    "            abs_delta_y = y_max-y_min\n",
    "            y_max_list.append(abs_delta_y) \n",
    "            if (abs_delta_x > 640):\n",
    "                print(\"Wrong pose\",pose)\n",
    "                \n",
    "crop_max = [np.ceil(max(x_max_list)), np.ceil(max(y_max_list))]\n",
    "print(\"Crop size as double:\",max(x_max_list),max(y_max_list))\n",
    "print(\"Crop size without margin:\",crop_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CasiaDataset()\n",
    "x_max = []\n",
    "y_max = []\n",
    "x_center = []\n",
    "y_center = []\n",
    "\n",
    "margin = 10\n",
    "print(\"Using\", poses.shape[0],\"poses\")\n",
    "invalid_pose_counter = 0\n",
    "im_size_total = [int(crop_max[1] + 2*margin), int(crop_max[0] + 2*margin)]\n",
    "\n",
    "#print(\"Dataset entries\", len(dataset.dataset_items[:])\n",
    "\n",
    "for item, i in zip(dataset, range(len(dataset))):  \n",
    "    annotations = item['annotations']\n",
    "    scenes = item['scenes']\n",
    "    poses = item['poses']\n",
    "    \n",
    "    person = '{:03d}'.format(dataset.dataset_items[i][0]) \n",
    "    sequence = dataset.dataset_items[i][1]\n",
    "    angle = '{:03d}'.format(dataset.dataset_items[i][2])\n",
    "    origin = '/mnt/DATA/HIWI/IBT/CASIA/'\n",
    "    folderpath = origin + 'images/'+ person + '/'+ sequence + '/' + angle + '/'\n",
    "    print(\"current folder: \", folderpath)\n",
    "    pathlib.Path(origin + 'preprocessing/crops/'+ person + '/' + sequence + '/' + sequence + '-' + angle + '/'\n",
    ").mkdir(parents=True, exist_ok = True)\n",
    "    \n",
    "\n",
    "    #print(\"Shapes:\")\n",
    "    #print(poses.shape)\n",
    "    x_tmp = []\n",
    "    y_tmp = []\n",
    "#     print(\"poses shape\", poses.shape)\n",
    "    for j in range(poses.shape[2]):\n",
    "    #for j in range(1):    \n",
    "        if (all(x == 0 for x in poses[:,0,j]) or all(y == 0 for y in poses[:,1,j])):\n",
    "            print(\"invalid poses in \", folderpath)\n",
    "            invalid_pose_counter += 1\n",
    "        else:\n",
    "            x0 = int(np.floor(np.min(poses[np.nonzero(poses[:,1,j]),1,j]))) - margin\n",
    "            x1 = int(np.floor(np.max(poses[np.nonzero(poses[:,1,j]),1,j]))) + margin\n",
    "            y0 = int(np.floor(np.min(poses[np.nonzero(poses[:,0,j]),0,j]))) - margin\n",
    "            y1 = int(np.floor(np.max(poses[np.nonzero(poses[:,0,j]),0,j]))) + margin\n",
    "        \n",
    "            #make sure image borders stay in range\n",
    "            im_size_tmp = Image.fromarray(scenes[j]).size\n",
    "            x0 = max(0,x0)\n",
    "            x1 = min(x1,im_size_tmp[0]-1)\n",
    "            y0 = max(0,y0)\n",
    "            y1 = min(y1,im_size_tmp[1]-1)\n",
    "        \n",
    "            im_tmp = scenes[j][x0:x1,y0:y1]\n",
    "\n",
    "#             plt.imshow(im_tmp)\n",
    "            x_dif = im_size_total[0] - x1 + x0\n",
    "            y_dif = im_size_total[1] - y1 + y0\n",
    "            x_l = np.floor(x_dif/2)\n",
    "            x_r = np.ceil(x_dif/2)\n",
    "            y_l = np.floor(y_dif/2)\n",
    "            y_r = np.ceil(y_dif/2)\n",
    "        \n",
    "            im_pad = np.pad(im_tmp,[(int(x_l),int(x_r)),(int(y_l),int(y_r)),(0,0)],'constant')#,'constant', constant_values=((0, 0),(0,0)))\n",
    "\n",
    "            #plt.imshow(im_pad)\n",
    "            \n",
    "            framename = '{:03d}'.format(j+int(annotations[''][0]))\n",
    "            #print(\"TEST\",parentfolder,anglepath,framename)\n",
    "            saving_path = origin + 'preprocessing/crops/'+ person + '/' + sequence + '/' + sequence + '-' + angle + '/'\n",
    "            filename = person + '-' + sequence + '-' + angle + '_frame_' + framename + '.jpg'\n",
    "            totalpath = saving_path + filename\n",
    "#             print(\"Image name\", filename)\n",
    "#             print(\"Total path\", totalpath)\n",
    "            Image.fromarray(im_pad).save(totalpath)\n",
    "            #im_save.save(totalpath)\n",
    "            \n",
    "            #print(\"i\",i,\"j\",j,\"poses\",poses[:,0,j],poses[:,1,j])\n",
    "            #print(\"invalid path:\",totalpath)\n",
    "            #plt.imshow(im)\n",
    "print(\"Invalid counter:\",invalid_pose_counter)\n",
    "print(\"Done\")\n",
    "\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.max([p for p in p_x if p != 0])\n",
    "print (b)\n",
    "print(len(p_x))\n",
    "# [e for i, e in enumerate(p_x) if e != 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_max_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python gait_36",
   "language": "python",
   "name": "gait_36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
