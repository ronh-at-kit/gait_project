{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import os.path as path\n",
    "import copy\n",
    "# from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "\n",
    "from gait_analysis import AnnotationsCasia as Annotations\n",
    "from gait_analysis import CasiaDataset\n",
    "from gait_analysis.Config import Config\n",
    "from gait_analysis import Composer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configuration  flows\n",
      "[OK]\n"
     ]
    }
   ],
   "source": [
    "#change configuration in settings.py\n",
    "\n",
    "crop_im_size = [186,250]\n",
    "c = Config()\n",
    "c.config['indexing']['grouping'] = 'person_sequence_angle'\n",
    "c.config['indexing']['people selection'] = [1]\n",
    "#c.config['indexing']['sequences_selection'] = ['nm-01']\n",
    "c.config['pose']['load'] = False\n",
    "c.config['flow']['load'] = True\n",
    "c.config['heatmaps']['load'] = False\n",
    "#c.config['scenes']['sequences'] = ['nm']\n",
    "#c.config['scenes']['angles'] = ['108']\n",
    "c.config['dataset_output'] = {\n",
    "#         'data': [\"scenes\",\"flows\",\"heatmaps_LAnkle\",\"heatmaps_RAnkle\"],\n",
    "        'data': ['flows'],\n",
    "        'label': \"annotations\"}\n",
    "composer = Composer()\n",
    "transformer = composer.compose()\n",
    "dataset = CasiaDataset(transform=transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NETWORK AND DATASET PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters defined\n"
     ]
    }
   ],
   "source": [
    "#DESIGN PARAMETERS FOR NEURAL NETWORK\n",
    "NR_LSTM_UNITS = 2 \n",
    "IMAGE_INPUT_SIZE_W = 640\n",
    "IMAGE_INPUT_SIZE_H = 480\n",
    "\n",
    "IMAGE_AFTER_CONV_SIZE_W = 18\n",
    "IMAGE_AFTER_CONV_SIZE_H = 13\n",
    "#for 3x3 kernels, n=num_layers: len_in = 2^n*len_out + sum[i=1..n](2^i)\n",
    "#CONV_LAYER_LENGTH = 5\n",
    "\n",
    "LSTM_IO_SIZE = 18*13\n",
    "LSTM_HIDDEN_SIZE = 18*13\n",
    "\n",
    "RGB_CHANNELS = 3\n",
    "TIMESTEPS = 10 # size videos\n",
    "BATCH_SIZE = 1 #until now just batch_size = 1\n",
    "\n",
    "NR_EPOCHS = 100\n",
    "\n",
    "VALIDATION_SPLIT = 0.2\n",
    "RANDOMIZED_SEED = 10\n",
    "SHUFFLE_DATASET = False\n",
    "\n",
    "learning_rate = 0.01 # reduce factos of 10 .. some epoch later.\n",
    "momentum = 0.9\n",
    "print(\"Hyperparameters defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings \n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 30\n",
      "Indices size: 30\n",
      "Split: 6\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "print(\"Dataset size:\", len(dataset))\n",
    "print(\"Indices size:\", len(indices))\n",
    "split = int(np.floor(VALIDATION_SPLIT * dataset_size))\n",
    "print(\"Split:\", split)\n",
    "if SHUFFLE_DATASET:\n",
    "    np.random.seed(RANDOMIZED_SEED)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "train_sampler = torch.utils.data.SequentialSampler(train_indices)\n",
    "test_sampler = torch.utils.data.SequentialSampler(test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=test_sampler)\n",
    "\n",
    "# #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#USE RANDOM IMAGES TO SET UP WORKING EXAMPLE\n",
    "class TEST_CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TEST_CNN_LSTM, self).__init__()\n",
    "        self.avialable_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3,6,3) #input 640x480\n",
    "        self.pool1 = nn.MaxPool2d(2,2) #input 638x478 output 319x239\n",
    "        self.conv2 = nn.Conv2d(6,16,3) # input 319x239 output 317x237\n",
    "        self.pool2 = nn.MaxPool2d(2,2) # input 317x237 output 158x118\n",
    "        self.conv3 = nn.Conv2d(16,6,3) # input 158x118 output 156x116\n",
    "        self.pool3 = nn.MaxPool2d(2,2) # input 156x116 output 78x58\n",
    "        self.conv4 = nn.Conv2d(6,3,3)  # input 78x58 output 76x56\n",
    "        self.pool4 = nn.MaxPool2d(2,2) # input 76x56 output 39x29\n",
    "        self.conv5 = nn.Conv2d(3,1,3)  # input 39x29 output 37x27\n",
    "        self.pool5 = nn.MaxPool2d(2,2) #output 37x27 output 18x13\n",
    "        self.lstm1 = nn.LSTM(LSTM_IO_SIZE,\n",
    "                            LSTM_HIDDEN_SIZE,\n",
    "                            TIMESTEPS)# horizontal direction\n",
    "        self.lstm2 = nn.LSTM(LSTM_IO_SIZE,\n",
    "                            LSTM_HIDDEN_SIZE,\n",
    "                            TIMESTEPS)# horizontal direction\n",
    "        self.fc1 = nn.Linear(LSTM_IO_SIZE,120)\n",
    "        self.fc2 = nn.Linear(120,20)\n",
    "        self.fc3 = nn.Linear(20,3)\n",
    "        \n",
    "        #initialize hidden states of LSTM\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "        #print(\"Hidden:\", _hidden)\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(TIMESTEPS, BATCH_SIZE, LSTM_HIDDEN_SIZE).to(self.avialable_device), \n",
    "                torch.randn(TIMESTEPS, BATCH_SIZE, LSTM_HIDDEN_SIZE).to(self.avialable_device))\n",
    "    def forward(self,x):\n",
    "#         print(\"Input list len:\",len(x))\n",
    "#         print(\"Input elemens size:\", x[0].size())\n",
    "#         batch_size = x[0].size()[0]\n",
    "\n",
    "        x_arr = torch.zeros(TIMESTEPS,BATCH_SIZE,1,IMAGE_AFTER_CONV_SIZE_H,IMAGE_AFTER_CONV_SIZE_W).to(self.avialable_device)\n",
    "        ## print(\"X arr size\", x_arr.size())\n",
    "        for i in range(TIMESTEPS):#parallel convolutions which are later concatenated for LSTM\n",
    "            x_tmp_c1 = self.pool1(F.relu(self.conv1(x[i].float())))\n",
    "            x_tmp_c2 = self.pool2(F.relu(self.conv2(x_tmp_c1)))\n",
    "            x_tmp_c3 = self.pool3(F.relu(self.conv3(x_tmp_c2)))\n",
    "            x_tmp_c4 = self.pool4(F.relu(self.conv4(x_tmp_c3)))\n",
    "            x_tmp_c5 = self.pool5(F.relu(self.conv5(x_tmp_c4)))\n",
    "            x_arr[i] = x_tmp_c5 # torch.squeeze(x_tmp_c5)\n",
    "        \n",
    "        x, hidden = self.lstm1(x_arr.view(TIMESTEPS,BATCH_SIZE,-1), self.hidden)\n",
    "        x, hidden = self.lstm2(x, self.hidden)\n",
    "        # the reshaping was taken from the documentation... and makes scense\n",
    "        x = x.view(TIMESTEPS,BATCH_SIZE,LSTM_HIDDEN_SIZE) #output.view(seq_len, batch, num_dir*hidden_size)\n",
    "#         x = torch.squeeze(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x) \n",
    "        x = x.permute(1,2,0)\n",
    "        return x\n",
    "print(\"Class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOS:\n",
    "# Look for overfitting..\n",
    "# use GPU: 300 samples. many epochs. learning rate maybe is too high.\n",
    "# Tweak learning rate\n",
    "# Increase the RNN size\n",
    "# Maybe change the CNN\n",
    "# Use patches. or OF\n",
    "# Increase the dataset: 10 images 10peoplo+++ not too much too much variance. \n",
    "# FEEDBACK on friday..:) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#TRAINING\n",
    "test_net = TEST_CNN_LSTM()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "test_net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(test_net.parameters(), lr=learning_rate, momentum=momentum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define and execute testing function\n",
    "def test_all_preds(model):\n",
    "    n_batches_test = len(test_loader)\n",
    "\n",
    "    #Time for printing\n",
    "    testing_start_time = time.time()\n",
    "\n",
    "    print('Start testing...')\n",
    "    correct = 0 \n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            inputs, labels = batch\n",
    "            \n",
    "            data_in = [s.to(device) for s in inputs['flows']]\n",
    "            labels = labels.to(device)\n",
    "            if not labels.size()[0] == BATCH_SIZE:\n",
    "                # skip uncompleted batch size NN is fixed to BATCHSIZE\n",
    "                continue\n",
    "            outputs = model(data_in)\n",
    "#             print(\"Out:\", len(outputs), outputs.size())\n",
    "#             print(\"Labels:\", len(labels), labels.size())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "#             print('predicted:',len(predicted),predicted.size())\n",
    "            n_errors = torch.nonzero(torch.abs(labels.long() - predicted)).size(0)\n",
    "            total += predicted.numel()\n",
    "            # print('predicted',predicted)\n",
    "            correct += predicted.numel() - n_errors\n",
    "            # print('labels',labels)\n",
    "    print('Accuracy {:.2f}%'.format(100*correct/total))\n",
    "    print('...testing finished')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training over all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Expected loss with {} different classes and {} data points: {}  (3, 24, 26.366694928034633)\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/.conda/envs/gait_37/lib/python3.7/site-packages/pandas/core/computation/expressions.py:183: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
      "  .format(op=op_str, alt_op=unsupported[op_str]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss epoch 0: 24.426898419857025, took 70.20054030418396s\n",
      "Epoch: 1\n",
      "Loss epoch 1: 22.995842397212982, took 68.52216720581055s\n",
      "Epoch: 2\n",
      "Loss epoch 2: 21.7490017414093, took 70.3896906375885s\n",
      "Epoch: 3\n",
      "Loss epoch 3: 19.018336474895477, took 69.02420210838318s\n",
      "Epoch: 4\n",
      "Loss epoch 4: 14.965862423181534, took 69.56251215934753s\n",
      "Epoch: 5\n",
      "Loss epoch 5: 12.641344964504242, took 69.26446843147278s\n",
      "Epoch: 6\n",
      "Loss epoch 6: 11.934603452682495, took 69.5945794582367s\n",
      "Epoch: 7\n",
      "Loss epoch 7: 11.786510214209557, took 71.22314667701721s\n",
      "Epoch: 8\n",
      "Loss epoch 8: 11.558038115501404, took 69.30912280082703s\n",
      "Epoch: 9\n",
      "Loss epoch 9: 11.1466573625803, took 69.14262652397156s\n",
      "Epoch: 10\n",
      "Loss epoch 10: 10.762106090784073, took 69.25573587417603s\n",
      "Epoch: 11\n",
      "Loss epoch 11: 10.499803006649017, took 69.76327967643738s\n",
      "Epoch: 12\n",
      "Loss epoch 12: 10.378843367099762, took 69.26860046386719s\n",
      "Epoch: 13\n",
      "Loss epoch 13: 10.324748441576958, took 69.12091946601868s\n",
      "Epoch: 14\n",
      "Loss epoch 14: 10.298743575811386, took 70.73924827575684s\n",
      "Epoch: 15\n",
      "Loss epoch 15: 10.199978083372116, took 72.71208453178406s\n",
      "Epoch: 16\n",
      "Loss epoch 16: 10.078641414642334, took 69.26280856132507s\n",
      "Epoch: 17\n",
      "Loss epoch 17: 9.99195921421051, took 68.93026828765869s\n",
      "Epoch: 18\n",
      "Loss epoch 18: 9.84431605041027, took 69.4321494102478s\n",
      "Epoch: 19\n",
      "Loss epoch 19: 9.765236184000969, took 69.46379017829895s\n",
      "Epoch: 20\n",
      "Loss epoch 20: 9.813195779919624, took 69.98060011863708s\n",
      "Epoch: 21\n",
      "Loss epoch 21: 9.717631429433823, took 69.24375891685486s\n",
      "Epoch: 22\n",
      "Loss epoch 22: 9.602979078888893, took 69.78097748756409s\n",
      "Epoch: 23\n",
      "Loss epoch 23: 9.515234991908073, took 68.73455357551575s\n",
      "Epoch: 24\n",
      "Loss epoch 24: 9.4533411860466, took 69.15568733215332s\n",
      "Epoch: 25\n",
      "Loss epoch 25: 9.490737825632095, took 69.4456250667572s\n",
      "Epoch: 26\n",
      "Loss epoch 26: 9.435091152787209, took 69.61591458320618s\n",
      "Epoch: 27\n",
      "Loss epoch 27: 9.238407641649246, took 69.56900978088379s\n",
      "Epoch: 28\n",
      "Loss epoch 28: 9.091962769627571, took 69.41439008712769s\n",
      "Epoch: 29\n",
      "Loss epoch 29: 9.051523208618164, took 68.82519483566284s\n",
      "Epoch: 30\n",
      "Loss epoch 30: 9.072644338011742, took 75.4689347743988s\n",
      "Epoch: 31\n",
      "Loss epoch 31: 8.99063466489315, took 72.48822093009949s\n",
      "Epoch: 32\n",
      "Loss epoch 32: 8.997627079486847, took 69.7519063949585s\n",
      "Epoch: 33\n",
      "Loss epoch 33: 9.017238512635231, took 70.31822109222412s\n",
      "Epoch: 34\n",
      "Loss epoch 34: 8.777183681726456, took 69.1316785812378s\n",
      "Epoch: 35\n",
      "Loss epoch 35: 8.739517614245415, took 69.48264002799988s\n",
      "Epoch: 36\n",
      "Loss epoch 36: 8.710359781980515, took 69.64482975006104s\n",
      "Epoch: 37\n",
      "Loss epoch 37: 8.676902368664742, took 68.97417974472046s\n",
      "Epoch: 38\n",
      "Loss epoch 38: 8.620933592319489, took 69.16266298294067s\n",
      "Epoch: 39\n",
      "Loss epoch 39: 8.524466410279274, took 70.83996725082397s\n",
      "Learning rate changed 0.01\n",
      "Epoch: 40\n",
      "Loss epoch 40: 6.924375042319298, took 74.03784155845642s\n",
      "Epoch: 41\n",
      "Loss epoch 41: 8.950978338718414, took 70.9551911354065s\n",
      "Epoch: 42\n",
      "Loss epoch 42: 9.328957974910736, took 71.23246026039124s\n",
      "Epoch: 43\n",
      "Loss epoch 43: 8.374181613326073, took 71.25233125686646s\n",
      "Epoch: 44\n",
      "Loss epoch 44: 8.045918941497803, took 69.02487468719482s\n",
      "Epoch: 45\n",
      "Loss epoch 45: 8.16189919412136, took 69.47390460968018s\n",
      "Epoch: 46\n",
      "Loss epoch 46: 8.249719828367233, took 69.1769745349884s\n",
      "Epoch: 47\n",
      "Loss epoch 47: 8.084464430809021, took 68.14498329162598s\n",
      "Epoch: 48\n",
      "Loss epoch 48: 8.02354010939598, took 69.09942865371704s\n",
      "Epoch: 49\n",
      "Loss epoch 49: 7.881506249308586, took 68.45995378494263s\n",
      "Epoch: 50\n",
      "Loss epoch 50: 7.843632683157921, took 68.79066824913025s\n",
      "Epoch: 51\n",
      "Loss epoch 51: 7.806381344795227, took 69.64232325553894s\n",
      "Epoch: 52\n",
      "Loss epoch 52: 7.695756629109383, took 69.0304868221283s\n",
      "Epoch: 53\n",
      "Loss epoch 53: 7.690123483538628, took 75.44170045852661s\n",
      "Epoch: 54\n",
      "Loss epoch 54: 7.683786913752556, took 68.6989574432373s\n",
      "Epoch: 55\n",
      "Loss epoch 55: 7.600455120205879, took 69.47761082649231s\n",
      "Epoch: 56\n",
      "Loss epoch 56: 7.5966091603040695, took 69.695152759552s\n",
      "Epoch: 57\n",
      "Loss epoch 57: 7.502405375242233, took 68.83039951324463s\n",
      "Epoch: 58\n",
      "Loss epoch 58: 7.515509471297264, took 69.8170793056488s\n",
      "Epoch: 59\n",
      "Loss epoch 59: 7.44592447578907, took 69.25752878189087s\n",
      "Epoch: 60\n",
      "Loss epoch 60: 7.393281236290932, took 69.15098643302917s\n",
      "Epoch: 61\n",
      "Loss epoch 61: 7.282780572772026, took 69.43015623092651s\n",
      "Epoch: 62\n",
      "Loss epoch 62: 7.3921626806259155, took 69.88812494277954s\n",
      "Epoch: 63\n",
      "Loss epoch 63: 7.325229197740555, took 69.35318779945374s\n",
      "Epoch: 64\n",
      "Loss epoch 64: 7.276685923337936, took 69.55775690078735s\n",
      "Epoch: 65\n",
      "Loss epoch 65: 7.216507285833359, took 69.61304759979248s\n",
      "Epoch: 66\n",
      "Loss epoch 66: 7.243296608328819, took 68.58823585510254s\n",
      "Epoch: 67\n",
      "Loss epoch 67: 7.106655657291412, took 69.16968536376953s\n",
      "Epoch: 68\n",
      "Loss epoch 68: 6.956432029604912, took 69.67518377304077s\n",
      "Epoch: 69\n",
      "Loss epoch 69: 6.971222147345543, took 71.71000385284424s\n",
      "Epoch: 70\n",
      "Loss epoch 70: 7.076451703906059, took 73.55787086486816s\n",
      "Epoch: 71\n",
      "Loss epoch 71: 6.812893748283386, took 71.4201169013977s\n",
      "Epoch: 72\n",
      "Loss epoch 72: 6.952000439167023, took 69.25803184509277s\n",
      "Epoch: 73\n",
      "Loss epoch 73: 6.762786313891411, took 69.61211442947388s\n",
      "Epoch: 74\n",
      "Loss epoch 74: 6.953267589211464, took 69.21226906776428s\n",
      "Epoch: 75\n",
      "Loss epoch 75: 6.751809284090996, took 70.23759841918945s\n",
      "Epoch: 76\n",
      "Loss epoch 76: 6.72989097237587, took 68.96208214759827s\n",
      "Epoch: 77\n",
      "Loss epoch 77: 6.7384277284145355, took 70.15505957603455s\n",
      "Epoch: 78\n",
      "Loss epoch 78: 6.807375073432922, took 69.2541024684906s\n",
      "Epoch: 79\n",
      "Loss epoch 79: 6.609863311052322, took 69.68664908409119s\n",
      "Epoch: 80\n",
      "Loss epoch 80: 6.521390870213509, took 69.29230213165283s\n",
      "Epoch: 81\n",
      "Loss epoch 81: 6.6840730756521225, took 69.58008599281311s\n",
      "Epoch: 82\n",
      "Loss epoch 82: 6.75995646417141, took 69.20551633834839s\n",
      "Epoch: 83\n",
      "Loss epoch 83: 6.444977313280106, took 69.54997730255127s\n",
      "Epoch: 84\n",
      "Loss epoch 84: 6.533507212996483, took 69.44275832176208s\n",
      "Epoch: 85\n",
      "Loss epoch 85: 6.602669581770897, took 69.64285254478455s\n",
      "Epoch: 86\n",
      "Loss epoch 86: 6.565703272819519, took 70.14527988433838s\n",
      "Epoch: 87\n",
      "Loss epoch 87: 6.459425166249275, took 69.78875851631165s\n",
      "Epoch: 88\n",
      "Loss epoch 88: 6.40238356590271, took 69.33229494094849s\n",
      "Epoch: 89\n",
      "Loss epoch 89: 6.529664158821106, took 68.92479276657104s\n",
      "Epoch: 90\n",
      "Loss epoch 90: 6.432297587394714, took 74.98515295982361s\n",
      "Epoch: 91\n",
      "Loss epoch 91: 6.351007089018822, took 69.59366512298584s\n",
      "Epoch: 92\n",
      "Loss epoch 92: 6.46409960091114, took 69.91715598106384s\n",
      "Epoch: 93\n",
      "Loss epoch 93: 6.380193546414375, took 69.52489447593689s\n",
      "Epoch: 94\n",
      "Loss epoch 94: 6.31159083545208, took 70.69024920463562s\n",
      "Epoch: 95\n",
      "Loss epoch 95: 6.385030031204224, took 69.0397162437439s\n",
      "Epoch: 96\n",
      "Loss epoch 96: 6.390555590391159, took 69.85082173347473s\n",
      "Epoch: 97\n",
      "Loss epoch 97: 6.207758739590645, took 69.22332692146301s\n",
      "Epoch: 98\n",
      "Loss epoch 98: 6.377991870045662, took 70.20490050315857s\n",
      "Epoch: 99\n",
      "Loss epoch 99: 6.41080467402935, took 69.71993112564087s\n",
      "Start testing...\n",
      "Accuracy 87.50%\n",
      "...testing finished\n",
      "...Training finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f10cf337400>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_batches = len(train_loader)\n",
    "\n",
    "#Time for printing\n",
    "training_start_time = time.time()\n",
    "\n",
    "loss_array = np.zeros(NR_EPOCHS)\n",
    "\n",
    "print('Start training...')\n",
    "print('Expected loss with {} different classes and {} data points: {} ', (3, len(dataset)-split, (len(dataset)-split)*np.log(3)))\n",
    "for epoch in range(NR_EPOCHS): \n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    if (epoch == 40):\n",
    "        learning_rate = 0.01\n",
    "        optimizer = optim.SGD(test_net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        print (\"Learning rate changed\", learning_rate)\n",
    "#     if (epoch == 80):\n",
    "#         learning_rate = 0.001\n",
    "#         optimizer = optim.SGD(test_net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "#         print (\"Learning rate changed\", learning_rate)\n",
    "    \n",
    "    print(\"Epoch:\", epoch)\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(train_loader): #loads all angles\n",
    "        inputs, labels = batch\n",
    "        flows = [s.to(device) for s in inputs['flows']]\n",
    "        labels = labels.unsqueeze(-1).to(device)\n",
    "        if not labels.size()[0] == BATCH_SIZE:\n",
    "            # skip uncompleted batch size NN is fixed to BATCHSIZE\n",
    "            continue\n",
    "        optimizer.zero_grad() \n",
    "        outputs = test_net(flows)\n",
    "        outputs = outputs.unsqueeze(-1)\n",
    "        #print(\"Size before permutation:\", outputs.size())\n",
    "        outputs = outputs.permute(0,2,1,3).squeeze(3).squeeze(0)\n",
    "        labels = labels.squeeze(2).squeeze(0)\n",
    "        #print(\"Out:\", len(outputs), outputs.size())\n",
    "        #print(\"Labels:\", len(labels), labels.size())\n",
    "        #print(\"Here\")\n",
    "        #print(scenes[0].squeeze(0).permute(2,1,0).size())\n",
    "        #for j in range(10):\n",
    "        #    scene_print = scenes[j].squeeze(0).permute(1,2,0)\n",
    "        #    plt.imshow(scene_print.numpy())\n",
    "        #    plt.show()\n",
    "        #print(labels)\n",
    "        loss = criterion(outputs,labels.long())\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "        #Print statistics\n",
    "        # print(loss.data.item())\n",
    "        running_loss += loss.data.item()\n",
    "        #total_train_loss += loss.data.item()\n",
    "        \n",
    "        #Print every 10th batch of an epoch\n",
    "#         if (i + 1) % (print_every + 1) == 0:\n",
    "#             print(\"Epoch {}, {:d}% \\t train_loss(mean): {:.2f} took: {:.2f}s\".format(\n",
    "#                     epoch+1, int(100 * (i+1) / n_batches), running_loss/print_every, time.time() - start_time))\n",
    "#             #Reset running loss and time\n",
    "#             running_loss = 0.0\n",
    "#             start_time = time.time()\n",
    "    # test after each epoch\n",
    "    print(\"Loss epoch {}: {}, took {}s\".format(epoch, running_loss,time.time()-start_time))\n",
    "    loss_array[epoch] = running_loss\n",
    "\n",
    "test_all_preds(test_net)\n",
    "#print('total training loss for epoch {}: {:.6f}'.format(epoch+1, total_train_loss))    \n",
    "print('...Training finished')\n",
    "plt.plot(loss_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected loss for untrained set with Cross Entropy:\n",
    "k = number of classes\n",
    "N = number of labeled data in dataset\n",
    "loss_per_prediction = -log(1/k) = log(k)\n",
    "total_loss = sum(log(k)) = N*log(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected loss with {} different classes and {} data points: {}  (3, 24, 26.366694928034633)\n"
     ]
    }
   ],
   "source": [
    "# print(labels.size())\n",
    "# print(outputs.size())\n",
    "# print(labels)\n",
    "# print(outputs)\n",
    "# import matplotlib.pyplot as plt\n",
    "# print(scenes[0].squeeze(0).size())\n",
    "# plt.imshow(scenes[9].squeeze(0).permute(1,2,0))\n",
    "# plt.figure(figsize=(30,40))\n",
    "# print('left foot trans from air to ground')\n",
    "# plt.subplot(131)\n",
    "# plt.imshow(scenes[4])\n",
    "# plt.title('frame 44')\n",
    "# plt.subplot(132)\n",
    "# plt.imshow(scenes[5])\n",
    "# plt.title('frame 45')\n",
    "# plt.subplot(133)\n",
    "# plt.imshow(scenes[6])\n",
    "# plt.title('frame 46')\n",
    "# plt.show()\n",
    "print('Expected loss with {} different classes and {} data points: {} ', (3, len(dataset)-split, (len(dataset)-split)*np.log(3)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python gait_36",
   "language": "python",
   "name": "gait_36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
