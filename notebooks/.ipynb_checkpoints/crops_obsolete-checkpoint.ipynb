{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONFIG\n",
    "\n",
    "from gait_analysis import CasiaDataset\n",
    "from gait_analysis.Config import Config\n",
    "import numpy as np\n",
    "\n",
    "from gait_analysis import CasiaDataset\n",
    "from gait_analysis.Config import Config\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "\n",
    "c = Config()\n",
    "c.config['flow']['load'] = False\n",
    "c.config['pose']['load'] = True\n",
    "c.config['indexing']['grouping'] = 'person_sequence_angle'\n",
    "#c.config['people_selection'] = range(1,2)\n",
    "#c.config['body_keypoints_include_list'] = ['LAnkle','RAnkle','LKnee','RKnee','LHip','RHip', \n",
    "#                                           'LHeel', 'RHeel,', 'LBigToe', 'RBigToe', 'LSmallToe', 'RBigToe']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 12 poses\n",
      "invalid poses\n",
      "invalid poses\n",
      "invalid poses\n",
      "Mean: 122.76471288888888 166.44075555555557\n",
      "Crop size as double: 155.312 229.74200000000002\n",
      "Crop size without margin: [156.0, 230.0]\n"
     ]
    }
   ],
   "source": [
    "dataset = CasiaDataset()\n",
    "#for i in range(len(dataset)):\n",
    "x_max = []\n",
    "y_max = []\n",
    "x_center = []\n",
    "y_center = []\n",
    "invalid_pose_counter = 0\n",
    "print(\"Using\",dataset[0]['poses'].shape[0],\"poses\")\n",
    "for item in dataset: \n",
    "#for i in range(5):\n",
    "    #for listitem in dataset: print(listitem)\n",
    "    annotations = item['annotations']\n",
    "    scenes = item['scenes']\n",
    "    poses = item['poses']\n",
    "    #print(\"Currently in\", dataset.dataset_items[i])\n",
    "    #print(\"Shapes:\")\n",
    "    #print(poses.shape)\n",
    "    x_tmp = []\n",
    "    y_tmp = []\n",
    "    for j in range(poses.shape[2]):\n",
    "#     first = annotations[''][0]\n",
    "#     last = annotations[''][-1]\n",
    "#     for j in range(int(annotations[''][0]),int(annotations[''][-1])):\n",
    "        if (all(x == 0 for x in poses[:,0,j]) or all(y == 0 for y in poses[:,1,j])):\n",
    "            print(\"invalid poses\")\n",
    "        else:\n",
    "            abs_delta_x = np.max((poses[np.nonzero(poses[:,0,j]),0,j]) \n",
    "                                 - np.min(poses[np.nonzero(poses[:,0,j]),0,j]))\n",
    "            abs_delta_y = np.max((poses[np.nonzero(poses[:,1,j]),1,j]) \n",
    "                                  - np.min(poses[np.nonzero(poses[:,1,j]),1,j]))\n",
    "\n",
    "            x_tmp.append(abs_delta_x)\n",
    "            y_tmp.append(abs_delta_y)\n",
    "\n",
    "    x_max.append(max(x_tmp))\n",
    "    y_max.append(max(y_tmp))\n",
    "\n",
    "crop_max = [np.ceil(max(x_max)), np.ceil(max(y_max))]\n",
    "print(\"Mean:\",np.mean(x_max),np.mean(y_max))\n",
    "print(\"Crop size as double:\",max(x_max),max(y_max))\n",
    "print(\"Crop size without margin:\",crop_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 2, 58)\n"
     ]
    }
   ],
   "source": [
    "print(poses.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 12 poses\n",
      "current folder:  /mnt/DATA/HIWI/IBT/CASIA/images/001/bg-01/018/\n",
      "current folder:  /mnt/DATA/HIWI/IBT/CASIA/images/001/bg-01/054/\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-c804ee439842>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m ).mkdir(parents=True, exist_ok = True)\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#generates output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annotations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mscenes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scenes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gait_project/gait_analysis/DataSets/CasiaDataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'scenes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscenes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'valid_indices'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0min_frame_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scenes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscenes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'flows'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'valid_indices'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0min_frame_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gait_project/gait_analysis/DataSets/ScenesCasia.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Loading scene images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_scene\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gait_project/gait_analysis/DataSets/ScenesCasia.py\u001b[0m in \u001b[0;36m_load_scene\u001b[0;34m(self, dataset_item)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mscene_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscene_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscene_images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gait_project/gait_analysis/DataSets/ScenesCasia.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mscene_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscene_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscene_images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gait_project/gait_analysis/DataSets/ScenesCasia.py\u001b[0m in \u001b[0;36mread_image\u001b[0;34m(im_file)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} don\\'t exist.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = CasiaDataset()\n",
    "x_max = []\n",
    "y_max = []\n",
    "x_center = []\n",
    "y_center = []\n",
    "\n",
    "margin = 10\n",
    "print(\"Using\", poses.shape[0],\"poses\")\n",
    "invalid_pose_counter = 0\n",
    "im_size_total = [int(crop_max[1] + 2*margin), int(crop_max[0] + 2*margin)]\n",
    "\n",
    "#print(\"Dataset entries\", len(dataset.dataset_items[:])\n",
    "\n",
    "for i in range(len(dataset)):  \n",
    "#for i in range(10):\n",
    "#     print(\"Len dataset:\", len(dataset))\n",
    "    person = '{:03d}'.format(dataset.dataset_items[i][0]) \n",
    "    sequence = dataset.dataset_items[i][1]\n",
    "    angle = '{:03d}'.format(dataset.dataset_items[i][2])\n",
    "    origin = '/mnt/DATA/HIWI/IBT/CASIA/'\n",
    "    folderpath = origin + 'images/'+ person + '/'+ sequence + '/' + angle + '/'\n",
    "    print(\"current folder: \", folderpath)\n",
    "    pathlib.Path(origin + 'preprocessing/crops/'+ person + '/' + sequence + '/' + sequence + '-' + angle + '/'\n",
    ").mkdir(parents=True, exist_ok = True)\n",
    "    \n",
    "    item = dataset[i] #generates output\n",
    "    annotations = item['annotations']\n",
    "    scenes = item['scenes']\n",
    "    poses = item['poses']\n",
    "    #print(\"Shapes:\")\n",
    "    #print(poses.shape)\n",
    "    x_tmp = []\n",
    "    y_tmp = []\n",
    "#     print(\"poses shape\", poses.shape)\n",
    "    for j in range(poses.shape[2]):\n",
    "    #for j in range(1):    \n",
    "        if (all(x == 0 for x in poses[:,0,j]) or all(y == 0 for y in poses[:,1,j])):\n",
    "            print(\"invalid poses in \", folderpath)\n",
    "            invalid_pose_counter += 1\n",
    "        else:\n",
    "            x0 = int(np.floor(np.min(poses[np.nonzero(poses[:,1,j]),1,j]))) - margin\n",
    "            x1 = int(np.floor(np.max(poses[np.nonzero(poses[:,1,j]),1,j]))) + margin\n",
    "            y0 = int(np.floor(np.min(poses[np.nonzero(poses[:,0,j]),0,j]))) - margin\n",
    "            y1 = int(np.floor(np.max(poses[np.nonzero(poses[:,0,j]),0,j]))) + margin\n",
    "        \n",
    "            #make sure image borders stay in range\n",
    "            im_size_tmp = Image.fromarray(scenes[j]).size\n",
    "            x0 = max(0,x0)\n",
    "            x1 = min(x1,im_size_tmp[0]-1)\n",
    "            y0 = max(0,y0)\n",
    "            y1 = min(y1,im_size_tmp[1]-1)\n",
    "        \n",
    "            im_tmp = scenes[j][x0:x1,y0:y1]\n",
    "\n",
    "#             plt.imshow(im_tmp)\n",
    "            x_dif = im_size_total[0] - x1 + x0\n",
    "            y_dif = im_size_total[1] - y1 + y0\n",
    "            x_l = np.floor(x_dif/2)\n",
    "            x_r = np.ceil(x_dif/2)\n",
    "            y_l = np.floor(y_dif/2)\n",
    "            y_r = np.ceil(y_dif/2)\n",
    "        \n",
    "            im_pad = np.pad(im_tmp,[(int(x_l),int(x_r)),(int(y_l),int(y_r)),(0,0)],'constant')#,'constant', constant_values=((0, 0),(0,0)))\n",
    "\n",
    "            #plt.imshow(im_pad)\n",
    "            \n",
    "            framename = '{:03d}'.format(j+int(annotations[''][0]))\n",
    "            #print(\"TEST\",parentfolder,anglepath,framename)\n",
    "            saving_path = origin + 'preprocessing/crops/'+ person + '/' + sequence + '/' + sequence + '-' + angle + '/'\n",
    "            filename = person + '-' + sequence + '-' + angle + '_frame_' + framename + '.jpg'\n",
    "            totalpath = saving_path + filename\n",
    "#             print(\"Image name\", filename)\n",
    "#             print(\"Total path\", totalpath)\n",
    "            Image.fromarray(im_pad).save(totalpath)\n",
    "            #im_save.save(totalpath)\n",
    "            \n",
    "            #print(\"i\",i,\"j\",j,\"poses\",poses[:,0,j],poses[:,1,j])\n",
    "            #print(\"invalid path:\",totalpath)\n",
    "            #plt.imshow(im)\n",
    "print(\"Invalid counter:\",invalid_pose_counter)\n",
    "print(\"Done\")\n",
    "\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j+int(annotations[''][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python gait_36",
   "language": "python",
   "name": "gait_36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
