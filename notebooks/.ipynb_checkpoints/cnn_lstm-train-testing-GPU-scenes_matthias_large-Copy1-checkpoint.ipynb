{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import os.path as path\n",
    "import copy\n",
    "# from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "\n",
    "from gait_analysis import AnnotationsCasia as Annotations\n",
    "from gait_analysis import CasiaDataset\n",
    "from gait_analysis.Config import Config\n",
    "from gait_analysis import Composer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configuration  scenes\n",
      "[OK]\n"
     ]
    }
   ],
   "source": [
    "#change configuration in settings.py\n",
    "\n",
    "crop_im_size = [186,250]\n",
    "c = Config()\n",
    "c.config['indexing']['grouping'] = 'person_sequence_angle'\n",
    "c.config['indexing']['people selection'] = [1]\n",
    "#c.config['indexing']['sequences_selection'] = ['nm-01']\n",
    "c.config['pose']['load'] = False\n",
    "c.config['flow']['load'] = False\n",
    "c.config['heatmaps']['load'] = False\n",
    "#c.config['scenes']['sequences'] = ['nm']\n",
    "#c.config['scenes']['angles'] = ['108']\n",
    "c.config['dataset_output'] = {\n",
    "#         'data': [\"scenes\",\"flows\",\"heatmaps_LAnkle\",\"heatmaps_RAnkle\"],\n",
    "        'data': [\"scenes\"],\n",
    "        'label': \"annotations\"}\n",
    "composer = Composer()\n",
    "transformer = composer.compose()\n",
    "dataset = CasiaDataset(transform=transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NETWORK AND DATASET PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters defined\n"
     ]
    }
   ],
   "source": [
    "#DESIGN PARAMETERS FOR NEURAL NETWORK\n",
    "NR_LSTM_UNITS = 2 \n",
    "IMAGE_INPUT_SIZE_W = 640\n",
    "IMAGE_INPUT_SIZE_H = 480\n",
    "\n",
    "IMAGE_AFTER_CONV_SIZE_W = 18\n",
    "IMAGE_AFTER_CONV_SIZE_H = 13\n",
    "#for 3x3 kernels, n=num_layers: len_in = 2^n*len_out + sum[i=1..n](2^i)\n",
    "#CONV_LAYER_LENGTH = 5\n",
    "\n",
    "LSTM_IO_SIZE = 18*13\n",
    "LSTM_HIDDEN_SIZE = 18*13\n",
    "\n",
    "RGB_CHANNELS = 3\n",
    "TIMESTEPS = 10 # size videos\n",
    "BATCH_SIZE = 1 #until now just batch_size = 1\n",
    "\n",
    "NR_EPOCHS = 100\n",
    "\n",
    "VALIDATION_SPLIT = 0.2\n",
    "RANDOMIZED_SEED = 10\n",
    "SHUFFLE_DATASET = False\n",
    "\n",
    "learning_rate = 0.01 # reduce factos of 10 .. some epoch later.\n",
    "momentum = 0.9\n",
    "print(\"Hyperparameters defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings \n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 30\n",
      "Indices size: 30\n",
      "Split: 6\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "print(\"Dataset size:\", len(dataset))\n",
    "print(\"Indices size:\", len(indices))\n",
    "split = int(np.floor(VALIDATION_SPLIT * dataset_size))\n",
    "print(\"Split:\", split)\n",
    "if SHUFFLE_DATASET:\n",
    "    np.random.seed(RANDOMIZED_SEED)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "train_sampler = torch.utils.data.SequentialSampler(train_indices)\n",
    "test_sampler = torch.utils.data.SequentialSampler(test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=test_sampler)\n",
    "\n",
    "# #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#USE RANDOM IMAGES TO SET UP WORKING EXAMPLE\n",
    "class TEST_CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TEST_CNN_LSTM, self).__init__()\n",
    "        self.avialable_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3,6,3) #input 640x480\n",
    "        self.pool1 = nn.MaxPool2d(2,2) #input 638x478 output 319x239\n",
    "        self.conv2 = nn.Conv2d(6,16,3) # input 319x239 output 317x237\n",
    "        self.pool2 = nn.MaxPool2d(2,2) # input 317x237 output 158x118\n",
    "        self.conv3 = nn.Conv2d(16,6,3) # input 158x118 output 156x116\n",
    "        self.pool3 = nn.MaxPool2d(2,2) # input 156x116 output 78x58\n",
    "        self.conv4 = nn.Conv2d(6,3,3)  # input 78x58 output 76x56\n",
    "        self.pool4 = nn.MaxPool2d(2,2) # input 76x56 output 39x29\n",
    "        self.conv5 = nn.Conv2d(3,1,3)  # input 39x29 output 37x27\n",
    "        self.pool5 = nn.MaxPool2d(2,2) #output 37x27 output 18x13\n",
    "        self.lstm1 = nn.LSTM(LSTM_IO_SIZE,\n",
    "                            LSTM_HIDDEN_SIZE,\n",
    "                            TIMESTEPS)# horizontal direction\n",
    "        self.lstm2 = nn.LSTM(LSTM_IO_SIZE,\n",
    "                            LSTM_HIDDEN_SIZE,\n",
    "                            TIMESTEPS)# horizontal direction\n",
    "        self.fc1 = nn.Linear(LSTM_IO_SIZE,120)\n",
    "        self.fc2 = nn.Linear(120,20)\n",
    "        self.fc3 = nn.Linear(20,3)\n",
    "        \n",
    "        #initialize hidden states of LSTM\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "        #print(\"Hidden:\", _hidden)\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(TIMESTEPS, BATCH_SIZE, LSTM_HIDDEN_SIZE).to(self.avialable_device), \n",
    "                torch.randn(TIMESTEPS, BATCH_SIZE, LSTM_HIDDEN_SIZE).to(self.avialable_device))\n",
    "    def forward(self,x):\n",
    "#         print(\"Input list len:\",len(x))\n",
    "#         print(\"Input elemens size:\", x[0].size())\n",
    "#         batch_size = x[0].size()[0]\n",
    "\n",
    "        x_arr = torch.zeros(TIMESTEPS,BATCH_SIZE,1,IMAGE_AFTER_CONV_SIZE_H,IMAGE_AFTER_CONV_SIZE_W).to(self.avialable_device)\n",
    "        ## print(\"X arr size\", x_arr.size())\n",
    "        for i in range(TIMESTEPS):#parallel convolutions which are later concatenated for LSTM\n",
    "            x_tmp_c1 = self.pool1(F.relu(self.conv1(x[i].float())))\n",
    "            x_tmp_c2 = self.pool2(F.relu(self.conv2(x_tmp_c1)))\n",
    "            x_tmp_c3 = self.pool3(F.relu(self.conv3(x_tmp_c2)))\n",
    "            x_tmp_c4 = self.pool4(F.relu(self.conv4(x_tmp_c3)))\n",
    "            x_tmp_c5 = self.pool5(F.relu(self.conv5(x_tmp_c4)))\n",
    "            x_arr[i] = x_tmp_c5 # torch.squeeze(x_tmp_c5)\n",
    "        \n",
    "        x, hidden = self.lstm1(x_arr.view(TIMESTEPS,BATCH_SIZE,-1), self.hidden)\n",
    "        x, hidden = self.lstm2(x, self.hidden)\n",
    "        # the reshaping was taken from the documentation... and makes scense\n",
    "        x = x.view(TIMESTEPS,BATCH_SIZE,LSTM_HIDDEN_SIZE) #output.view(seq_len, batch, num_dir*hidden_size)\n",
    "#         x = torch.squeeze(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x) \n",
    "        x = x.permute(1,2,0)\n",
    "        return x\n",
    "print(\"Class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOS:\n",
    "# Look for overfitting..\n",
    "# use GPU: 300 samples. many epochs. learning rate maybe is too high.\n",
    "# Tweak learning rate\n",
    "# Increase the RNN size\n",
    "# Maybe change the CNN\n",
    "# Use patches. or OF\n",
    "# Increase the dataset: 10 images 10peoplo+++ not too much too much variance. \n",
    "# FEEDBACK on friday..:) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#TRAINING\n",
    "test_net = TEST_CNN_LSTM()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "test_net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(test_net.parameters(), lr=learning_rate, momentum=momentum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define and execute testing function\n",
    "def test_all_preds(model):\n",
    "    n_batches_test = len(test_loader)\n",
    "\n",
    "    #Time for printing\n",
    "    testing_start_time = time.time()\n",
    "\n",
    "    print('Start testing...')\n",
    "    correct = 0 \n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            inputs, labels = batch\n",
    "            \n",
    "            scenes = [s.to(device) for s in inputs['scenes']]\n",
    "            labels = labels.to(device)\n",
    "            if not labels.size()[0] == BATCH_SIZE:\n",
    "                # skip uncompleted batch size NN is fixed to BATCHSIZE\n",
    "                continue\n",
    "            outputs = model(scenes)\n",
    "#             print(\"Out:\", len(outputs), outputs.size())\n",
    "#             print(\"Labels:\", len(labels), labels.size())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "#             print('predicted:',len(predicted),predicted.size())\n",
    "            n_errors = torch.nonzero(torch.abs(labels.long() - predicted)).size(0)\n",
    "            total += predicted.numel()\n",
    "            # print('predicted',predicted)\n",
    "            correct += predicted.numel() - n_errors\n",
    "            # print('labels',labels)\n",
    "    print('Accuracy {:.2f}%'.format(100*correct/total))\n",
    "    print('...testing finished')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training over all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/.conda/envs/gait_37/lib/python3.7/site-packages/pandas/core/computation/expressions.py:183: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
      "  .format(op=op_str, alt_op=unsupported[op_str]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss epoch 0: 25.11960130929947, took 57.304222106933594s\n",
      "Epoch: 1\n",
      "Loss epoch 1: 22.79861092567444, took 54.65706920623779s\n",
      "Epoch: 2\n",
      "Loss epoch 2: 20.797683894634247, took 56.34870886802673s\n",
      "Epoch: 3\n",
      "Loss epoch 3: 17.19485741853714, took 57.516353607177734s\n",
      "Epoch: 4\n",
      "Loss epoch 4: 13.851271539926529, took 56.39114999771118s\n",
      "Epoch: 5\n",
      "Loss epoch 5: 12.423924505710602, took 55.06913423538208s\n",
      "Epoch: 6\n",
      "Loss epoch 6: 11.878589004278183, took 53.33068132400513s\n",
      "Epoch: 7\n",
      "Loss epoch 7: 11.627152234315872, took 53.24469780921936s\n",
      "Epoch: 8\n",
      "Loss epoch 8: 11.365427792072296, took 53.109644412994385s\n",
      "Epoch: 9\n",
      "Loss epoch 9: 11.023528784513474, took 52.754942893981934s\n",
      "Epoch: 10\n",
      "Loss epoch 10: 10.623805075883865, took 52.837602615356445s\n",
      "Epoch: 11\n",
      "Loss epoch 11: 10.521677359938622, took 52.68549370765686s\n",
      "Epoch: 12\n",
      "Loss epoch 12: 10.482315093278885, took 52.75020933151245s\n",
      "Epoch: 13\n",
      "Loss epoch 13: 10.385836347937584, took 52.9321403503418s\n",
      "Epoch: 14\n",
      "Loss epoch 14: 10.27272154390812, took 52.88491153717041s\n",
      "Epoch: 15\n",
      "Loss epoch 15: 10.146821692585945, took 53.24278259277344s\n",
      "Epoch: 16\n",
      "Loss epoch 16: 10.04402607679367, took 52.47895526885986s\n",
      "Epoch: 17\n",
      "Loss epoch 17: 9.940214112401009, took 52.98548769950867s\n",
      "Epoch: 18\n",
      "Loss epoch 18: 9.824046522378922, took 52.991262674331665s\n",
      "Epoch: 19\n",
      "Loss epoch 19: 9.817866384983063, took 52.96106743812561s\n",
      "Epoch: 20\n",
      "Loss epoch 20: 9.768300220370293, took 53.46126842498779s\n",
      "Epoch: 21\n",
      "Loss epoch 21: 9.620763540267944, took 53.09287405014038s\n",
      "Epoch: 22\n",
      "Loss epoch 22: 9.50783522427082, took 56.96228790283203s\n",
      "Epoch: 23\n",
      "Loss epoch 23: 9.424769699573517, took 53.419100522994995s\n",
      "Epoch: 24\n",
      "Loss epoch 24: 9.253095597028732, took 53.13969349861145s\n",
      "Epoch: 25\n",
      "Loss epoch 25: 9.16985934972763, took 53.387558937072754s\n",
      "Epoch: 26\n",
      "Loss epoch 26: 9.117064252495766, took 52.85779881477356s\n",
      "Epoch: 27\n",
      "Loss epoch 27: 9.03017047047615, took 52.966341495513916s\n",
      "Epoch: 28\n",
      "Loss epoch 28: 8.973612979054451, took 53.130247354507446s\n",
      "Epoch: 29\n",
      "Loss epoch 29: 8.856144174933434, took 53.17926526069641s\n",
      "Epoch: 30\n",
      "Loss epoch 30: 8.759930029511452, took 53.291839599609375s\n",
      "Epoch: 31\n",
      "Loss epoch 31: 8.723803877830505, took 52.984068393707275s\n",
      "Epoch: 32\n",
      "Loss epoch 32: 8.657674744725227, took 52.73839092254639s\n",
      "Epoch: 33\n",
      "Loss epoch 33: 8.6559679210186, took 53.01388192176819s\n",
      "Epoch: 34\n",
      "Loss epoch 34: 8.520115107297897, took 53.17224383354187s\n",
      "Epoch: 35\n",
      "Loss epoch 35: 8.450143903493881, took 52.779226541519165s\n",
      "Epoch: 36\n",
      "Loss epoch 36: 8.396247252821922, took 52.8988835811615s\n",
      "Epoch: 37\n",
      "Loss epoch 37: 8.35253718495369, took 53.16377544403076s\n",
      "Epoch: 38\n",
      "Loss epoch 38: 8.307493910193443, took 52.87771797180176s\n",
      "Epoch: 39\n",
      "Loss epoch 39: 8.182427436113358, took 53.26814842224121s\n",
      "Epoch: 40\n",
      "Loss epoch 40: 8.154130637645721, took 52.836993932724s\n",
      "Epoch: 41\n",
      "Loss epoch 41: 8.198102489113808, took 53.0592565536499s\n",
      "Epoch: 42\n",
      "Loss epoch 42: 8.054382219910622, took 52.66671967506409s\n",
      "Epoch: 43\n",
      "Loss epoch 43: 7.998129233717918, took 52.943930864334106s\n",
      "Epoch: 44\n",
      "Loss epoch 44: 7.942004531621933, took 53.32933759689331s\n",
      "Epoch: 45\n",
      "Loss epoch 45: 7.961955472826958, took 52.817816495895386s\n",
      "Epoch: 46\n",
      "Loss epoch 46: 7.891644895076752, took 53.136064529418945s\n",
      "Epoch: 47\n",
      "Loss epoch 47: 7.827713757753372, took 53.13444113731384s\n",
      "Epoch: 48\n",
      "Loss epoch 48: 7.806113764643669, took 53.183679819107056s\n",
      "Epoch: 49\n",
      "Loss epoch 49: 7.831274002790451, took 53.64628887176514s\n",
      "Epoch: 50\n",
      "Loss epoch 50: 7.729202151298523, took 53.33763360977173s\n",
      "Epoch: 51\n",
      "Loss epoch 51: 7.669051304459572, took 53.7876501083374s\n",
      "Epoch: 52\n",
      "Loss epoch 52: 7.640143394470215, took 53.110191106796265s\n",
      "Epoch: 53\n",
      "Loss epoch 53: 7.624144822359085, took 53.80616116523743s\n",
      "Epoch: 54\n",
      "Loss epoch 54: 7.596604600548744, took 54.14618277549744s\n",
      "Epoch: 55\n",
      "Loss epoch 55: 7.609852716326714, took 54.09904360771179s\n",
      "Epoch: 56\n",
      "Loss epoch 56: 7.459812477231026, took 52.838258266448975s\n",
      "Epoch: 57\n",
      "Loss epoch 57: 7.497727796435356, took 53.68212532997131s\n",
      "Epoch: 58\n",
      "Loss epoch 58: 7.398345157504082, took 53.95559644699097s\n",
      "Epoch: 59\n",
      "Loss epoch 59: 7.386646598577499, took 53.14195013046265s\n",
      "Epoch: 60\n",
      "Loss epoch 60: 7.340197756886482, took 53.21331238746643s\n",
      "Epoch: 61\n",
      "Loss epoch 61: 7.225543826818466, took 53.48821210861206s\n",
      "Epoch: 62\n",
      "Loss epoch 62: 7.2090452164411545, took 53.943235874176025s\n",
      "Epoch: 63\n",
      "Loss epoch 63: 7.274720340967178, took 57.83245921134949s\n",
      "Epoch: 64\n",
      "Loss epoch 64: 7.166781634092331, took 55.01655888557434s\n",
      "Epoch: 65\n",
      "Loss epoch 65: 7.022718444466591, took 53.55024528503418s\n",
      "Epoch: 66\n",
      "Loss epoch 66: 7.172413215041161, took 53.456421852111816s\n",
      "Epoch: 67\n",
      "Loss epoch 67: 7.071886494755745, took 53.18215560913086s\n",
      "Epoch: 68\n",
      "Loss epoch 68: 6.940195173025131, took 53.057881593704224s\n",
      "Epoch: 69\n",
      "Loss epoch 69: 7.100105360150337, took 53.42443776130676s\n",
      "Epoch: 70\n",
      "Loss epoch 70: 6.958392396569252, took 53.45145058631897s\n",
      "Epoch: 71\n",
      "Loss epoch 71: 6.956518590450287, took 53.20166778564453s\n",
      "Epoch: 72\n",
      "Loss epoch 72: 6.96506167948246, took 52.99026942253113s\n",
      "Epoch: 73\n",
      "Loss epoch 73: 6.841646611690521, took 53.43718957901001s\n",
      "Epoch: 74\n",
      "Loss epoch 74: 6.9706022292375565, took 52.58673310279846s\n",
      "Epoch: 75\n",
      "Loss epoch 75: 6.818413898348808, took 53.01239085197449s\n",
      "Epoch: 76\n",
      "Loss epoch 76: 6.807726353406906, took 52.91095232963562s\n",
      "Epoch: 77\n",
      "Loss epoch 77: 6.991647943854332, took 60.44248700141907s\n",
      "Epoch: 78\n",
      "Loss epoch 78: 6.718843266367912, took 55.81052780151367s\n",
      "Epoch: 79\n",
      "Loss epoch 79: 6.763112023472786, took 55.015690088272095s\n",
      "Epoch: 80\n",
      "Loss epoch 80: 6.901809394359589, took 54.337801694869995s\n",
      "Epoch: 81\n",
      "Loss epoch 81: 6.68670479953289, took 53.13518834114075s\n",
      "Epoch: 82\n",
      "Loss epoch 82: 6.713022768497467, took 53.143397092819214s\n",
      "Epoch: 83\n",
      "Loss epoch 83: 6.797503486275673, took 53.10312747955322s\n",
      "Epoch: 84\n",
      "Loss epoch 84: 6.635236591100693, took 53.48083448410034s\n",
      "Epoch: 85\n",
      "Loss epoch 85: 6.681011646986008, took 53.16951775550842s\n",
      "Epoch: 86\n",
      "Loss epoch 86: 6.8220063000917435, took 52.968483686447144s\n",
      "Epoch: 87\n",
      "Loss epoch 87: 6.559915289282799, took 53.435713052749634s\n",
      "Epoch: 88\n",
      "Loss epoch 88: 6.612861141562462, took 53.55860376358032s\n",
      "Epoch: 89\n",
      "Loss epoch 89: 6.66098116338253, took 53.41703486442566s\n",
      "Epoch: 90\n",
      "Loss epoch 90: 6.731233641505241, took 53.544567584991455s\n",
      "Epoch: 91\n",
      "Loss epoch 91: 6.4861298352479935, took 52.77562117576599s\n",
      "Epoch: 92\n",
      "Loss epoch 92: 6.587747827172279, took 53.000020265579224s\n",
      "Epoch: 93\n",
      "Loss epoch 93: 6.5877958089113235, took 53.496588468551636s\n",
      "Epoch: 94\n",
      "Loss epoch 94: 6.609908118844032, took 53.22924065589905s\n",
      "Epoch: 95\n",
      "Loss epoch 95: 6.458306938409805, took 52.77388119697571s\n",
      "Epoch: 96\n",
      "Loss epoch 96: 6.519057422876358, took 53.72615838050842s\n",
      "Epoch: 97\n",
      "Loss epoch 97: 6.502914234995842, took 52.85850548744202s\n",
      "Epoch: 98\n",
      "Loss epoch 98: 6.5547744035720825, took 53.490259647369385s\n",
      "Epoch: 99\n",
      "Loss epoch 99: 6.412259832024574, took 53.325084924697876s\n",
      "Start testing...\n",
      "Accuracy 87.50%\n",
      "...testing finished\n",
      "...Training finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f796a5afda0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_batches = len(train_loader)\n",
    "\n",
    "#Time for printing\n",
    "training_start_time = time.time()\n",
    "\n",
    "loss_array = np.zeros(NR_EPOCHS)\n",
    "\n",
    "print('Start training...')\n",
    "for epoch in range(NR_EPOCHS): \n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    total_train_loss = 0\n",
    "    \n",
    "#     if (epoch == 80):\n",
    "#         learning_rate = 0.001\n",
    "#         optimizer = optim.SGD(test_net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "#         print (\"Learning rate changed\", learning_rate)\n",
    "#     if (epoch == 80):\n",
    "#         learning_rate = 0.001\n",
    "#         optimizer = optim.SGD(test_net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "#         print (\"Learning rate changed\", learning_rate)\n",
    "    \n",
    "    print(\"Epoch:\", epoch)\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(train_loader): #loads all angles\n",
    "        inputs, labels = batch\n",
    "        scenes = [s.to(device) for s in inputs['scenes']]\n",
    "        labels = labels.unsqueeze(-1).to(device)\n",
    "        if not labels.size()[0] == BATCH_SIZE:\n",
    "            # skip uncompleted batch size NN is fixed to BATCHSIZE\n",
    "            continue\n",
    "        optimizer.zero_grad() \n",
    "        outputs = test_net(scenes)\n",
    "        outputs = outputs.unsqueeze(-1)\n",
    "        #print(\"Size before permutation:\", outputs.size())\n",
    "        outputs = outputs.permute(0,2,1,3).squeeze(3).squeeze(0)\n",
    "        labels = labels.squeeze(2).squeeze(0)\n",
    "        #print(\"Out:\", len(outputs), outputs.size())\n",
    "        #print(\"Labels:\", len(labels), labels.size())\n",
    "        #print(\"Here\")\n",
    "        #print(scenes[0].squeeze(0).permute(2,1,0).size())\n",
    "        #for j in range(10):\n",
    "        #    scene_print = scenes[j].squeeze(0).permute(1,2,0)\n",
    "        #    plt.imshow(scene_print.numpy())\n",
    "        #    plt.show()\n",
    "        #print(labels)\n",
    "        loss = criterion(outputs,labels.long())\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "        #Print statistics\n",
    "        # print(loss.data.item())\n",
    "        running_loss += loss.data.item()\n",
    "        #total_train_loss += loss.data.item()\n",
    "        \n",
    "        #Print every 10th batch of an epoch\n",
    "#         if (i + 1) % (print_every + 1) == 0:\n",
    "#             print(\"Epoch {}, {:d}% \\t train_loss(mean): {:.2f} took: {:.2f}s\".format(\n",
    "#                     epoch+1, int(100 * (i+1) / n_batches), running_loss/print_every, time.time() - start_time))\n",
    "#             #Reset running loss and time\n",
    "#             running_loss = 0.0\n",
    "#             start_time = time.time()\n",
    "    # test after each epoch\n",
    "    print(\"Loss epoch {}: {}, took {}s\".format(epoch, running_loss,time.time()-start_time))\n",
    "    loss_array[epoch] = running_loss\n",
    "\n",
    "test_all_preds(test_net)\n",
    "#print('total training loss for epoch {}: {:.6f}'.format(epoch+1, total_train_loss))    \n",
    "print('...Training finished')\n",
    "plt.plot(loss_array)\n",
    "plt.plot(loss_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(labels.size())\n",
    "# print(outputs.size())\n",
    "# print(labels)\n",
    "# print(outputs)\n",
    "# import matplotlib.pyplot as plt\n",
    "# print(scenes[0].squeeze(0).size())\n",
    "# plt.imshow(scenes[9].squeeze(0).permute(1,2,0))\n",
    "# plt.figure(figsize=(30,40))\n",
    "# print('left foot trans from air to ground')\n",
    "# plt.subplot(131)\n",
    "# plt.imshow(scenes[4])\n",
    "# plt.title('frame 44')\n",
    "# plt.subplot(132)\n",
    "# plt.imshow(scenes[5])\n",
    "# plt.title('frame 45')\n",
    "# plt.subplot(133)\n",
    "# plt.imshow(scenes[6])\n",
    "# plt.title('frame 46')\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python gait_37",
   "language": "python",
   "name": "gait_37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
