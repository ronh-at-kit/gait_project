{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import os.path as path\n",
    "import copy\n",
    "# from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "\n",
    "from gait_analysis import AnnotationsCasia as Annotations\n",
    "from gait_analysis import CasiaDataset\n",
    "from gait_analysis.Config import Config\n",
    "from gait_analysis import Composer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configuration  scenes\n",
      "[OK]\n"
     ]
    }
   ],
   "source": [
    "#change configuration in settings.py\n",
    "\n",
    "crop_im_size = [186,250]\n",
    "c = Config()\n",
    "c.config['indexing']['grouping'] = 'person_sequence_angle'\n",
    "c.config['indexing']['people selection'] = [1]\n",
    "#c.config['indexing']['sequences_selection'] = ['nm-01']\n",
    "c.config['pose']['load'] = False\n",
    "c.config['flow']['load'] = False\n",
    "c.config['heatmaps']['load'] = False\n",
    "#c.config['scenes']['sequences'] = ['nm']\n",
    "#c.config['scenes']['angles'] = ['108']\n",
    "c.config['dataset_output'] = {\n",
    "#         'data': [\"scenes\",\"flows\",\"heatmaps_LAnkle\",\"heatmaps_RAnkle\"],\n",
    "        'data': [\"scenes\"],\n",
    "        'label': \"annotations\"}\n",
    "composer = Composer()\n",
    "transformer = composer.compose()\n",
    "dataset = CasiaDataset(transform=transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NETWORK AND DATASET PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters defined\n"
     ]
    }
   ],
   "source": [
    "#DESIGN PARAMETERS FOR NEURAL NETWORK\n",
    "NR_LSTM_UNITS = 2 \n",
    "IMAGE_INPUT_SIZE_W = 640\n",
    "IMAGE_INPUT_SIZE_H = 480\n",
    "\n",
    "IMAGE_AFTER_CONV_SIZE_W = 18\n",
    "IMAGE_AFTER_CONV_SIZE_H = 13\n",
    "#for 3x3 kernels, n=num_layers: len_in = 2^n*len_out + sum[i=1..n](2^i)\n",
    "#CONV_LAYER_LENGTH = 5\n",
    "\n",
    "LSTM_IO_SIZE = 18*13\n",
    "LSTM_HIDDEN_SIZE = 18*13\n",
    "\n",
    "RGB_CHANNELS = 3\n",
    "TIMESTEPS = 40 # size videos\n",
    "BATCH_SIZE = 1 #until now just batch_size = 1\n",
    "\n",
    "NR_EPOCHS = 50\n",
    "\n",
    "VALIDATION_SPLIT = 0.2\n",
    "RANDOMIZED_SEED = 10\n",
    "SHUFFLE_DATASET = False\n",
    "\n",
    "learning_rate = 0.01 # reduce factos of 10 .. some epoch later.\n",
    "momentum = 0.9\n",
    "print(\"Hyperparameters defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings \n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 5\n",
      "Indices size: 5\n",
      "Split: 1\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "print(\"Dataset size:\", len(dataset))\n",
    "print(\"Indices size:\", len(indices))\n",
    "split = int(np.floor(VALIDATION_SPLIT * dataset_size))\n",
    "print(\"Split:\", split)\n",
    "if SHUFFLE_DATASET:\n",
    "    np.random.seed(RANDOMIZED_SEED)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "train_sampler = torch.utils.data.SequentialSampler(train_indices)\n",
    "test_sampler = torch.utils.data.SequentialSampler(test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=test_sampler)\n",
    "\n",
    "# #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#USE RANDOM IMAGES TO SET UP WORKING EXAMPLE\n",
    "class TEST_CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TEST_CNN_LSTM, self).__init__()\n",
    "        self.avialable_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3,6,3) #input 640x480\n",
    "        self.pool1 = nn.MaxPool2d(2,2) #input 638x478 output 319x239\n",
    "        self.conv2 = nn.Conv2d(6,16,3) # input 319x239 output 317x237\n",
    "        self.pool2 = nn.MaxPool2d(2,2) # input 317x237 output 158x118\n",
    "        self.conv3 = nn.Conv2d(16,6,3) # input 158x118 output 156x116\n",
    "        self.pool3 = nn.MaxPool2d(2,2) # input 156x116 output 78x58\n",
    "        self.conv4 = nn.Conv2d(6,3,3)  # input 78x58 output 76x56\n",
    "        self.pool4 = nn.MaxPool2d(2,2) # input 76x56 output 39x29\n",
    "        self.conv5 = nn.Conv2d(3,1,3)  # input 39x29 output 37x27\n",
    "        self.pool5 = nn.MaxPool2d(2,2) #output 37x27 output 18x13\n",
    "        self.lstm1 = nn.LSTM(LSTM_IO_SIZE,\n",
    "                            LSTM_HIDDEN_SIZE,\n",
    "                            TIMESTEPS)# horizontal direction\n",
    "        self.lstm2 = nn.LSTM(LSTM_IO_SIZE,\n",
    "                            LSTM_HIDDEN_SIZE,\n",
    "                            TIMESTEPS)# horizontal direction\n",
    "        self.fc1 = nn.Linear(LSTM_IO_SIZE,120)\n",
    "        self.fc2 = nn.Linear(120,20)\n",
    "        self.fc3 = nn.Linear(20,3)\n",
    "        \n",
    "        #initialize hidden states of LSTM\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "        #print(\"Hidden:\", _hidden)\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(TIMESTEPS, BATCH_SIZE, LSTM_HIDDEN_SIZE).to(self.avialable_device), \n",
    "                torch.randn(TIMESTEPS, BATCH_SIZE, LSTM_HIDDEN_SIZE).to(self.avialable_device))\n",
    "    def forward(self,x):\n",
    "#         print(\"Input list len:\",len(x))\n",
    "#         print(\"Input elemens size:\", x[0].size())\n",
    "#         batch_size = x[0].size()[0]\n",
    "\n",
    "        x_arr = torch.zeros(TIMESTEPS,BATCH_SIZE,1,IMAGE_AFTER_CONV_SIZE_H,IMAGE_AFTER_CONV_SIZE_W).to(self.avialable_device)\n",
    "        ## print(\"X arr size\", x_arr.size())\n",
    "        for i in range(TIMESTEPS):#parallel convolutions which are later concatenated for LSTM\n",
    "            x_tmp_c1 = self.pool1(F.relu(self.conv1(x[i].float())))\n",
    "            x_tmp_c2 = self.pool2(F.relu(self.conv2(x_tmp_c1)))\n",
    "            x_tmp_c3 = self.pool3(F.relu(self.conv3(x_tmp_c2)))\n",
    "            x_tmp_c4 = self.pool4(F.relu(self.conv4(x_tmp_c3)))\n",
    "            x_tmp_c5 = self.pool5(F.relu(self.conv5(x_tmp_c4)))\n",
    "            x_arr[i] = x_tmp_c5 # torch.squeeze(x_tmp_c5)\n",
    "        \n",
    "        x, hidden = self.lstm1(x_arr.view(TIMESTEPS,BATCH_SIZE,-1), self.hidden)\n",
    "        x, hidden = self.lstm2(x, self.hidden)\n",
    "        # the reshaping was taken from the documentation... and makes scense\n",
    "        x = x.view(TIMESTEPS,BATCH_SIZE,LSTM_HIDDEN_SIZE) #output.view(seq_len, batch, num_dir*hidden_size)\n",
    "#         x = torch.squeeze(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x) \n",
    "        x = x.permute(1,2,0)\n",
    "        return x\n",
    "print(\"Class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOS:\n",
    "# Look for overfitting..\n",
    "# use GPU: 300 samples. many epochs. learning rate maybe is too high.\n",
    "# Tweak learning rate\n",
    "# Increase the RNN size\n",
    "# Maybe change the CNN\n",
    "# Use patches. or OF\n",
    "# Increase the dataset: 10 images 10peoplo+++ not too much too much variance. \n",
    "# FEEDBACK on friday..:) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#TRAINING\n",
    "test_net = TEST_CNN_LSTM()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "test_net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(test_net.parameters(), lr=learning_rate, momentum=momentum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define and execute testing function\n",
    "def test_all_preds(model):\n",
    "    n_batches_test = len(test_loader)\n",
    "\n",
    "    #Time for printing\n",
    "    testing_start_time = time.time()\n",
    "\n",
    "    print('Start testing...')\n",
    "    correct = 0 \n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            inputs, labels = batch\n",
    "            \n",
    "            scenes = [s.to(device) for s in inputs['scenes']]\n",
    "            labels = labels.to(device)\n",
    "            if not labels.size()[0] == BATCH_SIZE:\n",
    "                # skip uncompleted batch size NN is fixed to BATCHSIZE\n",
    "                continue\n",
    "            outputs = model(scenes)\n",
    "#             print(\"Out:\", len(outputs), outputs.size())\n",
    "#             print(\"Labels:\", len(labels), labels.size())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "#             print('predicted:',len(predicted),predicted.size())\n",
    "            n_errors = torch.nonzero(torch.abs(labels.long() - predicted)).size(0)\n",
    "            total += predicted.numel()\n",
    "            # print('predicted',predicted)\n",
    "            correct += predicted.numel() - n_errors\n",
    "            # print('labels',labels)\n",
    "    print('Accuracy {:.2f}%'.format(100*correct/total))\n",
    "    print('...testing finished')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training over all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/.conda/envs/gait_37/lib/python3.7/site-packages/pandas/core/computation/expressions.py:183: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
      "  .format(op=op_str, alt_op=unsupported[op_str]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss epoch 0: 4.507093071937561, took 10.108455896377563s\n",
      "Epoch: 1\n",
      "Loss epoch 1: 4.420469284057617, took 8.698943138122559s\n",
      "Epoch: 2\n",
      "Loss epoch 2: 4.285942435264587, took 8.766133546829224s\n",
      "Epoch: 3\n",
      "Loss epoch 3: 4.134092807769775, took 8.988276958465576s\n",
      "Epoch: 4\n",
      "Loss epoch 4: 3.9922101497650146, took 9.27753210067749s\n",
      "Epoch: 5\n",
      "Loss epoch 5: 3.8677985072135925, took 8.907352447509766s\n",
      "Epoch: 6\n",
      "Loss epoch 6: 3.761456549167633, took 8.80866527557373s\n",
      "Epoch: 7\n",
      "Loss epoch 7: 3.6712125539779663, took 8.891075849533081s\n",
      "Epoch: 8\n",
      "Loss epoch 8: 3.596523642539978, took 8.735529661178589s\n",
      "Epoch: 9\n",
      "Loss epoch 9: 3.5327279567718506, took 8.659430265426636s\n",
      "Epoch: 10\n",
      "Loss epoch 10: 3.4751908779144287, took 8.718618631362915s\n",
      "Epoch: 11\n",
      "Loss epoch 11: 3.4192052483558655, took 9.07642412185669s\n",
      "Epoch: 12\n",
      "Loss epoch 12: 3.3619245290756226, took 8.960973024368286s\n",
      "Epoch: 13\n",
      "Loss epoch 13: 3.299912929534912, took 8.910082578659058s\n",
      "Epoch: 14\n",
      "Loss epoch 14: 3.2314948439598083, took 8.842028141021729s\n",
      "Epoch: 15\n",
      "Loss epoch 15: 3.156032621860504, took 8.78690242767334s\n",
      "Epoch: 16\n",
      "Loss epoch 16: 3.073123335838318, took 9.279212236404419s\n",
      "Epoch: 17\n",
      "Loss epoch 17: 2.9822264909744263, took 8.812768936157227s\n",
      "Epoch: 18\n",
      "Loss epoch 18: 2.8841347098350525, took 9.458245038986206s\n",
      "Epoch: 19\n",
      "Loss epoch 19: 2.781070828437805, took 9.567323446273804s\n",
      "Epoch: 20\n",
      "Loss epoch 20: 2.6761257648468018, took 9.077906847000122s\n",
      "Epoch: 21\n",
      "Loss epoch 21: 2.569931447505951, took 9.301247835159302s\n",
      "Epoch: 22\n",
      "Loss epoch 22: 2.469840109348297, took 9.093893766403198s\n",
      "Epoch: 23\n",
      "Loss epoch 23: 2.374730110168457, took 9.069223165512085s\n",
      "Epoch: 24\n",
      "Loss epoch 24: 2.2844653725624084, took 8.89029312133789s\n",
      "Epoch: 25\n",
      "Loss epoch 25: 2.202412724494934, took 9.662437200546265s\n",
      "Epoch: 26\n",
      "Loss epoch 26: 2.1269532442092896, took 9.033563375473022s\n",
      "Epoch: 27\n",
      "Loss epoch 27: 2.058994948863983, took 8.983664989471436s\n",
      "Epoch: 28\n",
      "Loss epoch 28: 1.9980428218841553, took 9.00925612449646s\n",
      "Epoch: 29\n",
      "Loss epoch 29: 1.9415786862373352, took 9.460265159606934s\n",
      "Epoch: 30\n",
      "Loss epoch 30: 1.8914081156253815, took 9.315485000610352s\n",
      "Epoch: 31\n",
      "Loss epoch 31: 1.8474273681640625, took 9.373987436294556s\n",
      "Epoch: 32\n",
      "Loss epoch 32: 1.8074492812156677, took 9.49139928817749s\n",
      "Epoch: 33\n",
      "Loss epoch 33: 1.7714415788650513, took 9.147733449935913s\n",
      "Epoch: 34\n",
      "Loss epoch 34: 1.7396975755691528, took 9.242359399795532s\n",
      "Epoch: 35\n",
      "Loss epoch 35: 1.711313247680664, took 9.1649169921875s\n",
      "Epoch: 36\n",
      "Loss epoch 36: 1.6855111718177795, took 8.983936548233032s\n",
      "Epoch: 37\n",
      "Loss epoch 37: 1.662949949502945, took 8.90699315071106s\n",
      "Epoch: 38\n",
      "Loss epoch 38: 1.64251109957695, took 9.282608032226562s\n",
      "Epoch: 39\n",
      "Loss epoch 39: 1.6239123344421387, took 9.052502870559692s\n",
      "Epoch: 40\n",
      "Loss epoch 40: 1.6063986122608185, took 9.064723491668701s\n",
      "Epoch: 41\n",
      "Loss epoch 41: 1.5908374786376953, took 8.909368991851807s\n",
      "Epoch: 42\n",
      "Loss epoch 42: 1.5766154825687408, took 9.335347414016724s\n",
      "Epoch: 43\n",
      "Loss epoch 43: 1.5637501180171967, took 9.19716215133667s\n",
      "Epoch: 44\n",
      "Loss epoch 44: 1.5508714020252228, took 8.918009996414185s\n",
      "Epoch: 45\n",
      "Loss epoch 45: 1.5390762388706207, took 9.458247900009155s\n",
      "Epoch: 46\n",
      "Loss epoch 46: 1.5284745395183563, took 9.513289213180542s\n",
      "Epoch: 47\n",
      "Loss epoch 47: 1.5185282230377197, took 9.025094270706177s\n",
      "Epoch: 48\n",
      "Loss epoch 48: 1.5085706114768982, took 8.993175029754639s\n",
      "Epoch: 49\n",
      "Loss epoch 49: 1.499504566192627, took 8.720803260803223s\n",
      "Epoch: 50\n",
      "Loss epoch 50: 1.4911441802978516, took 8.903512716293335s\n",
      "Epoch: 51\n",
      "Loss epoch 51: 1.4831869900226593, took 9.119349002838135s\n",
      "Epoch: 52\n",
      "Loss epoch 52: 1.4753946363925934, took 9.844580888748169s\n",
      "Epoch: 53\n",
      "Loss epoch 53: 1.467656522989273, took 9.569527387619019s\n",
      "Epoch: 54\n",
      "Loss epoch 54: 1.4606969356536865, took 9.575601577758789s\n",
      "Epoch: 55\n",
      "Loss epoch 55: 1.454292356967926, took 9.43790078163147s\n",
      "Epoch: 56\n",
      "Loss epoch 56: 1.4478209614753723, took 9.03013825416565s\n",
      "Epoch: 57\n",
      "Loss epoch 57: 1.441509485244751, took 8.969040393829346s\n",
      "Epoch: 58\n",
      "Loss epoch 58: 1.435412049293518, took 8.766879796981812s\n",
      "Epoch: 59\n",
      "Loss epoch 59: 1.4296130239963531, took 9.291150331497192s\n",
      "Epoch: 60\n",
      "Loss epoch 60: 1.4239159226417542, took 8.9253408908844s\n",
      "Epoch: 61\n",
      "Loss epoch 61: 1.4182302057743073, took 8.725036859512329s\n",
      "Epoch: 62\n",
      "Loss epoch 62: 1.4125985205173492, took 8.912401914596558s\n",
      "Epoch: 63\n",
      "Loss epoch 63: 1.4069572389125824, took 8.750616073608398s\n",
      "Epoch: 64\n",
      "Loss epoch 64: 1.4012213051319122, took 8.784146308898926s\n",
      "Epoch: 65\n",
      "Loss epoch 65: 1.3952916860580444, took 8.850016355514526s\n",
      "Epoch: 66\n",
      "Loss epoch 66: 1.3885964155197144, took 9.22632646560669s\n",
      "Epoch: 67\n",
      "Loss epoch 67: 1.3822360336780548, took 8.653178215026855s\n",
      "Epoch: 68\n",
      "Loss epoch 68: 1.3759762644767761, took 8.918636322021484s\n",
      "Epoch: 69\n",
      "Loss epoch 69: 1.369059532880783, took 8.7718186378479s\n",
      "Epoch: 70\n",
      "Loss epoch 70: 1.3615433275699615, took 8.909722328186035s\n",
      "Epoch: 71\n",
      "Loss epoch 71: 1.3538777828216553, took 8.779928207397461s\n",
      "Epoch: 72\n",
      "Loss epoch 72: 1.345894306898117, took 8.85748553276062s\n",
      "Epoch: 73\n",
      "Loss epoch 73: 1.3376296162605286, took 9.221577167510986s\n",
      "Epoch: 74\n",
      "Loss epoch 74: 1.3290042877197266, took 8.701822757720947s\n",
      "Epoch: 75\n",
      "Loss epoch 75: 1.3194131255149841, took 8.764841318130493s\n",
      "Epoch: 76\n",
      "Loss epoch 76: 1.3093302845954895, took 8.810386419296265s\n",
      "Epoch: 77\n",
      "Loss epoch 77: 1.297745168209076, took 8.916870594024658s\n",
      "Epoch: 78\n",
      "Loss epoch 78: 1.284662514925003, took 8.942203760147095s\n",
      "Epoch: 79\n",
      "Loss epoch 79: 1.2702559530735016, took 8.794487237930298s\n",
      "Epoch: 80\n",
      "Loss epoch 80: 1.2567327320575714, took 9.129780769348145s\n",
      "Epoch: 81\n",
      "Loss epoch 81: 1.2423215806484222, took 8.787067174911499s\n",
      "Epoch: 82\n",
      "Loss epoch 82: 1.227755531668663, took 8.907400131225586s\n",
      "Epoch: 83\n",
      "Loss epoch 83: 1.2119387090206146, took 8.882638931274414s\n",
      "Epoch: 84\n",
      "Loss epoch 84: 1.1935696750879288, took 8.726470947265625s\n",
      "Epoch: 85\n",
      "Loss epoch 85: 1.1766270995140076, took 8.801555633544922s\n",
      "Epoch: 86\n",
      "Loss epoch 86: 1.1573479175567627, took 8.876630067825317s\n",
      "Epoch: 87\n",
      "Loss epoch 87: 1.136062279343605, took 9.147382736206055s\n",
      "Epoch: 88\n",
      "Loss epoch 88: 1.1168799549341202, took 9.011480569839478s\n",
      "Epoch: 89\n",
      "Loss epoch 89: 1.1006464213132858, took 8.837358474731445s\n",
      "Epoch: 90\n",
      "Loss epoch 90: 1.0767322778701782, took 9.33304738998413s\n",
      "Epoch: 91\n",
      "Loss epoch 91: 1.0583514720201492, took 8.761334419250488s\n",
      "Epoch: 92\n",
      "Loss epoch 92: 1.0409921258687973, took 8.746124744415283s\n",
      "Epoch: 93\n",
      "Loss epoch 93: 1.0162506848573685, took 8.897509336471558s\n",
      "Epoch: 94\n",
      "Loss epoch 94: 1.0010778903961182, took 9.079691410064697s\n",
      "Epoch: 95\n",
      "Loss epoch 95: 0.9834795743227005, took 8.983147859573364s\n",
      "Epoch: 96\n",
      "Loss epoch 96: 0.9577385038137436, took 9.009844541549683s\n",
      "Epoch: 97\n",
      "Loss epoch 97: 0.9455766975879669, took 8.806962490081787s\n",
      "Epoch: 98\n",
      "Loss epoch 98: 0.9220531135797501, took 8.80124807357788s\n",
      "Epoch: 99\n",
      "Loss epoch 99: 0.9068202525377274, took 8.918567419052124s\n",
      "Start testing...\n",
      "Accuracy 95.00%\n",
      "...testing finished\n",
      "...Training finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb7d4d87748>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_batches = len(train_loader)\n",
    "\n",
    "#Time for printing\n",
    "training_start_time = time.time()\n",
    "\n",
    "loss_array = np.zeros(NR_EPOCHS)\n",
    "\n",
    "print('Start training...')\n",
    "for epoch in range(NR_EPOCHS): \n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    total_train_loss = 0\n",
    "    \n",
    "#     if (epoch == 80):\n",
    "#         learning_rate = 0.001\n",
    "#         optimizer = optim.SGD(test_net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "#         print (\"Learning rate changed\", learning_rate)\n",
    "#     if (epoch == 80):\n",
    "#         learning_rate = 0.001\n",
    "#         optimizer = optim.SGD(test_net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "#         print (\"Learning rate changed\", learning_rate)\n",
    "    \n",
    "    print(\"Epoch:\", epoch)\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(train_loader): #loads all angles\n",
    "        inputs, labels = batch\n",
    "        scenes = [s.to(device) for s in inputs['scenes']]\n",
    "        labels = labels.unsqueeze(-1).to(device)\n",
    "        if not labels.size()[0] == BATCH_SIZE:\n",
    "            # skip uncompleted batch size NN is fixed to BATCHSIZE\n",
    "            continue\n",
    "        optimizer.zero_grad() \n",
    "        outputs = test_net(scenes)\n",
    "        outputs = outputs.unsqueeze(-1)\n",
    "        #print(\"Size before permutation:\", outputs.size())\n",
    "        outputs = outputs.permute(0,2,1,3).squeeze(3).squeeze(0)\n",
    "        labels = labels.squeeze(2).squeeze(0)\n",
    "        #print(\"Out:\", len(outputs), outputs.size())\n",
    "        #print(\"Labels:\", len(labels), labels.size())\n",
    "        #print(\"Here\")\n",
    "        #print(scenes[0].squeeze(0).permute(2,1,0).size())\n",
    "        #for j in range(10):\n",
    "        #    scene_print = scenes[j].squeeze(0).permute(1,2,0)\n",
    "        #    plt.imshow(scene_print.numpy())\n",
    "        #    plt.show()\n",
    "        #print(labels)\n",
    "        loss = criterion(outputs,labels.long())\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "        #Print statistics\n",
    "        # print(loss.data.item())\n",
    "        running_loss += loss.data.item()\n",
    "        #total_train_loss += loss.data.item()\n",
    "        \n",
    "        #Print every 10th batch of an epoch\n",
    "#         if (i + 1) % (print_every + 1) == 0:\n",
    "#             print(\"Epoch {}, {:d}% \\t train_loss(mean): {:.2f} took: {:.2f}s\".format(\n",
    "#                     epoch+1, int(100 * (i+1) / n_batches), running_loss/print_every, time.time() - start_time))\n",
    "#             #Reset running loss and time\n",
    "#             running_loss = 0.0\n",
    "#             start_time = time.time()\n",
    "    # test after each epoch\n",
    "    print(\"Loss epoch {}: {}, took {}s\".format(epoch, running_loss,time.time()-start_time))\n",
    "    loss_array[epoch] = running_loss\n",
    "\n",
    "test_all_preds(test_net)\n",
    "#print('total training loss for epoch {}: {:.6f}'.format(epoch+1, total_train_loss))    \n",
    "print('...Training finished')\n",
    "plt.plot(loss_array)\n",
    "plt.plot(loss_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(labels.size())\n",
    "# print(outputs.size())\n",
    "# print(labels)\n",
    "# print(outputs)\n",
    "# import matplotlib.pyplot as plt\n",
    "# print(scenes[0].squeeze(0).size())\n",
    "# plt.imshow(scenes[9].squeeze(0).permute(1,2,0))\n",
    "# plt.figure(figsize=(30,40))\n",
    "# print('left foot trans from air to ground')\n",
    "# plt.subplot(131)\n",
    "# plt.imshow(scenes[4])\n",
    "# plt.title('frame 44')\n",
    "# plt.subplot(132)\n",
    "# plt.imshow(scenes[5])\n",
    "# plt.title('frame 45')\n",
    "# plt.subplot(133)\n",
    "# plt.imshow(scenes[6])\n",
    "# plt.title('frame 46')\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python gait_37",
   "language": "python",
   "name": "gait_37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
