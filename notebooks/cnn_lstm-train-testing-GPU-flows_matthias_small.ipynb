{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import os.path as path\n",
    "import copy\n",
    "# from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "\n",
    "from gait_analysis import AnnotationsCasia as Annotations\n",
    "from gait_analysis import CasiaDataset\n",
    "from gait_analysis.Config import Config\n",
    "from gait_analysis import Composer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configuration  flows\n",
      "[OK]\n"
     ]
    }
   ],
   "source": [
    "#change configuration in settings.py\n",
    "\n",
    "crop_im_size = [186,250]\n",
    "c = Config()\n",
    "c.config['indexing']['grouping'] = 'person_sequence_angle'\n",
    "c.config['indexing']['people selection'] = [1]\n",
    "#c.config['indexing']['sequences_selection'] = ['nm-01']\n",
    "c.config['pose']['load'] = False\n",
    "c.config['flow']['load'] = True\n",
    "c.config['heatmaps']['load'] = False\n",
    "#c.config['scenes']['sequences'] = ['nm']\n",
    "#c.config['scenes']['angles'] = ['108']\n",
    "c.config['dataset_output'] = {\n",
    "#         'data': [\"scenes\",\"flows\",\"heatmaps_LAnkle\",\"heatmaps_RAnkle\"],\n",
    "        'data': ['flows'],\n",
    "        'label': \"annotations\"}\n",
    "composer = Composer()\n",
    "transformer = composer.compose()\n",
    "dataset = CasiaDataset(transform=transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NETWORK AND DATASET PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters defined\n"
     ]
    }
   ],
   "source": [
    "#DESIGN PARAMETERS FOR NEURAL NETWORK\n",
    "NR_LSTM_UNITS = 2 \n",
    "IMAGE_INPUT_SIZE_W = 640\n",
    "IMAGE_INPUT_SIZE_H = 480\n",
    "\n",
    "IMAGE_AFTER_CONV_SIZE_W = 18\n",
    "IMAGE_AFTER_CONV_SIZE_H = 13\n",
    "#for 3x3 kernels, n=num_layers: len_in = 2^n*len_out + sum[i=1..n](2^i)\n",
    "#CONV_LAYER_LENGTH = 5\n",
    "\n",
    "LSTM_IO_SIZE = 18*13\n",
    "LSTM_HIDDEN_SIZE = 18*13\n",
    "\n",
    "RGB_CHANNELS = 3\n",
    "TIMESTEPS = 40 # size videos\n",
    "BATCH_SIZE = 1 #until now just batch_size = 1\n",
    "\n",
    "NR_EPOCHS = 50\n",
    "\n",
    "VALIDATION_SPLIT = 0.2\n",
    "RANDOMIZED_SEED = 10\n",
    "SHUFFLE_DATASET = False\n",
    "\n",
    "learning_rate = 0.01 # reduce factos of 10 .. some epoch later.\n",
    "momentum = 0.9\n",
    "print(\"Hyperparameters defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings \n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 5\n",
      "Indices size: 5\n",
      "Split: 1\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "print(\"Dataset size:\", len(dataset))\n",
    "print(\"Indices size:\", len(indices))\n",
    "split = int(np.floor(VALIDATION_SPLIT * dataset_size))\n",
    "print(\"Split:\", split)\n",
    "if SHUFFLE_DATASET:\n",
    "    np.random.seed(RANDOMIZED_SEED)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "train_sampler = torch.utils.data.SequentialSampler(train_indices)\n",
    "test_sampler = torch.utils.data.SequentialSampler(test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=test_sampler)\n",
    "\n",
    "# #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#USE RANDOM IMAGES TO SET UP WORKING EXAMPLE\n",
    "class TEST_CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TEST_CNN_LSTM, self).__init__()\n",
    "        self.avialable_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3,6,3) #input 640x480\n",
    "        self.pool1 = nn.MaxPool2d(2,2) #input 638x478 output 319x239\n",
    "        self.conv2 = nn.Conv2d(6,16,3) # input 319x239 output 317x237\n",
    "        self.pool2 = nn.MaxPool2d(2,2) # input 317x237 output 158x118\n",
    "        self.conv3 = nn.Conv2d(16,6,3) # input 158x118 output 156x116\n",
    "        self.pool3 = nn.MaxPool2d(2,2) # input 156x116 output 78x58\n",
    "        self.conv4 = nn.Conv2d(6,3,3)  # input 78x58 output 76x56\n",
    "        self.pool4 = nn.MaxPool2d(2,2) # input 76x56 output 39x29\n",
    "        self.conv5 = nn.Conv2d(3,1,3)  # input 39x29 output 37x27\n",
    "        self.pool5 = nn.MaxPool2d(2,2) #output 37x27 output 18x13\n",
    "        self.lstm1 = nn.LSTM(LSTM_IO_SIZE,\n",
    "                            LSTM_HIDDEN_SIZE,\n",
    "                            TIMESTEPS)# horizontal direction\n",
    "        self.lstm2 = nn.LSTM(LSTM_IO_SIZE,\n",
    "                            LSTM_HIDDEN_SIZE,\n",
    "                            TIMESTEPS)# horizontal direction\n",
    "        self.fc1 = nn.Linear(LSTM_IO_SIZE,120)\n",
    "        self.fc2 = nn.Linear(120,20)\n",
    "        self.fc3 = nn.Linear(20,3)\n",
    "        \n",
    "        #initialize hidden states of LSTM\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "        #print(\"Hidden:\", _hidden)\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(TIMESTEPS, BATCH_SIZE, LSTM_HIDDEN_SIZE).to(self.avialable_device), \n",
    "                torch.randn(TIMESTEPS, BATCH_SIZE, LSTM_HIDDEN_SIZE).to(self.avialable_device))\n",
    "    def forward(self,x):\n",
    "#         print(\"Input list len:\",len(x))\n",
    "#         print(\"Input elemens size:\", x[0].size())\n",
    "#         batch_size = x[0].size()[0]\n",
    "\n",
    "        x_arr = torch.zeros(TIMESTEPS,BATCH_SIZE,1,IMAGE_AFTER_CONV_SIZE_H,IMAGE_AFTER_CONV_SIZE_W).to(self.avialable_device)\n",
    "        ## print(\"X arr size\", x_arr.size())\n",
    "        for i in range(TIMESTEPS):#parallel convolutions which are later concatenated for LSTM\n",
    "            x_tmp_c1 = self.pool1(F.relu(self.conv1(x[i].float())))\n",
    "            x_tmp_c2 = self.pool2(F.relu(self.conv2(x_tmp_c1)))\n",
    "            x_tmp_c3 = self.pool3(F.relu(self.conv3(x_tmp_c2)))\n",
    "            x_tmp_c4 = self.pool4(F.relu(self.conv4(x_tmp_c3)))\n",
    "            x_tmp_c5 = self.pool5(F.relu(self.conv5(x_tmp_c4)))\n",
    "            x_arr[i] = x_tmp_c5 # torch.squeeze(x_tmp_c5)\n",
    "        \n",
    "        x, hidden = self.lstm1(x_arr.view(TIMESTEPS,BATCH_SIZE,-1), self.hidden)\n",
    "        x, hidden = self.lstm2(x, self.hidden)\n",
    "        # the reshaping was taken from the documentation... and makes scense\n",
    "        x = x.view(TIMESTEPS,BATCH_SIZE,LSTM_HIDDEN_SIZE) #output.view(seq_len, batch, num_dir*hidden_size)\n",
    "#         x = torch.squeeze(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x) \n",
    "        x = x.permute(1,2,0)\n",
    "        return x\n",
    "print(\"Class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOS:\n",
    "# Look for overfitting..\n",
    "# use GPU: 300 samples. many epochs. learning rate maybe is too high.\n",
    "# Tweak learning rate\n",
    "# Increase the RNN size\n",
    "# Maybe change the CNN\n",
    "# Use patches. or OF\n",
    "# Increase the dataset: 10 images 10peoplo+++ not too much too much variance. \n",
    "# FEEDBACK on friday..:) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#TRAINING\n",
    "test_net = TEST_CNN_LSTM()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "test_net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(test_net.parameters(), lr=learning_rate, momentum=momentum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define and execute testing function\n",
    "def test_all_preds(model):\n",
    "    n_batches_test = len(test_loader)\n",
    "\n",
    "    #Time for printing\n",
    "    testing_start_time = time.time()\n",
    "\n",
    "    print('Start testing...')\n",
    "    correct = 0 \n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            inputs, labels = batch\n",
    "            \n",
    "            data_in = [s.to(device) for s in inputs['flows']]\n",
    "            labels = labels.to(device)\n",
    "            if not labels.size()[0] == BATCH_SIZE:\n",
    "                # skip uncompleted batch size NN is fixed to BATCHSIZE\n",
    "                continue\n",
    "            outputs = model(data_in)\n",
    "#             print(\"Out:\", len(outputs), outputs.size())\n",
    "#             print(\"Labels:\", len(labels), labels.size())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "#             print('predicted:',len(predicted),predicted.size())\n",
    "            n_errors = torch.nonzero(torch.abs(labels.long() - predicted)).size(0)\n",
    "            total += predicted.numel()\n",
    "            # print('predicted',predicted)\n",
    "            correct += predicted.numel() - n_errors\n",
    "            # print('labels',labels)\n",
    "    print('Accuracy {:.2f}%'.format(100*correct/total))\n",
    "    print('...testing finished')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training over all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Expected loss with {} different classes and {} data points: {}  (3, 4, 4.394449154672439)\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/.conda/envs/gait_37/lib/python3.7/site-packages/pandas/core/computation/expressions.py:183: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
      "  .format(op=op_str, alt_op=unsupported[op_str]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss epoch 0: 4.141621470451355, took 15.0257089138031s\n",
      "Epoch: 1\n",
      "Loss epoch 1: 4.073852777481079, took 12.42219066619873s\n",
      "Epoch: 2\n",
      "Loss epoch 2: 3.97269743680954, took 11.944282531738281s\n",
      "Epoch: 3\n",
      "Loss epoch 3: 3.870367407798767, took 12.94161343574524s\n",
      "Epoch: 4\n",
      "Loss epoch 4: 3.7850934267044067, took 12.47977590560913s\n",
      "Epoch: 5\n",
      "Loss epoch 5: 3.7134406566619873, took 11.829708814620972s\n",
      "Epoch: 6\n",
      "Loss epoch 6: 3.6533865928649902, took 12.615229606628418s\n",
      "Epoch: 7\n",
      "Loss epoch 7: 3.6020764112472534, took 12.835860967636108s\n",
      "Epoch: 8\n",
      "Loss epoch 8: 3.5564024448394775, took 12.730127573013306s\n",
      "Epoch: 9\n",
      "Loss epoch 9: 3.513446569442749, took 12.820738554000854s\n",
      "Epoch: 10\n",
      "Loss epoch 10: 3.4713022708892822, took 13.207047939300537s\n",
      "Epoch: 11\n",
      "Loss epoch 11: 3.4275647401809692, took 12.264318943023682s\n",
      "Epoch: 12\n",
      "Loss epoch 12: 3.380095660686493, took 12.368423223495483s\n",
      "Epoch: 13\n",
      "Loss epoch 13: 3.326919913291931, took 12.162353038787842s\n",
      "Epoch: 14\n",
      "Loss epoch 14: 3.2665452361106873, took 12.42027759552002s\n",
      "Epoch: 15\n",
      "Loss epoch 15: 3.1986706256866455, took 12.021663904190063s\n",
      "Epoch: 16\n",
      "Loss epoch 16: 3.1219335794448853, took 12.328333377838135s\n",
      "Epoch: 17\n",
      "Loss epoch 17: 3.035791039466858, took 12.801870584487915s\n",
      "Epoch: 18\n",
      "Loss epoch 18: 2.941245436668396, took 18.90107226371765s\n",
      "Epoch: 19\n",
      "Loss epoch 19: 2.840248167514801, took 13.853075981140137s\n",
      "Epoch: 20\n",
      "Loss epoch 20: 2.734557330608368, took 12.598989248275757s\n",
      "Epoch: 21\n",
      "Loss epoch 21: 2.625640034675598, took 12.124418258666992s\n",
      "Epoch: 22\n",
      "Loss epoch 22: 2.5149494409561157, took 12.15848684310913s\n",
      "Epoch: 23\n",
      "Loss epoch 23: 2.404901087284088, took 13.619818925857544s\n",
      "Epoch: 24\n",
      "Loss epoch 24: 2.2976021766662598, took 12.212230443954468s\n",
      "Epoch: 25\n",
      "Loss epoch 25: 2.200957179069519, took 11.951244592666626s\n",
      "Epoch: 26\n",
      "Loss epoch 26: 2.112361431121826, took 12.724251747131348s\n",
      "Epoch: 27\n",
      "Loss epoch 27: 2.0309016704559326, took 12.304041862487793s\n",
      "Epoch: 28\n",
      "Loss epoch 28: 1.9622932076454163, took 12.124975681304932s\n",
      "Epoch: 29\n",
      "Loss epoch 29: 1.9017406404018402, took 11.930354118347168s\n",
      "Epoch: 30\n",
      "Loss epoch 30: 1.8479899168014526, took 12.21929931640625s\n",
      "Epoch: 31\n",
      "Loss epoch 31: 1.8003669083118439, took 12.829939126968384s\n",
      "Epoch: 32\n",
      "Loss epoch 32: 1.7580128014087677, took 12.494509935379028s\n",
      "Epoch: 33\n",
      "Loss epoch 33: 1.7205384969711304, took 12.086791515350342s\n",
      "Epoch: 34\n",
      "Loss epoch 34: 1.6874293386936188, took 11.392301321029663s\n",
      "Epoch: 35\n",
      "Loss epoch 35: 1.658118098974228, took 11.93493938446045s\n",
      "Epoch: 36\n",
      "Loss epoch 36: 1.6322796046733856, took 11.678542137145996s\n",
      "Epoch: 37\n",
      "Loss epoch 37: 1.6095589101314545, took 11.490094661712646s\n",
      "Epoch: 38\n",
      "Loss epoch 38: 1.5893615782260895, took 11.614974975585938s\n",
      "Epoch: 39\n",
      "Loss epoch 39: 1.5712209045886993, took 11.805248498916626s\n",
      "Learning rate changed 0.01\n",
      "Epoch: 40\n",
      "Loss epoch 40: 1.5635182559490204, took 11.461045026779175s\n",
      "Epoch: 41\n",
      "Loss epoch 41: 1.5574648082256317, took 11.415281772613525s\n",
      "Epoch: 42\n",
      "Loss epoch 42: 1.5476701259613037, took 11.894695281982422s\n",
      "Epoch: 43\n",
      "Loss epoch 43: 1.538268357515335, took 11.727408170700073s\n",
      "Epoch: 44\n",
      "Loss epoch 44: 1.5286323130130768, took 11.968351364135742s\n",
      "Epoch: 45\n",
      "Loss epoch 45: 1.5182276964187622, took 11.791525840759277s\n",
      "Epoch: 46\n",
      "Loss epoch 46: 1.5068884789943695, took 12.178476572036743s\n",
      "Epoch: 47\n",
      "Loss epoch 47: 1.4957923889160156, took 12.179693937301636s\n",
      "Epoch: 48\n",
      "Loss epoch 48: 1.4856203198432922, took 12.29622220993042s\n",
      "Epoch: 49\n",
      "Loss epoch 49: 1.4762201607227325, took 11.945878505706787s\n",
      "Epoch: 50\n",
      "Loss epoch 50: 1.4670269191265106, took 11.719111919403076s\n",
      "Epoch: 51\n",
      "Loss epoch 51: 1.4578232765197754, took 13.291576385498047s\n",
      "Epoch: 52\n",
      "Loss epoch 52: 1.4491035044193268, took 11.88847041130066s\n",
      "Epoch: 53\n",
      "Loss epoch 53: 1.4408720433712006, took 12.219368934631348s\n",
      "Epoch: 54\n",
      "Loss epoch 54: 1.4329251945018768, took 12.844868421554565s\n",
      "Epoch: 55\n",
      "Loss epoch 55: 1.4251467287540436, took 12.971571445465088s\n",
      "Epoch: 56\n",
      "Loss epoch 56: 1.4173775017261505, took 11.757121562957764s\n",
      "Epoch: 57\n",
      "Loss epoch 57: 1.4095973372459412, took 11.847080945968628s\n",
      "Epoch: 58\n",
      "Loss epoch 58: 1.4018838107585907, took 12.032567501068115s\n",
      "Epoch: 59\n",
      "Loss epoch 59: 1.394164264202118, took 12.3388671875s\n",
      "Epoch: 60\n",
      "Loss epoch 60: 1.38641557097435, took 12.578935146331787s\n",
      "Epoch: 61\n",
      "Loss epoch 61: 1.3782890439033508, took 12.676194429397583s\n",
      "Epoch: 62\n",
      "Loss epoch 62: 1.3696319460868835, took 12.25845718383789s\n",
      "Epoch: 63\n",
      "Loss epoch 63: 1.3602745831012726, took 12.485375165939331s\n",
      "Epoch: 64\n",
      "Loss epoch 64: 1.3510457575321198, took 12.609286546707153s\n",
      "Epoch: 65\n",
      "Loss epoch 65: 1.3418686389923096, took 11.67594313621521s\n",
      "Epoch: 66\n",
      "Loss epoch 66: 1.3324030041694641, took 11.988030195236206s\n",
      "Epoch: 67\n",
      "Loss epoch 67: 1.3227457702159882, took 11.913570880889893s\n",
      "Epoch: 68\n",
      "Loss epoch 68: 1.3121200799942017, took 12.398168563842773s\n",
      "Epoch: 69\n",
      "Loss epoch 69: 1.299747258424759, took 12.4877450466156s\n",
      "Epoch: 70\n",
      "Loss epoch 70: 1.287726253271103, took 11.780114650726318s\n",
      "Epoch: 71\n",
      "Loss epoch 71: 1.2761485576629639, took 11.453649044036865s\n",
      "Epoch: 72\n",
      "Loss epoch 72: 1.2635031044483185, took 11.524950742721558s\n",
      "Epoch: 73\n",
      "Loss epoch 73: 1.248066782951355, took 11.69999098777771s\n",
      "Epoch: 74\n",
      "Loss epoch 74: 1.230014517903328, took 11.317265510559082s\n",
      "Epoch: 75\n",
      "Loss epoch 75: 1.2142065912485123, took 11.471186399459839s\n",
      "Epoch: 76\n",
      "Loss epoch 76: 1.198166847229004, took 11.461589097976685s\n",
      "Epoch: 77\n",
      "Loss epoch 77: 1.178543046116829, took 11.84095811843872s\n",
      "Epoch: 78\n",
      "Loss epoch 78: 1.1596737056970596, took 11.822728395462036s\n",
      "Epoch: 79\n",
      "Loss epoch 79: 1.1452521830797195, took 11.480947732925415s\n",
      "Epoch: 80\n",
      "Loss epoch 80: 1.1297564655542374, took 11.49542760848999s\n",
      "Epoch: 81\n",
      "Loss epoch 81: 1.1089540868997574, took 11.380589008331299s\n",
      "Epoch: 82\n",
      "Loss epoch 82: 1.090646579861641, took 11.541949272155762s\n",
      "Epoch: 83\n",
      "Loss epoch 83: 1.0755552500486374, took 11.716227054595947s\n",
      "Epoch: 84\n",
      "Loss epoch 84: 1.054112434387207, took 11.69089150428772s\n",
      "Epoch: 85\n",
      "Loss epoch 85: 1.034471109509468, took 11.537236213684082s\n",
      "Epoch: 86\n",
      "Loss epoch 86: 1.0170311331748962, took 11.273741722106934s\n",
      "Epoch: 87\n",
      "Loss epoch 87: 0.994435042142868, took 11.340595006942749s\n",
      "Epoch: 88\n",
      "Loss epoch 88: 0.983443096280098, took 11.457887887954712s\n",
      "Epoch: 89\n",
      "Loss epoch 89: 0.9549120217561722, took 11.88015103340149s\n",
      "Epoch: 90\n",
      "Loss epoch 90: 0.9458231925964355, took 11.586885213851929s\n",
      "Epoch: 91\n",
      "Loss epoch 91: 0.9236821830272675, took 11.28516674041748s\n",
      "Epoch: 92\n",
      "Loss epoch 92: 0.9057734161615372, took 11.329062461853027s\n",
      "Epoch: 93\n",
      "Loss epoch 93: 0.8965898603200912, took 11.304803133010864s\n",
      "Epoch: 94\n",
      "Loss epoch 94: 0.8650115877389908, took 11.303299188613892s\n",
      "Epoch: 95\n",
      "Loss epoch 95: 0.8645904809236526, took 12.205601215362549s\n",
      "Epoch: 96\n",
      "Loss epoch 96: 0.8355745077133179, took 11.423066139221191s\n",
      "Epoch: 97\n",
      "Loss epoch 97: 0.8283938765525818, took 11.71049976348877s\n",
      "Epoch: 98\n",
      "Loss epoch 98: 0.8074388802051544, took 11.701234102249146s\n",
      "Epoch: 99\n",
      "Loss epoch 99: 0.7910287231206894, took 11.634534120559692s\n",
      "Start testing...\n",
      "Accuracy 95.00%\n",
      "...testing finished\n",
      "...Training finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe5ef8ccba8>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_batches = len(train_loader)\n",
    "\n",
    "#Time for printing\n",
    "training_start_time = time.time()\n",
    "\n",
    "loss_array = np.zeros(NR_EPOCHS)\n",
    "\n",
    "print('Start training...')\n",
    "print('Expected loss with {} different classes and {} data points: {} ', (3, len(dataset)-split, (len(dataset)-split)*np.log(3)))\n",
    "for epoch in range(NR_EPOCHS): \n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    if (epoch == 40):\n",
    "        learning_rate = 0.01\n",
    "        optimizer = optim.SGD(test_net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        print (\"Learning rate changed\", learning_rate)\n",
    "#     if (epoch == 80):\n",
    "#         learning_rate = 0.001\n",
    "#         optimizer = optim.SGD(test_net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "#         print (\"Learning rate changed\", learning_rate)\n",
    "    \n",
    "    print(\"Epoch:\", epoch)\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(train_loader): #loads all angles\n",
    "        inputs, labels = batch\n",
    "        flows = [s.to(device) for s in inputs['flows']]\n",
    "        labels = labels.unsqueeze(-1).to(device)\n",
    "        if not labels.size()[0] == BATCH_SIZE:\n",
    "            # skip uncompleted batch size NN is fixed to BATCHSIZE\n",
    "            continue\n",
    "        optimizer.zero_grad() \n",
    "        outputs = test_net(flows)\n",
    "        outputs = outputs.unsqueeze(-1)\n",
    "        #print(\"Size before permutation:\", outputs.size())\n",
    "        outputs = outputs.permute(0,2,1,3).squeeze(3).squeeze(0)\n",
    "        labels = labels.squeeze(2).squeeze(0)\n",
    "        #print(\"Out:\", len(outputs), outputs.size())\n",
    "        #print(\"Labels:\", len(labels), labels.size())\n",
    "        #print(\"Here\")\n",
    "        #print(scenes[0].squeeze(0).permute(2,1,0).size())\n",
    "        #for j in range(10):\n",
    "        #    scene_print = scenes[j].squeeze(0).permute(1,2,0)\n",
    "        #    plt.imshow(scene_print.numpy())\n",
    "        #    plt.show()\n",
    "        #print(labels)\n",
    "        loss = criterion(outputs,labels.long())\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "        #Print statistics\n",
    "        # print(loss.data.item())\n",
    "        running_loss += loss.data.item()\n",
    "        #total_train_loss += loss.data.item()\n",
    "        \n",
    "        #Print every 10th batch of an epoch\n",
    "#         if (i + 1) % (print_every + 1) == 0:\n",
    "#             print(\"Epoch {}, {:d}% \\t train_loss(mean): {:.2f} took: {:.2f}s\".format(\n",
    "#                     epoch+1, int(100 * (i+1) / n_batches), running_loss/print_every, time.time() - start_time))\n",
    "#             #Reset running loss and time\n",
    "#             running_loss = 0.0\n",
    "#             start_time = time.time()\n",
    "    # test after each epoch\n",
    "    print(\"Loss epoch {}: {}, took {}s\".format(epoch, running_loss,time.time()-start_time))\n",
    "    loss_array[epoch] = running_loss\n",
    "\n",
    "test_all_preds(test_net)\n",
    "#print('total training loss for epoch {}: {:.6f}'.format(epoch+1, total_train_loss))    \n",
    "print('...Training finished')\n",
    "plt.plot(loss_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected loss for untrained set with Cross Entropy:\n",
    "k = number of classes\n",
    "N = number of labeled data in dataset\n",
    "loss_per_prediction = -log(1/k) = log(k)\n",
    "total_loss = sum(log(k)) = N*log(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected loss with {} different classes and {} data points: {}  (3, 4, 4.394449154672439)\n"
     ]
    }
   ],
   "source": [
    "# print(labels.size())\n",
    "# print(outputs.size())\n",
    "# print(labels)\n",
    "# print(outputs)\n",
    "# import matplotlib.pyplot as plt\n",
    "# print(scenes[0].squeeze(0).size())\n",
    "# plt.imshow(scenes[9].squeeze(0).permute(1,2,0))\n",
    "# plt.figure(figsize=(30,40))\n",
    "# print('left foot trans from air to ground')\n",
    "# plt.subplot(131)\n",
    "# plt.imshow(scenes[4])\n",
    "# plt.title('frame 44')\n",
    "# plt.subplot(132)\n",
    "# plt.imshow(scenes[5])\n",
    "# plt.title('frame 45')\n",
    "# plt.subplot(133)\n",
    "# plt.imshow(scenes[6])\n",
    "# plt.title('frame 46')\n",
    "# plt.show()\n",
    "print('Expected loss with {} different classes and {} data points: {} ', (3, len(dataset)-split, (len(dataset)-split)*np.log(3)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python gait_36",
   "language": "python",
   "name": "gait_36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
