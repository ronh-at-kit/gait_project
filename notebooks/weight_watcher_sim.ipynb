{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use this file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configuration needed\n"
     ]
    }
   ],
   "source": [
    "print(\"No configuration needed\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#DESIGN PARAMETERS FOR NEURAL NETWORK\n",
    "NR_LSTM_UNITS = 1\n",
    "IMAGE_INPUT_SIZE = 550\n",
    "# Similar input size to \"normal\" data: 130x130 -> 15x15 with 3 conv layers\n",
    "# image input of 54 yields output after conv layers of 5\n",
    "IMAGE_AFTER_CONV_SIZE = 15\n",
    "\n",
    "#for 3x3 kernels, n=num_layers: len_in = 2^n*len_out + sum[i=1..n](2^i)\n",
    "#CONV_LAYER_LENGTH = 5\n",
    "\n",
    "LSTM_INPUT_SIZE = IMAGE_AFTER_CONV_SIZE*IMAGE_AFTER_CONV_SIZE\n",
    "LSTM_HIDDEN_SIZE = 100\n",
    "\n",
    "RGB_CHANNELS = 3\n",
    "TIMESTEPS = 10\n",
    "BATCH_SIZE = 1 #until now just batch_size = 1\n",
    "NR_EPOCHS = 5\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "\n",
    "FORMAT_TIMESTEPS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created\n"
     ]
    }
   ],
   "source": [
    "# Generate dataset\n",
    "if TIMESTEPS == 10:\n",
    "    lab = [\n",
    "        [0,0,0,1,1,2,2,2,1,1],\n",
    "        [1,0,0,0,1,1,2,2,2,1]\n",
    "    ]\n",
    "elif TIMESTEPS == 20:\n",
    "        lab = [\n",
    "        [0,0,0,1,1,2,2,2,1,1,0,0,0,1,1,2,2,2,1,1],\n",
    "        [1,0,0,0,1,1,2,2,2,1,1,0,0,0,1,1,2,2,2,1]\n",
    "        ]\n",
    "std_dev = 1\n",
    "training_set_size = len(lab)\n",
    "arr = np.full((training_set_size,TIMESTEPS,BATCH_SIZE,RGB_CHANNELS,IMAGE_INPUT_SIZE,IMAGE_INPUT_SIZE),0)\n",
    "noise_arr = np.random.normal(0,std_dev,arr.shape)\n",
    "# print(noise_arr.shape)\n",
    "\n",
    "sequences = lab\n",
    "for i,ll in enumerate(lab):\n",
    "    for j,l in enumerate(ll):\n",
    "        sequences[i][j] = (l-1)*0.5\n",
    "# print(sequences)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for j, image in enumerate(sequence):\n",
    "        noise_arr[i][j] = noise_arr[i][j] + np.full(noise_arr[i][j].shape,image)\n",
    "# print(noise_arr)\n",
    "\n",
    "dataset = torch.from_numpy(noise_arr)\n",
    "labelset = torch.tensor(lab)\n",
    "# print(labels)\n",
    "# print(dataset)\n",
    "print(\"Dataset created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model):\n",
    "    print(\"To be implemented\")\n",
    "\n",
    "#     n_batches_test = len(test_loader)\n",
    "\n",
    "#     #Time for printing\n",
    "#     testing_start_time = time.time()\n",
    "\n",
    "#     print('Start testing...')\n",
    "#     correct = 0 \n",
    "#     total = 0\n",
    "#     with torch.no_grad():\n",
    "#         for i, batch in enumerate(train_loader):\n",
    "#             inputs, labels = batch\n",
    "            \n",
    "#             data_in = [s.to(device) for s in inputs['flows']]\n",
    "#             labels = labels.to(device)\n",
    "#             if not labels.size()[0] == BATCH_SIZE:\n",
    "#                 # skip uncompleted batch size NN is fixed to BATCHSIZE\n",
    "#                 continue\n",
    "#             outputs = model(data_in)\n",
    "# #             print(\"Out:\", len(outputs), outputs.size())\n",
    "# #             print(\"Labels:\", len(labels), labels.size())\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "# #             print('predicted:',len(predicted),predicted.size())\n",
    "#             n_errors = torch.nonzero(torch.abs(labels.long() - predicted)).size(0)\n",
    "#             total += predicted.numel()\n",
    "#             # print('predicted',predicted)\n",
    "#             correct += predicted.numel() - n_errors\n",
    "#             # print('labels',labels)\n",
    "#     print('Accuracy {:.2f}%'.format(100*correct/total))\n",
    "#     print('...testing finished')\n",
    "# print(\"Definition done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class defined\n",
      "Hidden: 2\n"
     ]
    }
   ],
   "source": [
    "#USE RANDOM IMAGES TO SET UP WORKING EXAMPLE\n",
    "class TEST_CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TEST_CNN_LSTM, self).__init__()\n",
    "                                        # in 54x54\n",
    "        self.conv1 = nn.Conv2d(3,6,3) #out 52x52\n",
    "        self.pool1 = nn.MaxPool2d(2,2) #out 26x26\n",
    "        self.conv2= nn.Conv2d(6,3,3) #out 24x24\n",
    "        self.pool2 = nn.MaxPool2d(2,2) #out 12x12\n",
    "        self.conv3 = nn.Conv2d(3,1,3) #out 10x10\n",
    "        self.pool3 = nn.MaxPool2d(2,2) #out 5x5\n",
    "        self.conv4= nn.Conv2d(1,1,3) #out 24x24\n",
    "        self.pool4 = nn.MaxPool2d(2,2) #out 12x12\n",
    "        self.conv5 = nn.Conv2d(1,1,3) #out 10x10\n",
    "        self.pool5 = nn.MaxPool2d(2,2) #out 5x5     \n",
    "        \n",
    "#         self.lstm = nn.LSTM(LSTM_INPUT_SIZE,\n",
    "#                             LSTM_HIDDEN_SIZE,\n",
    "#                             NR_LSTM_UNITS)\n",
    "        self.fc1 = nn.Linear(LSTM_INPUT_SIZE,100)\n",
    "        self.fc2 = nn.Linear(100,20)\n",
    "        self.fc3 = nn.Linear(20,3)\n",
    "        \n",
    "        #initialize hidden states of normal LSTM\n",
    "        self._hidden = (torch.randn(NR_LSTM_UNITS, BATCH_SIZE, LSTM_HIDDEN_SIZE),\n",
    "                        torch.randn(NR_LSTM_UNITS, BATCH_SIZE, LSTM_HIDDEN_SIZE))\n",
    "\n",
    "        print(\"Hidden:\", len(self._hidden))\n",
    "    def forward(self,x):\n",
    "        #print(\"Input:\", x.size())\n",
    "        x = x.float()\n",
    "        \n",
    "#         print(\"X arr size\", x_arr.size())\n",
    "#         print(\"x shape\",x.shape)\n",
    "#         print(\"x[0]\",x[0].shape)\n",
    "        x_arr = torch.zeros(TIMESTEPS,BATCH_SIZE,1,IMAGE_AFTER_CONV_SIZE,IMAGE_AFTER_CONV_SIZE)\n",
    "    \n",
    "        for i in range(TIMESTEPS):#parallel convolutions which are later concatenated for LSTM\n",
    "            x_tmp_c1 = self.pool1(F.relu(self.conv1(x[i])))\n",
    "            x_tmp_c2 = self.pool2(F.relu(self.conv2(x_tmp_c1)))\n",
    "            x_tmp_c3 = self.pool3(F.relu(self.conv3(x_tmp_c2)))\n",
    "            x_tmp_c4 = self.pool4(F.relu(self.conv4(x_tmp_c3)))\n",
    "            x_tmp_c5 = self.pool5(F.relu(self.conv5(x_tmp_c4)))\n",
    "            x_arr[i] = x_tmp_c5\n",
    "    \n",
    "        x = torch.cat(tuple(x for x in x_arr),0)\n",
    "        \n",
    "#         print(\"x before LSTM\",x.view(TIMESTEPS,BATCH_SIZE,-1).shape) \n",
    "#         x, _hidden = self.lstm(x.view(TIMESTEPS,BATCH_SIZE,-1), self._hidden)\n",
    "#         print(\"x after LSTM\",x.shape) \n",
    "        x = x.view(-1,LSTM_INPUT_SIZE)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "print(\"Class defined\")\n",
    "\n",
    "#TRAINING\n",
    "net = TEST_CNN_LSTM()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gait_analysis import WeightWatcher\n",
    "monitor = WeightWatcher(net,['conv5','fc3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Epoch: 0 Loss 2.0484602451324463\n",
      "Epoch: 1 Loss 2.0137808322906494\n",
      "Epoch: 2 Loss 1.9505335092544556\n",
      "Epoch: 3 Loss 1.8673484325408936\n",
      "Epoch: 4 Loss 1.7657229900360107\n",
      "...Training finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Start training...')\n",
    "for epoch in range(NR_EPOCHS): \n",
    "    loss = 0.0\n",
    "    optimizer.zero_grad() \n",
    "    \n",
    "    for data_in, labels in zip(dataset, labelset):\n",
    "        outputs = net(data_in)\n",
    "        single_loss = criterion(outputs, labels.long())\n",
    "        loss += single_loss\n",
    "    \n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "    monitor.update_weights(net,['conv5','fc3'])\n",
    "    monitor.update_loss(loss)\n",
    "    # or monitor.update_loss(loss.data.item())\n",
    "    print(\"Epoch:\", epoch, \"Loss\",loss.data.item())\n",
    "print('...Training finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2c64b33b38>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = monitor.get_weight_changes(['fc3','conv5'])\n",
    "single = monitor.get_weight_changes(['fc3'])\n",
    "ll = monitor.get_loss()\n",
    "plt.figure()\n",
    "plt.plot(single)\n",
    "plt.figure()\n",
    "plt.plot(y)\n",
    "plt.figure()\n",
    "plt.plot(x)\n",
    "plt.figure()\n",
    "plt.plot(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python gait_36",
   "language": "python",
   "name": "gait_36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
