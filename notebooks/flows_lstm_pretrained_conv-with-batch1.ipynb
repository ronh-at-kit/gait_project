{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings.py should be e.g. cnn_flows_prtrain\n",
      "Hyperparameters defined\n",
      "Bug with learning rate when sequence length is not the same for each element of the dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings.py should be e.g. cnn_flows_prtrain\")\n",
    "#DESIGN PARAMETERS FOR NEURAL NETWORK\n",
    "\n",
    "VALIDATION_SPLIT = 0.5 #indicated ratio of training to validation data: 0.2 -> 20% VALIDATION data\n",
    "RANDOMIZED_SEED = 20\n",
    "SHUFFLE_DATASET = False\n",
    "\n",
    "TRAINING_PREPARATION = False\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "TIME_STEPS = 40\n",
    "\n",
    "SLICE_FROM_TIME_STEP = 0 #slices from timestep SLICE_FROM_TIMESTEP to the last one\n",
    "\n",
    "NR_EPOCHS = 200\n",
    "\n",
    "LR = 0.0001\n",
    "print(\"Hyperparameters defined\")\n",
    "print(\"Bug with learning rate when sequence length is not the same for each element of the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import os.path as path\n",
    "import copy\n",
    "\n",
    "from gait_analysis import AnnotationsCasia as Annotations\n",
    "from gait_analysis import CasiaDataset\n",
    "from gait_analysis.Config import Config\n",
    "from gait_analysis import Composer\n",
    "from gait_analysis import WeightWatcher\n",
    "from gait_analysis import AccuracyTrackerTrainTest\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gait_analysis.Models import PretrainConvFlow\n",
    "from gait_analysis.Models.TransferConvLSTMFlow import TransferConvLSTMFlow\n",
    "\n",
    "print(\"done\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: doesn't x = x.view(BATCH_SIZE,TIME_STEPS*LSTM_HIDDEN_FEATURES) mix up batch size order?\n",
      "TODO: BATCH_SIZE is currently fixed and one\n",
      "TODO: Is x_arr in device?\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "net = TransferConvLSTMFlow()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=LR)\n",
    "\n",
    "# monitor = WeightWatcher(net,['conv5','fc1'])\n",
    "tt_acc_tracker = AccuracyTrackerTrainTest([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configuration  cnn_flows_pretrain\n",
      "[OK]\n"
     ]
    }
   ],
   "source": [
    "#change configuration in settings.py\n",
    "c = Config()\n",
    "c.config['indexing']['grouping'] = 'person_sequence_angle'\n",
    "# c.config['transformers']['DimensionResize']['dimension'] = TIME_STEPS\n",
    "# #c.config['indexing']['people selection'] = [1]\n",
    "# #c.config['indexing']['sequences_selection'] = ['nm-01']\n",
    "# c.config['pose']['load'] = False\n",
    "# c.config['flow']['load'] = True\n",
    "# c.config['heatmaps']['load'] = False\n",
    "# #c.config['scenes']['sequences'] = ['nm']\n",
    "# #c.config['scenes']['angles'] = ['108']\n",
    "# c.config['dataset_output'] = {\n",
    "# #         'data': [\"scenes\",\"flows\",\"heatmaps_LAnkle\",\"heatmaps_RAnkle\"],\n",
    "#         'data': ['flows'],\n",
    "#         'label': \"annotations\"}\n",
    "composer = Composer()\n",
    "transformer = composer.compose()\n",
    "dataset = CasiaDataset(transform=transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 1655\n",
      "Indices size: 1655\n",
      "Split: 827\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "print(\"Dataset size:\", len(dataset))\n",
    "print(\"Indices size:\", len(indices))\n",
    "split = int(np.floor(VALIDATION_SPLIT * dataset_size))\n",
    "print(\"Split:\", split)\n",
    "if SHUFFLE_DATASET:\n",
    "    np.random.seed(RANDOMIZED_SEED)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "train_sampler = torch.utils.data.SequentialSampler(train_indices)\n",
    "test_sampler = torch.utils.data.SequentialSampler(test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people selection from:  40  to  124\n"
     ]
    }
   ],
   "source": [
    "print('people selection from: ', c.config['indexing']['people_selection'][0],' to ', c.config['indexing']['people_selection'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #PREPARATION FOR TRAINING\n",
    "# loss_array = []\n",
    "# learning_rate_array = []\n",
    "\n",
    "# print('Start training...')\n",
    "# print(\"Expected loss with {} different classes and {} data elements: {}\".format(3, len(dataset)-split, (len(dataset)-split)*np.log(3)))\n",
    "# running_loss = 0.0\n",
    "# #print(\"Data set length:\", len((train_loader)), \"Validation length:\", len(test_loader))\n",
    "# print(\"Batch size:\", BATCH_SIZE)\n",
    "# print(\"Evaluating first element...\")\n",
    "# start_time = time.time()\n",
    "# i, batch = next(iter(enumerate(train_loader)))\n",
    "# inputs, labels = batch\n",
    "# data_in = [s.to(device) for s in inputs['flows']]\n",
    "# # print(\"Data in original\", data_in)\n",
    "\n",
    "\n",
    "# # print(\"Proof for normalized data:\", data_in[0][0])\n",
    "# labels = labels.to(device)\n",
    "# print(\"Time steps:{}, input sequence length:{}\".format(TIME_STEPS,len(data_in)))\n",
    "# #print(\"NN input: \",len(flows),len(flows[0]),len(flows[0][0]),len(flows[0][0][0]),len(flows[0][0][0][0]))\n",
    "# optimizer.zero_grad() \n",
    "# outputs = net(data_in)\n",
    "# print(\"Expected output format: [BATCH, NR_CLASSES, TIMESTEPS]\")\n",
    "# # print(\"Output format:\", len(outputs), outputs.size())\n",
    "# print(\"Expected label format: [BATCH, TIMESTEPS] (with int-label as each element indicating the correct one)\")\n",
    "# # print(\"Labels:\", len(labels), labels.size())\n",
    "# # print(\"Slicing loss. Using loss from:\",SLICE_FROM_TIME_STEP,\"to\",TIME_STEPS)\n",
    "# print(\"Final label: \",labels[:,SLICE_FROM_TIME_STEP:TIME_STEPS].size())\n",
    "# print(\"Final output:\", outputs[:,:,SLICE_FROM_TIME_STEP:TIME_STEPS].size())\n",
    "# # print(\"Labels content:\", labels)\n",
    "# labels = labels.squeeze(0)\n",
    "# outputs = outputs.squeeze(0)\n",
    "# print(\"Dimensions:\",\"Labels\",labels.size(),\"Pred\",outputs.size())\n",
    "# # before: loss = criterion(outputs[:,:,SLICE_FROM_TIME_STEP:TIME_STEPS].float(),labels[:,SLICE_FROM_TIME_STEP:TIME_STEPS].long())\n",
    "# loss = criterion(outputs[SLICE_FROM_TIME_STEP:TIME_STEPS,:].float(),labels[SLICE_FROM_TIME_STEP:TIME_STEPS].long())\n",
    "# loss.backward() \n",
    "# optimizer.step()\n",
    "\n",
    "# running_loss += loss.data.item()\n",
    "# elapsed_time = time.time() - start_time;\n",
    "# loss_array.append(running_loss)\n",
    "# learning_rate_array.append(LR)\n",
    "# print(\"Loss:{}, expected loss:{}\".format(running_loss, np.log(3)))\n",
    "# print(\"Time needed:{}s\".format(elapsed_time))\n",
    "# print(\"Expected loss for total training data: \", (len(dataset)-split)*np.log(3))\n",
    "# print(\"Expected training time per epoch:{} min\".format(elapsed_time* len(train_loader)/60))\n",
    "# print(\"Estimated total training time:{} hours\".format(elapsed_time* len(train_loader)*NR_EPOCHS/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "-----------------------------\n",
      "Epoch 0: Loss [1.003391716847606,0.7860072586111434], Acc [0.536,0.754] took 261.37s\n",
      "Accuracy by class [[0.75, 0.518, 0.374],[0.754, 0.654, 0.841]] Total elements: [[10112, 10756, 12252],[10101, 10745, 12234]]\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "-----------------------------\n",
      "Epoch 1: Loss [0.6362952312674044,0.5343821931461555], Acc [0.786,0.809] took 259.61s\n",
      "Accuracy by class [[0.771, 0.733, 0.844],[0.817, 0.756, 0.848]] Total elements: [[10112, 10756, 12252],[10101, 10745, 12234]]\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "-----------------------------\n",
      "Epoch 2: Loss [0.4852945136879865,0.4522878092401339], Acc [0.824,0.832] took 264.16s\n",
      "Accuracy by class [[0.814, 0.807, 0.848],[0.837, 0.789, 0.864]] Total elements: [[10112, 10756, 12252],[10101, 10745, 12234]]\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "-----------------------------\n",
      "Epoch 3: Loss [0.42810543377593924,0.41320172906642205], Acc [0.841,0.844] took 264.9s\n",
      "Accuracy by class [[0.834, 0.835, 0.852],[0.846, 0.807, 0.873]] Total elements: [[10112, 10756, 12252],[10101, 10745, 12234]]\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "-----------------------------\n",
      "Epoch 4: Loss [0.3966439631230156,0.3890639756921552], Acc [0.852,0.852] took 259.87s\n",
      "Accuracy by class [[0.844, 0.854, 0.856],[0.855, 0.817, 0.879]] Total elements: [[10112, 10756, 12252],[10101, 10745, 12234]]\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n",
      "Patch: repeat last image on missing flow file\n"
     ]
    }
   ],
   "source": [
    "print('Start training...')\n",
    "\n",
    "for epoch in range(NR_EPOCHS): \n",
    "    start_time = time.time()\n",
    "    running_loss_train = 0.0\n",
    "    running_loss_test = 0.0\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        inputs, labels = batch\n",
    "        data_in = [s.to(device) for s in inputs['flows']]\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "#         print(\"Time steps:{}, input sequence length:{}\".format(TIME_STEPS,len(data_in)))\n",
    "        #print(\"NN input: \",len(flows),len(flows[0]),len(flows[0][0]),len(flows[0][0][0]),len(flows[0][0][0][0]))\n",
    "        optimizer.zero_grad() \n",
    "        outputs = net(data_in)\n",
    "        labels = labels.squeeze(0).long()\n",
    "        outputs = outputs.squeeze(0).float()\n",
    "        \n",
    "#         print(\"Size output\",outputs.size(),\"and label\", labels.size())\n",
    "#         print(outputs)\n",
    "        \n",
    "        loss = criterion(outputs[:,SLICE_FROM_TIME_STEP:TIME_STEPS].float(),labels[SLICE_FROM_TIME_STEP:TIME_STEPS].long())\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss_train += loss.data.item()/((1-VALIDATION_SPLIT)*len(dataset))\n",
    "        elapsed_time = time.time() - start_time;\n",
    "        \n",
    "        tt_acc_tracker.update_loss(running_loss_train,\"TRAIN\")\n",
    "#         acc_tracker.update_lr(LR)\n",
    "\n",
    "        prediction = torch.max(outputs,1)[1]\n",
    "        label_element = labels\n",
    "    \n",
    "        tt_acc_tracker.update_acc(prediction,label_element,\"TRAIN\")\n",
    "        #         print(\"Prediction\", labels)\n",
    "#         acc_tracker.update_acc(prediction,labels)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for i,batch in enumerate(test_loader):\n",
    "            inputs, labels = batch\n",
    "            data_in = [s.to(device) for s in inputs['flows']]\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = net(data_in)\n",
    "            labels = labels.squeeze(0).long()\n",
    "            outputs = outputs.squeeze(0).float()\n",
    "            loss = criterion(outputs[:,SLICE_FROM_TIME_STEP:TIME_STEPS],labels[SLICE_FROM_TIME_STEP:TIME_STEPS])\n",
    "            running_loss_test += loss.data.item()/(VALIDATION_SPLIT*len(dataset))\n",
    "            tt_acc_tracker.update_loss(running_loss_train,\"TEST\")\n",
    "\n",
    "            prediction = torch.max(outputs,1)[1]\n",
    "            label_element = labels\n",
    "\n",
    "            tt_acc_tracker.update_acc(prediction,label_element,\"TEST\")\n",
    "   \n",
    "              \n",
    "    print(\"-----------------------------\")\n",
    "    print(\"Epoch {}: Loss [{},{}], Acc [{},{}] took {}s\".format(epoch, running_loss_train,running_loss_test,tt_acc_tracker.get_acc_tot(\"TRAIN\"),tt_acc_tracker.get_acc_tot(\"TEST\"), np.around(time.time()-start_time,decimals=2)))\n",
    "    print(\"Accuracy by class [{},{}] Total elements: [{},{}]\".format(tt_acc_tracker.get_acc(\"TRAIN\"),tt_acc_tracker.get_acc(\"TEST\"), tt_acc_tracker.get_labels_distribution(\"TRAIN\"),tt_acc_tracker.get_labels_distribution(\"TEST\")))\n",
    "\n",
    "    tt_acc_tracker.update_loss(running_loss_train,\"TRAIN\")\n",
    "    tt_acc_tracker.update_loss(running_loss_test,\"TEST\")\n",
    "    tt_acc_tracker.update_graph()\n",
    "    tt_acc_tracker.reset_acc_both()\n",
    "    tt_acc_tracker.update_lr(LR)\n",
    "\n",
    "print('...Training finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), '/home/ron/PycharmProjects/Gait2019/gait_project/saved_models/TransferConvLSTMFlow/TransferConvLSTMFlowB1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss value')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tt_acc_tracker.test_tracker.get_loss_graph())\n",
    "plt.title('loss batch 1')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_acc_tracker.write_to_csv('/home/ron/PycharmProjects/Gait2019/plots/B1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
